# FedCL å¿«é€Ÿå…¥é—¨æŒ‡å—

## å®‰è£…å’Œå¯¼å…¥

```bash
# å®‰è£…ä¾èµ–
pip install torch torchvision loguru omegaconf

# å¯¼å…¥æ¡†æ¶
import fedcl
```

## ä¸€è¡Œä»£ç å¯åŠ¨è”é‚¦å­¦ä¹ 

```python
# æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
result = fedcl.train(
    dataset="mnist",
    num_clients=3,
    rounds=10
)
print(f"æœ€ç»ˆå‡†ç¡®ç‡: {result.accuracy:.4f}")
```

## è‡ªå®šä¹‰æ¨¡å‹

```python
import torch.nn as nn
from fedcl.methods.learners import DefaultLearner

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )
        self.criterion = nn.CrossEntropyLoss()
    
    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³è¾“å…¥
        return self.network(x)
    
    def forward_with_loss(self, x, target):
        output = self.forward(x)
        loss = self.criterion(output, target)
        return output, loss

# åˆ›å»ºå­¦ä¹ å™¨
config = {
    "model": {"instance": MyModel()},
    "optimizer": {"type": "adam", "learning_rate": 0.01},
    "local_epochs": 2
}
learner = DefaultLearner("client_0", config)
```

## ä½¿ç”¨StandardFederationTrainer

```python
from fedcl.methods.trainers import StandardFederationTrainer

# é…ç½®è®­ç»ƒå™¨
config = {
    "num_clients": 3,
    "local_epochs": 2,
    "learning_rate": 0.01,
    "batch_size": 32,
    "aggregator": "fedavg",
    "learner": "default"
}

# åˆ›å»ºè®­ç»ƒå™¨
trainer = StandardFederationTrainer(config)

# å¼€å§‹è®­ç»ƒ
result = await trainer.train()
print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆå‡†ç¡®ç‡: {result.accuracy:.4f}")
```

## è‡ªå®šä¹‰èšåˆå™¨

```python
from fedcl.api import aggregator
from fedcl.methods.aggregators import AbstractAggregator

@aggregator
class MyAggregator(AbstractAggregator):
    def aggregate(self, client_results):
        # å®ç°è‡ªå®šä¹‰èšåˆé€»è¾‘
        aggregated_weights = {}
        total_samples = sum(r["num_samples"] for r in client_results)
        
        for key in client_results[0]["model_weights"].keys():
            aggregated_weights[key] = sum(
                r["model_weights"][key] * r["num_samples"] / total_samples
                for r in client_results
            )
        
        return {
            "aggregated_weights": aggregated_weights,
            "num_clients": len(client_results)
        }
```

## é…ç½®é©±åŠ¨å®éªŒ

```python
# ä½¿ç”¨é…ç½®æ–‡ä»¶
config = {
    "dataset": "mnist",
    "num_clients": 3,
    "rounds": 10,
    "local_epochs": 2,
    "learner": "default",
    "aggregator": "fedavg",
    "evaluator": "prototype",
    "model": {
        "type": "mlp",
        "input_dim": 784,
        "hidden_dims": [128, 64],
        "output_dim": 10
    },
    "optimizer": {
        "type": "adam",
        "learning_rate": 0.01
    }
}

result = fedcl.train_from_config(config)
```

## æŸ¥çœ‹å¯ç”¨ç»„ä»¶

```python
# åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ç»„ä»¶
components = fedcl.list_components()
print("å¯ç”¨ç»„ä»¶:", components)

# è·å–ç»„ä»¶è¯¦ç»†ä¿¡æ¯
info = fedcl.get_component_info("fedavg")
print("FedAvgèšåˆå™¨ä¿¡æ¯:", info)
```

## å¸¸è§é…ç½®é€‰é¡¹

### åŸºç¡€é…ç½®
```python
config = {
    "num_clients": 3,           # å®¢æˆ·ç«¯æ•°é‡
    "rounds": 10,              # è”é‚¦å­¦ä¹ è½®æ•°
    "local_epochs": 2,         # æ¯è½®æœ¬åœ°è®­ç»ƒè½®æ•°
    "batch_size": 32,          # æ‰¹å¤„ç†å¤§å°
    "learning_rate": 0.01,     # å­¦ä¹ ç‡
    "client_selection_ratio": 1.0,  # å®¢æˆ·ç«¯é€‰æ‹©æ¯”ä¾‹
}
```

### æ‰§è¡Œæ¨¡å¼é…ç½®
```python
config = {
    "execution": {
        "mode": "auto",        # auto, local, pseudo, distributed
        "num_workers": 4,      # å·¥ä½œè¿›ç¨‹æ•°
        "timeout": 300         # è¶…æ—¶æ—¶é—´(ç§’)
    }
}
```

### æ•°æ®åˆ†åŒºé…ç½®
```python
config = {
    "data_partition": {
        "type": "iid",         # iid, non_iid_label, non_iid_quantity
        "alpha": 0.5           # ç”¨äºnon_iid_labelçš„Dirichletåˆ†å¸ƒå‚æ•°
    }
}
```

## æœ€ä½³å®è·µ

### 1. æ¨¡å‹è®¾è®¡
- ç»§æ‰¿ `nn.Module`
- å®ç° `forward_with_loss` æ–¹æ³•
- åœ¨æ¨¡å‹ä¸­å®šä¹‰ `criterion`

### 2. å­¦ä¹ å™¨ä½¿ç”¨
- ä½¿ç”¨ `DefaultLearner` ä½œä¸ºèµ·ç‚¹
- é€šè¿‡é…ç½®ä¼ å…¥æ¨¡å‹å®ä¾‹
- æ”¯æŒå†…ç½®æŸå¤±è®¡ç®—

### 3. è®­ç»ƒå™¨é€‰æ‹©
- ä½¿ç”¨ `StandardFederationTrainer` è¿›è¡Œæ ‡å‡†è”é‚¦å­¦ä¹ 
- é€šè¿‡é…ç½®é€‰æ‹©èšåˆå™¨å’Œå­¦ä¹ å™¨
- æ”¯æŒå¤šç§æ‰§è¡Œæ¨¡å¼

### 4. è°ƒè¯•æŠ€å·§
```python
# å¯ç”¨è°ƒè¯•æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# ä½¿ç”¨æœ¬åœ°æ¨¡å¼å¿«é€Ÿè°ƒè¯•
config = {"execution": {"mode": "local"}}

# æ£€æŸ¥ç»„ä»¶æ³¨å†ŒçŠ¶æ€
print(fedcl.list_components())
```

## å®Œæ•´ç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
å®Œæ•´çš„MNISTè”é‚¦å­¦ä¹ ç¤ºä¾‹
"""

import torch.nn as nn
from fedcl.methods.learners import DefaultLearner
from fedcl.methods.trainers import StandardFederationTrainer

# 1. å®šä¹‰æ¨¡å‹
class MNISTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )
        self.criterion = nn.CrossEntropyLoss()
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        return self.network(x)
    
    def forward_with_loss(self, x, target):
        output = self.forward(x)
        loss = self.criterion(output, target)
        return output, loss

# 2. é…ç½®è®­ç»ƒå™¨
config = {
    "num_clients": 3,
    "local_epochs": 2,
    "learning_rate": 0.01,
    "batch_size": 32,
    "aggregator": "fedavg",
    "learner": "default"
}

# 3. åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
trainer = StandardFederationTrainer(config)
result = await trainer.train()

print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼")
print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {result.accuracy:.4f}")
print(f"   è®­ç»ƒè½®æ•°: {result.rounds}")
print(f"   å®¢æˆ·ç«¯æ•°é‡: {result.num_clients}")
```

## ä¸‹ä¸€æ­¥

1. **é˜…è¯»å®Œæ•´æ–‡æ¡£**: æŸ¥çœ‹ `docs/é¡¹ç›®è®¾è®¡æ–‡æ¡£.md` äº†è§£è¯¦ç»†æ¶æ„
2. **æ¢ç´¢ç»„ä»¶**: ä½¿ç”¨ `fedcl.list_components()` æŸ¥çœ‹å¯ç”¨ç»„ä»¶
3. **è‡ªå®šä¹‰ç®—æ³•**: å®ç°è‡ªå·±çš„å­¦ä¹ å™¨ã€èšåˆå™¨æˆ–è¯„ä¼°å™¨
4. **ç”Ÿäº§éƒ¨ç½²**: é…ç½®åˆ†å¸ƒå¼æ¨¡å¼è¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒ

## è·å–å¸®åŠ©

- æŸ¥çœ‹æ—¥å¿—è¾“å‡ºäº†è§£è¿è¡ŒçŠ¶æ€
- ä½¿ç”¨æœ¬åœ°æ¨¡å¼è¿›è¡Œè°ƒè¯•
- æ£€æŸ¥ç»„ä»¶æ³¨å†ŒçŠ¶æ€
- å‚è€ƒå®Œæ•´æ–‡æ¡£äº†è§£é«˜çº§åŠŸèƒ½
