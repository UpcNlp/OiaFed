# 联邦学习框架架构设计说明

## 目录命名调整理由

### 1. `business/` → `fl/` 的调整

#### 调整原因
- **精确性**: `fl` (Federated Learning) 直接指向联邦学习核心逻辑，比泛化的 `business` 更精确
- **简洁性**: 符合项目 `fedcl` 的命名风格，保持一致性
- **语义明确**: 明确表示这是联邦学习特有的业务逻辑层，而非通用业务层

#### 符合项目规范
根据项目规范中的"零联邦概念暴露"和"标准PyTorch接口"原则：
- `fl/` 层专门处理联邦学习的协调逻辑
- 用户仍使用标准PyTorch概念，但框架在 `fl/` 层内部处理联邦细节

### 2. 删除 `evaluators/` 的理由

#### 违反核心设计原则

**违反"零联邦概念暴露"**:
```python
# ❌ 错误方式 - 用户需要学习联邦评估概念
federated_evaluator = FederatedEvaluator(config)
results = await federated_evaluator.evaluate()

# ✅ 正确方式 - 用户使用标准PyTorch评估
model.eval()
with torch.no_grad():
    for data, target in test_loader:
        output = model(data)
        # 标准评估逻辑
```

**违反"标准PyTorch接口"**:
- 评估本质上是标准的模型推理操作
- 不需要联邦学习框架提供专门的评估器
- 用户应该直接使用PyTorch的标准评估方式

**违反"保持简洁性"**:
- 项目规范明确要求系统保持简洁
- 评估器增加了不必要的复杂性
- 评估可以在trainer的train()方法中直接实现

#### 更符合实际使用模式

```python
# 用户在trainer中直接实现评估逻辑
@fedcl.trainer("my_fedavg")
class MyTrainer(AbstractFederationTrainer):
    async def train(self):
        for round_num in range(self.config.num_rounds):
            # 训练阶段
            selected_clients = self.select_clients(round_num)
            results = await asyncio.gather(*[
                self.learner_proxy.train_epoch(client_id)
                for client_id in selected_clients
            ])
            
            # 直接在这里实现评估 - 标准PyTorch方式
            if round_num % self.config.eval_frequency == 0:
                eval_results = []
                for client_id in selected_clients:
                    # 获取客户端模型进行标准评估
                    model = await self.learner_proxy.get_model(client_id)
                    model.eval()
                    
                    # 标准PyTorch评估逻辑
                    accuracy = self._evaluate_model(model, test_data)
                    eval_results.append(accuracy)
                
                avg_accuracy = sum(eval_results) / len(eval_results)
                logger.info(f"Round {round_num} accuracy: {avg_accuracy}")
```

## 调整后的架构优势

### 1. 更清晰的职责分离

```
fedcl/
├── fl/                         # 联邦学习核心层
│   └── trainers/               # 联邦训练协调器
├── proxy/                      # 透明代理层  
├── strategy/                   # 策略调度层
├── execution/                  # 执行实现层
├── transport/                  # 通信传输层
└── methods/                    # 算法实现层
```

### 2. 符合用户心智模型

用户思考路径：
1. **"我要做联邦学习"** → `fl/trainers/` (定义联邦训练逻辑)
2. **"我要用FedAvg算法"** → `methods/aggregators/fedavg.py` (算法实现)
3. **"我要在不同环境运行"** → 配置文件切换，代码无需修改

### 3. 降低学习成本

```python
# 用户只需要理解这一个概念：Trainer
@fedcl.trainer("my_experiment")
class MyExperiment(AbstractFederationTrainer):
    async def train(self):
        # 联邦训练逻辑
        # 评估逻辑
        # 结果记录逻辑
        # 全部在一个地方，符合直觉
        pass
```

## 与项目现状对比

### 当前问题
- `transparent/` 目录混杂了不同层次的组件
- `engine/federation_engine.py` 职责不明确
- 评估逻辑分散，增加复杂性

### 调整后优势
- **`fl/trainers/`**: 明确的联邦训练逻辑层
- **删除专门评估器**: 用户使用标准PyTorch评估，降低学习成本
- **清晰的分层**: 每层职责单一，依赖关系明确

## 实施建议

### 立即行动
1. 将 `transparent/abstract_federation_trainer.py` 移动到 `fl/trainers/`
2. 删除所有专门的评估器组件
3. 在trainer基类中提供评估相关的辅助方法

### 后续优化
1. 逐步将其他trainer相关组件迁移到 `fl/trainers/`
2. 确保所有评估逻辑都通过标准PyTorch接口实现
3. 在文档中强调"评估使用标准PyTorch方式"

这样的调整完全符合项目的设计规范，让框架更加简洁、易用，真正做到了"用户只需关心联邦学习算法逻辑，无需了解分布式细节"的目标。