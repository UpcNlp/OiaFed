# FedCL: 透明联邦持续学习框架

## 项目概述

FedCL (Federated Continual Learning) 是一个全新的透明联邦学习框架，旨在让真联邦和伪联邦对用户完全透明，专注于算法逻辑而非分布式细节。

### 核心理念

**分布式联邦写代码过程和集中式一样，底层自动处理权重、梯度、特征获取等。**

### 版本信息
- **版本**: v0.2.0
- **作者**: FedCL Development Team
- **状态**: 生产环境就绪

## 设计思路

### 1. 透明化设计

FedCL的核心设计理念是**透明化**，主要体现在以下几个方面：

#### 1.1 执行模式透明
- **本地模拟模式**: 单机多进程模拟联邦学习
- **伪联邦模式**: 单机多进程，真实网络通信
- **真联邦模式**: 多机分布式，真实网络通信

用户无需关心底层执行模式，框架自动检测和适配。

#### 1.2 通信透明
- **透明代理机制**: `LearnerProxy` 让用户像操作本地对象一样操作远程学习器
- **自动序列化**: 权重、梯度、特征等自动序列化和传输
- **智能传输选择**: 根据执行模式自动选择最优传输方式

#### 1.3 数据管理透明
- **自动数据分区**: `AutoDataManager` 自动处理IID/Non-IID数据分区
- **智能数据加载**: 根据执行模式自动选择数据加载策略
- **透明数据访问**: 统一的数据访问接口

### 2. 模块化架构

#### 2.1 分层设计
```
┌─────────────────────────────────────┐
│              API Layer              │  ← 用户接口层
├─────────────────────────────────────┤
│           Transparent Layer         │  ← 透明代理层
├─────────────────────────────────────┤
│           Automation Layer          │  ← 自动化层
├─────────────────────────────────────┤
│           Execution Layer           │  ← 执行层
├─────────────────────────────────────┤
│           Comm Layer                │  ← 通信层
├─────────────────────────────────────┤
│           Methods Layer             │  ← 算法层
├─────────────────────────────────────┤
│           Registry Layer            │  ← 注册层
└─────────────────────────────────────┘
```

#### 2.2 组件化设计
- **学习器 (Learner)**: 负责客户端本地训练逻辑
- **聚合器 (Aggregator)**: 负责服务器端模型聚合
- **评估器 (Evaluator)**: 负责模型评估和指标计算
- **训练器 (Trainer)**: 负责整体训练流程协调

### 3. 装饰器驱动

#### 3.1 组件注册
```python
@fedcl.learner
class MyLearner(AbstractLearner):
    pass

@fedcl.aggregator  
class MyAggregator(AbstractAggregator):
    pass

@fedcl.evaluator
class MyEvaluator(AbstractEvaluator):
    pass

@fedcl.trainer
class MyTrainer(AbstractFederationTrainer):
    pass
```

#### 3.2 配置驱动
```python
config = {
    "learner": "my_learner",
    "aggregator": "my_aggregator", 
    "evaluator": "my_evaluator",
    "trainer": "my_trainer"
}
```

## 总体架构

### 1. 目录结构

```
fedcl/
├── api/                    # API层 - 用户接口
│   ├── decorators.py      # 装饰器系统
│   ├── experiments.py     # 实验接口
│   └── trainer.py         # 训练器接口
├── transparent/           # 透明层 - 代理机制
│   ├── learner_proxy.py   # 学习器代理
│   ├── base_federation_engine.py  # 联邦引擎
│   └── mode_detector.py   # 模式检测器
├── automation/            # 自动化层 - 智能管理
│   ├── auto_data_manager.py  # 自动数据管理
│   ├── model_synchronizer.py # 模型同步
│   └── failure_recovery.py   # 故障恢复
├── execution/             # 执行层 - 执行引擎
│   ├── base_learner.py    # 学习器基类
│   ├── local_executor.py  # 本地执行器
│   ├── pseudo_executor.py # 伪联邦执行器
│   └── distributed_executor.py  # 分布式执行器
├── comm/                  # 通信层 - 通信管理
│   ├── transports/        # 传输协议
│   ├── transparent_communication.py  # 透明通信
│   └── message_types.py   # 消息类型
├── methods/               # 算法层 - 具体实现
│   ├── learners/          # 学习器实现
│   ├── aggregators/       # 聚合器实现
│   ├── evaluators/        # 评估器实现
│   └── trainers/          # 训练器实现
├── fl/                    # 联邦学习核心
│   └── abstract_trainer.py  # 训练器抽象类
└── registry/              # 注册层 - 组件管理
    └── registry.py        # 组件注册表
```

### 2. 核心组件

#### 2.1 学习器 (Learner)
```python
class AbstractLearner(ABC):
    """抽象学习器基类"""
    
    @abstractmethod
    async def train_epoch(self, **kwargs) -> Dict[str, Any]:
        """执行一个epoch的本地训练"""
        pass
    
    @abstractmethod
    async def evaluate(self, **kwargs) -> Dict[str, Any]:
        """执行本地评估"""
        pass
    
    @abstractmethod
    def get_model_weights(self) -> Dict[str, Any]:
        """获取模型权重"""
        pass
    
    @abstractmethod
    def set_model_weights(self, weights: Dict[str, Any]) -> None:
        """设置模型权重"""
        pass
```

#### 2.2 聚合器 (Aggregator)
```python
class AbstractAggregator(ABC):
    """抽象聚合器基类"""
    
    @abstractmethod
    def aggregate(self, client_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """聚合客户端结果"""
        pass
```

#### 2.3 训练器 (Trainer)
```python
class AbstractFederationTrainer(ABC):
    """抽象联邦训练器基类"""
    
    @abstractmethod
    async def train(self, **kwargs) -> TrainingResult:
        """执行联邦训练"""
        pass
    
    @abstractmethod
    async def evaluate(self, **kwargs) -> EvaluationResult:
        """执行联邦评估"""
        pass
```

### 3. 执行模式

#### 3.1 本地模拟模式
- **特点**: 单机多进程模拟联邦学习
- **适用场景**: 算法验证、快速原型
- **优势**: 开发效率高，调试方便

#### 3.2 伪联邦模式
- **特点**: 单机多进程，真实网络通信
- **适用场景**: 通信协议测试、性能基准
- **优势**: 真实通信，单机部署

#### 3.3 真联邦模式
- **特点**: 多机分布式，真实网络通信
- **适用场景**: 生产环境、大规模部署
- **优势**: 真实分布式，可扩展性强

## 使用说明

### 1. 快速开始

#### 1.1 一行代码启动
```python
import fedcl

# 使用默认配置启动联邦学习
result = fedcl.train(
    dataset="mnist",
    num_clients=3,
    rounds=10
)
```

#### 1.2 配置驱动启动
```python
config = {
    "dataset": "mnist",
    "num_clients": 3,
    "rounds": 10,
    "learner": "default",
    "aggregator": "fedavg",
    "evaluator": "prototype"
}

result = fedcl.train_from_config(config)
```

### 2. 自定义组件

#### 2.1 自定义学习器
```python
import torch.nn as nn
from fedcl.execution.base_learner import AbstractLearner
from fedcl.api import learner

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )
        self.criterion = nn.CrossEntropyLoss()
    
    def forward(self, x):
        return self.network(x)
    
    def forward_with_loss(self, x, target):
        output = self.forward(x)
        loss = self.criterion(output, target)
        return output, loss

@learner
class MyLearner(AbstractLearner):
    def __init__(self, client_id: str, config: Dict[str, Any]):
        super().__init__(client_id, config)
        self.model = MyModel()
        self.optimizer = torch.optim.Adam(self.model.parameters())
    
    async def train_epoch(self, **kwargs):
        # 实现训练逻辑
        pass
    
    async def evaluate(self, **kwargs):
        # 实现评估逻辑
        pass
    
    def get_model_weights(self):
        return {k: v.cpu().clone() for k, v in self.model.state_dict().items()}
    
    def set_model_weights(self, weights):
        self.model.load_state_dict(weights)
```

#### 2.2 自定义聚合器
```python
from fedcl.api import aggregator

@aggregator
class MyAggregator(AbstractAggregator):
    def aggregate(self, client_results):
        # 实现聚合逻辑
        pass
```

#### 2.3 自定义训练器
```python
from fedcl.api import trainer

@trainer
class MyTrainer(AbstractFederationTrainer):
    async def train(self, **kwargs):
        # 实现训练流程
        pass
    
    async def evaluate(self, **kwargs):
        # 实现评估流程
        pass
```

### 3. 高级用法

#### 3.1 实验管理
```python
# 快速实验
result = fedcl.quick_experiment(
    experiment_name="mnist_fedavg",
    configs=[
        {"aggregator": "fedavg", "rounds": 10},
        {"aggregator": "fedprox", "rounds": 10},
    ]
)
```

#### 3.2 组件管理
```python
# 列出所有组件
components = fedcl.list_components()

# 获取组件信息
info = fedcl.get_component_info("my_learner")

# 清除注册表
fedcl.clear_registry()
```

### 4. 配置详解

#### 4.1 基础配置
```python
config = {
    # 数据集配置
    "dataset": "mnist",
    "data_path": "./data",
    "batch_size": 32,
    
    # 联邦学习配置
    "num_clients": 3,
    "rounds": 10,
    "local_epochs": 2,
    "client_selection_ratio": 1.0,
    
    # 组件配置
    "learner": "default",
    "aggregator": "fedavg",
    "evaluator": "prototype",
    
    # 模型配置
    "model": {
        "type": "mlp",
        "input_dim": 784,
        "hidden_dims": [128, 64],
        "output_dim": 10
    },
    
    # 优化器配置
    "optimizer": {
        "type": "adam",
        "learning_rate": 0.01
    }
}
```

#### 4.2 高级配置
```python
config = {
    # 执行模式配置
    "execution": {
        "mode": "auto",  # auto, local, pseudo, distributed
        "num_workers": 4,
        "timeout": 300
    },
    
    # 通信配置
    "communication": {
        "transport": "auto",  # auto, memory, process, network
        "host": "localhost",
        "port": 8080
    },
    
    # 数据分区配置
    "data_partition": {
        "type": "iid",  # iid, non_iid_label, non_iid_quantity
        "alpha": 0.5  # 用于non_iid_label
    }
}
```

## 最佳实践

### 1. 模型设计
- 实现 `forward_with_loss` 方法，支持内置损失计算
- 使用 `nn.Module` 作为基类
- 在模型中定义 `criterion` 属性

### 2. 学习器设计
- 继承 `AbstractLearner`
- 实现所有抽象方法
- 使用 `@fedcl.learner` 装饰器注册

### 3. 配置管理
- 使用YAML文件管理配置
- 分离开发和生产配置
- 使用环境变量覆盖敏感信息

### 4. 错误处理
- 实现适当的异常处理
- 使用日志记录关键信息
- 提供有意义的错误消息

### 5. 性能优化
- 选择合适的执行模式
- 优化数据传输
- 使用适当的批处理大小

## 故障排除

### 1. 常见问题

#### 1.1 组件未注册
```
ValueError: 学习器 'my_learner' 未注册
```
**解决方案**: 确保使用 `@fedcl.learner` 装饰器注册组件

#### 1.2 配置错误
```
ValueError: 配置项 'dataset' 缺失
```
**解决方案**: 检查配置文件，确保所有必需项都存在

#### 1.3 模型权重不匹配
```
RuntimeError: size mismatch
```
**解决方案**: 确保所有客户端的模型结构一致

### 2. 调试技巧

#### 2.1 启用调试日志
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

#### 2.2 使用本地模式
```python
config = {
    "execution": {"mode": "local"},
    # 其他配置...
}
```

#### 2.3 检查组件注册
```python
components = fedcl.list_components()
print(components)
```

## 扩展开发

### 1. 添加新组件

#### 1.1 新学习器
1. 继承 `AbstractLearner`
2. 实现抽象方法
3. 使用 `@fedcl.learner` 装饰器
4. 在配置中指定使用

#### 1.2 新聚合器
1. 继承 `AbstractAggregator`
2. 实现 `aggregate` 方法
3. 使用 `@fedcl.aggregator` 装饰器

#### 1.3 新评估器
1. 继承 `AbstractEvaluator`
2. 实现 `evaluate` 方法
3. 使用 `@fedcl.evaluator` 装饰器

### 2. 自定义传输协议

#### 2.1 实现传输类
```python
class MyTransport(AbstractTransport):
    def send(self, message):
        # 实现发送逻辑
        pass
    
    def receive(self):
        # 实现接收逻辑
        pass
```

#### 2.2 注册传输协议
```python
from fedcl.comm import register_transport
register_transport("my_protocol", MyTransport)
```

## 总结

FedCL框架通过透明化设计、模块化架构和装饰器驱动，实现了以下目标：

1. **开发效率**: 一行代码启动联邦学习
2. **透明性**: 用户无需关心底层实现细节
3. **可扩展性**: 支持自定义组件和算法
4. **生产就绪**: 支持多种执行模式和部署方式
5. **易用性**: 配置驱动，装饰器注册

通过这个框架，用户可以专注于联邦学习算法的设计和实现，而不用担心分布式系统的复杂性。
