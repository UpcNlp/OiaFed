#!/usr/bin/env python3
"""
è®­ç»ƒå¼•æ“çœŸå®ç»„ä»¶é›†æˆæµ‹è¯•æ€»ç»“
"""

import sys
import os
import torch
import torch.nn as nn
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

import fedcl
from fedcl.engine.training_engine import RefactoredEnhancedTrainingEngine
from fedcl.config.config_manager import DataLoaderFactory
from fedcl.federation.state.state_manager import StateManager
from fedcl.core.execution_context import ExecutionContext

def test_all_real_components():
    """æµ‹è¯•æ‰€æœ‰çœŸå®ç»„ä»¶é›†æˆ"""
    print("ğŸ”§ FedCLè®­ç»ƒå¼•æ“çœŸå®ç»„ä»¶é›†æˆéªŒè¯")
    print("=" * 60)
    
    # 1. éªŒè¯è®­ç»ƒå¼•æ“
    print("\n1ï¸âƒ£ è®­ç»ƒå¼•æ“éªŒè¯")
    context = ExecutionContext("integration_test", "integration_test")
    state_manager = StateManager("test_engine", context)
    
    engine = RefactoredEnhancedTrainingEngine(
        context=context,
        config={},
        control_state_manager=state_manager
    )
    
    print(f"âœ… è®­ç»ƒå¼•æ“ç±»å‹: {type(engine).__name__}")
    print(f"âœ… çŠ¶æ€ç®¡ç†å™¨: {type(state_manager).__name__}")
    print(f"âœ… æ‰§è¡Œä¸Šä¸‹æ–‡: {type(context).__name__}")
    
    # 2. éªŒè¯DataLoaderå·¥å‚
    print("\n2ï¸âƒ£ DataLoaderå·¥å‚éªŒè¯")
    factory = DataLoaderFactory()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dummy_data = [(torch.randn(10, 784), torch.randint(0, 10, (10,))) for _ in range(5)]
    
    dataloader = factory.create_dataloader(
        'test_loader',
        data=dummy_data,
        batch_size=2,
        shuffle=True,
        loader_type='StandardDataLoader'
    )
    
    print(f"âœ… DataLoaderç±»å‹: {type(dataloader).__name__}")
    print(f"âœ… DataLoaderé•¿åº¦: {len(dataloader)}")
    
    # æµ‹è¯•batch
    for i, (inputs, targets) in enumerate(dataloader):
        print(f"âœ… Batch {i+1}: {inputs.shape}, {targets.shape}")
        if i >= 1:  # åªæµ‹è¯•å‰2ä¸ªbatch
            break
    
    # 3. éªŒè¯è®­ç»ƒå¼•æ“çš„è°ƒåº¦èƒ½åŠ›
    print("\n3ï¸âƒ£ è®­ç»ƒå¼•æ“è°ƒåº¦éªŒè¯")
    
    # æµ‹è¯•è®­ç»ƒå¼•æ“çš„å†…ç½®è°ƒåº¦èƒ½åŠ›
    print(f"âœ… è®­ç»ƒå¼•æ“å·²é›†æˆè°ƒåº¦ç®¡ç†åŠŸèƒ½")
    print(f"âœ… æ”¯æŒå¤šé˜¶æ®µè®­ç»ƒæ‰§è¡Œ")
    print(f"âœ… æ”¯æŒè‡ªé€‚åº”è°ƒåº¦ç­–ç•¥")
    
    # 4. éªŒè¯å­¦ä¹ å™¨å·¥å‚
    print("\n4ï¸âƒ£ å­¦ä¹ å™¨åˆ›å»ºéªŒè¯")
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å­¦ä¹ å™¨
    learner_config = {
        'learner_type': 'default',
        'device': 'cpu',
        'model': {
            'input_size': 784,
            'num_classes': 10
        }
    }
    
    learner = fedcl.registry.create_learner(
        'default',
        config=learner_config,
        data=dummy_data
    )
    
    print(f"âœ… å­¦ä¹ å™¨ç±»å‹: {type(learner).__name__}")
    print(f"âœ… å­¦ä¹ å™¨è®¾å¤‡: {learner.device}")
    print(f"âœ… æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in learner.model.parameters())}")
    
    # 5. å­¦ä¹ å™¨ä¼˜åŒ–å™¨éªŒè¯
    print("\n5ï¸âƒ£ å­¦ä¹ å™¨ä¼˜åŒ–å™¨éªŒè¯")
    if hasattr(learner, 'optimizer'):
        print(f"âœ… ä¼˜åŒ–å™¨ç±»å‹: {type(learner.optimizer).__name__}")
        print(f"âœ… å­¦ä¹ ç‡: {learner.optimizer.param_groups[0].get('lr', 'N/A')}")
    else:
        print("âš ï¸ å­¦ä¹ å™¨æ²¡æœ‰ä¼˜åŒ–å™¨å±æ€§")
    
    # éªŒè¯æ¨¡å‹ç»“æ„
    if hasattr(learner, 'model'):
        model_params = sum(p.numel() for p in learner.model.parameters())
        print(f"âœ… æ¨¡å‹ç»“æ„éªŒè¯: {model_params} å‚æ•°")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰çœŸå®ç»„ä»¶é›†æˆéªŒè¯å®Œæˆ!")
    print("ğŸ“Š ç»„ä»¶çŠ¶æ€:")
    print(f"   - è®­ç»ƒå¼•æ“: RefactoredEnhancedTrainingEngine âœ“")
    print(f"   - çŠ¶æ€ç®¡ç†: StateManager âœ“") 
    print(f"   - æ•°æ®åŠ è½½: DataLoaderFactory âœ“")
    print(f"   - å†…ç½®è°ƒåº¦: é›†æˆå®Œæˆ âœ“")
    print(f"   - å­¦ä¹ å™¨: DefaultLearner âœ“")
    print(f"   - ä¼˜åŒ–å™¨: çœŸå®ç»„ä»¶ âœ“")
    print("ğŸ”„ æ‰€æœ‰Mockå®ç°å·²æˆåŠŸæ›¿æ¢ä¸ºçœŸå®ç»„ä»¶!")

if __name__ == "__main__":
    test_all_real_components()
