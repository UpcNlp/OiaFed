"""
ä½¿ç”¨MLflowè¿è¡Œæ‰¹é‡å®éªŒ
examples/run_batch_experiments_mlflow.py

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ MLflow åç«¯è¿›è¡Œå®éªŒè·Ÿè¸ªå’Œå¯è§†åŒ–

ä½¿ç”¨æ–¹æ³•:
    # 1. å®‰è£… MLflow
    pip install mlflow

    # 2. è¿è¡Œæ‰¹é‡å®éªŒ
    python examples/run_batch_experiments_mlflow.py --mode comparison

    # 3. æŸ¥çœ‹MLflow UI
    mlflow ui --backend-store-uri experiments/mlruns
    # æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:5000
"""

import asyncio
import sys
import os
from pathlib import Path

# åœ¨å¯¼å…¥ fedcl ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œåˆ‡æ¢åˆ° MLflow åç«¯
os.environ['FEDCL_RECORDER_BACKEND'] = 'mlflow'

# æ·»åŠ é¡¹ç›®è·¯å¾„
root = Path(__file__).parent.parent
sys.path.insert(0, str(root))

from fedcl.experiment import (
    BatchExperimentRunner,
    create_algorithm_comparison_experiments,
    create_grid_search_experiments,
    Recorder  # ä¼šè‡ªåŠ¨ä½¿ç”¨ MLflow åç«¯
)


async def algorithm_comparison():
    """ç®—æ³•å¯¹æ¯”å®éªŒ - ä½¿ç”¨MLflow"""
    print("=" * 80)
    print("ç®—æ³•å¯¹æ¯”å®éªŒ - MLflow ç‰ˆæœ¬")
    print("=" * 80)

    # åˆ›å»ºç®—æ³•å¯¹æ¯”å®éªŒé…ç½®
    experiments = create_algorithm_comparison_experiments(
        base_name="mnist_iid_mlflow",
        algorithms=['fedavg', 'fedprox', 'scaffold'],
        common_config={
            'learning_rate': 0.01,
            'batch_size': 32,
            'max_rounds': 3  # å¿«é€Ÿæ¼”ç¤ºï¼Œä»…3è½®
        }
    )

    print(f"\nåˆ›å»ºäº† {len(experiments)} ç»„å®éªŒ:")
    for exp in experiments:
        print(f"  - {exp['name']}")

    # è¿è¡Œå®éªŒï¼ˆä¸²è¡Œï¼‰
    runner = BatchExperimentRunner(
        base_config="configs/distributed/experiments/iid/",
        experiment_variants=experiments
    )

    print("\nå¼€å§‹è¿è¡Œå®éªŒ...")
    results = await runner.run_all(parallel=False)

    # è¾“å‡ºç»“æœæ‘˜è¦
    print_results_summary(results)

    print("\n" + "=" * 80)
    print("âœ“ å®éªŒå®Œæˆï¼")
    print("=" * 80)
    print("\næŸ¥çœ‹MLflow UI:")
    print("  cd /home/nlp/ct/projects/MOE-FedCL")
    print("  mlflow ui --backend-store-uri experiments/mlruns")
    print("  ç„¶åè®¿é—®: http://localhost:5000")
    print("\nåœ¨UIä¸­ä½ å¯ä»¥:")
    print("  - å¯¹æ¯”ä¸åŒç®—æ³•çš„å‡†ç¡®ç‡æ›²çº¿")
    print("  - æŸ¥çœ‹æ¯è½®è®­ç»ƒçš„è¯¦ç»†æŒ‡æ ‡")
    print("  - ç­›é€‰å’Œæ’åºå®éªŒç»“æœ")
    print("  - ä¸‹è½½å®éªŒæ•°æ®å’Œæ¨¡å‹")


async def grid_search():
    """ç½‘æ ¼æœç´¢å®éªŒ - ä½¿ç”¨MLflow"""
    print("=" * 80)
    print("ç½‘æ ¼æœç´¢å®éªŒ - MLflow ç‰ˆæœ¬")
    print("=" * 80)

    # åˆ›å»ºç½‘æ ¼æœç´¢å®éªŒ
    experiments = create_grid_search_experiments(
        base_name="mnist_grid_search_mlflow",
        param_grid={
            'learning_rate': [0.01, 0.001],
            'batch_size': [32, 64],
            'local_epochs': [1, 3]
        }
    )

    print(f"\nåˆ›å»ºäº† {len(experiments)} ç»„ç½‘æ ¼æœç´¢å®éªŒ")

    runner = BatchExperimentRunner(
        base_config="configs/distributed/experiments/iid/",
        experiment_variants=experiments
    )

    # å¹¶è¡Œè¿è¡Œï¼ˆæœ€å¤š2ä¸ªåŒæ—¶ï¼‰
    print("\nå¼€å§‹å¹¶è¡Œè¿è¡Œå®éªŒï¼ˆæœ€å¤š2ä¸ªåŒæ—¶ï¼‰...")
    results = await runner.run_all(parallel=True, max_parallel=2)

    # æ‰¾å‡ºæœ€ä½³é…ç½®
    successful = [r for r in results if r['status'] == 'success']
    if successful:
        best = max(successful, key=lambda x: x.get('accuracy', 0))
        print(f"\nğŸ† æœ€ä½³é…ç½®: {best['name']}")
        print(f"   å‡†ç¡®ç‡: {best['accuracy']:.4f}")

    print_results_summary(results)

    print("\næŸ¥çœ‹MLflow UIè¿›è¡Œæ·±å…¥åˆ†æ:")
    print("  mlflow ui --backend-store-uri experiments/mlruns")


def print_results_summary(results):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    print("\n" + "=" * 80)
    print("å®éªŒç»“æœæ‘˜è¦")
    print("=" * 80)

    successful = [r for r in results if r['status'] == 'success']
    failed = [r for r in results if r['status'] == 'failed']

    print(f"\næ€»è®¡: {len(results)} ç»„å®éªŒ")
    print(f"æˆåŠŸ: {len(successful)} ç»„")
    print(f"å¤±è´¥: {len(failed)} ç»„")

    if successful:
        print("\næˆåŠŸçš„å®éªŒ:")
        print(f"{'å®éªŒåç§°':<50} {'å‡†ç¡®ç‡':<10} {'è½®æ•°':<8} {'è€—æ—¶(s)':<10}")
        print("-" * 80)
        for r in successful:
            name = r['name'][:48]
            acc = r.get('accuracy', 0)
            rounds = r.get('rounds', 'N/A')
            duration = r.get('duration', 0)
            print(f"{name:<50} {acc:.4f}    {rounds:<8} {duration:.2f}")

        # æ‰¾å‡ºæœ€ä½³
        best = max(successful, key=lambda x: x.get('accuracy', 0))
        print(f"\nğŸ† æœ€ä½³ç»“æœ: {best['name']}")
        print(f"   å‡†ç¡®ç‡: {best['accuracy']:.4f}")

    if failed:
        print("\nå¤±è´¥çš„å®éªŒ:")
        for r in failed:
            print(f"âœ— {r['name']}: {r.get('error', 'Unknown error')}")


async def quick_demo():
    """å¿«é€Ÿæ¼”ç¤º - å•ä¸ªå®éªŒ"""
    print("=" * 80)
    print("MLflow å¿«é€Ÿæ¼”ç¤º - å•ä¸ªå®éªŒ")
    print("=" * 80)

    experiments = [{
        'name': 'mlflow_demo_fedavg',
        'overrides': {'trainer.name': 'fedavg', 'learning_rate': 0.01}
    }]

    runner = BatchExperimentRunner(
        base_config="configs/distributed/experiments/iid/",
        experiment_variants=experiments
    )

    print("\nè¿è¡Œå•ä¸ªå®éªŒè¿›è¡Œæ¼”ç¤º...")
    results = await runner.run_all(parallel=False)

    print_results_summary(results)

    print("\næç¤º: è¿è¡Œ 'mlflow ui --backend-store-uri experiments/mlruns' æŸ¥çœ‹è¯¦ç»†ç»“æœ")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨MLflowè¿è¡Œæ‰¹é‡å®éªŒ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

1. ç®—æ³•å¯¹æ¯”:
   python examples/run_batch_experiments_mlflow.py --mode comparison

2. ç½‘æ ¼æœç´¢:
   python examples/run_batch_experiments_mlflow.py --mode grid_search

3. å¿«é€Ÿæ¼”ç¤º:
   python examples/run_batch_experiments_mlflow.py --mode demo

æŸ¥çœ‹ç»“æœ:
   mlflow ui --backend-store-uri experiments/mlruns
   è®¿é—®: http://localhost:5000
        """
    )

    parser.add_argument('--mode',
                       choices=['comparison', 'grid_search', 'demo'],
                       default='demo',
                       help='å®éªŒæ¨¡å¼')

    args = parser.parse_args()

    # æ£€æŸ¥ MLflow æ˜¯å¦å®‰è£…
    try:
        import mlflow
        print(f"âœ“ MLflow ç‰ˆæœ¬: {mlflow.__version__}")
    except ImportError:
        print("âœ— MLflow æœªå®‰è£…!")
        print("  è¯·è¿è¡Œ: pip install mlflow")
        sys.exit(1)

    # è¿è¡Œå¯¹åº”çš„å®éªŒ
    if args.mode == 'comparison':
        await algorithm_comparison()
    elif args.mode == 'grid_search':
        await grid_search()
    else:
        await quick_demo()


if __name__ == "__main__":
    asyncio.run(main())
