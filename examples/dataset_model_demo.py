"""
æ•°æ®é›†å’Œæ¨¡å‹ç®¡ç†ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
examples/dataset_model_demo.py

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ï¼š
1. @dataset è£…é¥°å™¨æ³¨å†Œæ•°æ®é›†
2. @model è£…é¥°å™¨æ³¨å†Œæ¨¡å‹
3. æ•°æ®åˆ’åˆ†ç­–ç•¥ï¼ˆIID/Non-IIDï¼‰
4. ä»æ³¨å†Œè¡¨è·å–ç»„ä»¶
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torchvision import datasets, transforms
from typing import Dict, Any

# å¯¼å…¥è£…é¥°å™¨å’ŒåŸºç±»
from fedcl.api.decorators import dataset, model
from fedcl.api.registry import registry

# ç›´æ¥å¯¼å…¥ï¼Œé¿å…è§¦å‘ methods çš„å®Œæ•´åˆå§‹åŒ–
import sys
sys.path.insert(0, '/home/nlp/ct/projects/MOE-FedCL')
from fedcl.methods.datasets.base import FederatedDataset
from fedcl.methods.models.base import FederatedModel, count_parameters, print_model_summary


# ==================== 1. å®šä¹‰å¹¶æ³¨å†Œæ•°æ®é›† ====================

@dataset(
    name='mnist_federated',
    description='MNISTè”é‚¦å­¦ä¹ æ•°æ®é›†',
    version='1.0',
    dataset_type='image_classification',
    num_classes=10
)
class MNISTFederated(FederatedDataset):
    """MNISTè”é‚¦æ•°æ®é›†å®ç°"""

    def __init__(self, root: str = './data', train: bool = True, download: bool = True):
        super().__init__(root, train, download)

        # æ•°æ®è½¬æ¢
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])

        # åŠ è½½MNISTæ•°æ®é›†
        self.dataset = datasets.MNIST(
            root=root,
            train=train,
            download=download,
            transform=transform
        )

        # è®¾ç½®å±æ€§
        self.num_classes = 10
        self.input_shape = (1, 28, 28)

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'dataset_name': 'MNIST',
            'num_samples': len(self.dataset),
            'num_classes': self.num_classes,
            'input_shape': self.input_shape,
            'train': self.train,
        }


# ==================== 2. å®šä¹‰å¹¶æ³¨å†Œæ¨¡å‹ ====================

@model(
    name='simple_cnn',
    description='ç®€å•çš„CNNåˆ†ç±»æ¨¡å‹',
    version='1.0',
    task='classification',
    input_shape=(1, 28, 28),
    output_shape=(10,)
)
class SimpleCNN(nn.Module):
    """ç®€å•çš„CNNæ¨¡å‹"""

    def __init__(self, num_classes: int = 10):
        super().__init__()

        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 7 * 7, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


@model(
    name='advanced_cnn',
    description='å¸¦æœ‰FederatedModelåŠŸèƒ½çš„é«˜çº§CNN',
    version='1.0',
    task='classification'
)
class AdvancedCNN(FederatedModel):
    """ç»§æ‰¿FederatedModelçš„é«˜çº§CNNï¼ˆå¯é€‰ï¼‰"""

    def __init__(self, num_classes: int = 10):
        super().__init__()

        # è®¾ç½®å…ƒæ•°æ®
        self.set_metadata(
            task_type='classification',
            input_shape=(1, 28, 28),
            output_shape=(num_classes,)
        )

        # å®šä¹‰ç½‘ç»œç»“æ„
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, num_classes)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.dropout(self.relu(self.fc1(x)))
        x = self.fc2(x)
        return x


# ==================== 3. ä½¿ç”¨ç¤ºä¾‹ ====================

def demo_dataset_partitioning():
    """æ¼”ç¤ºæ•°æ®é›†åˆ’åˆ†"""
    print("=" * 80)
    print("æ•°æ®é›†åˆ’åˆ†æ¼”ç¤º")
    print("=" * 80)

    # ä»æ³¨å†Œè¡¨è·å–æ•°æ®é›†ç±»
    MNISTFedCls = registry.get_dataset('mnist_federated')
    fed_dataset = MNISTFedCls(root='./data', train=True, download=True)

    print(f"\næ•°æ®é›†ä¿¡æ¯: {fed_dataset.get_statistics()}")

    # æ¼”ç¤º1ï¼šIIDåˆ’åˆ†
    print("\n--- 1. IIDåˆ’åˆ†ï¼ˆå‡åŒ€éšæœºï¼‰---")
    client_datasets_iid = fed_dataset.partition(num_clients=5, strategy='iid')

    for client_id, dataset in client_datasets_iid.items():
        print(f"  Client {client_id}: {len(dataset)} æ ·æœ¬")
        # æŸ¥çœ‹ç±»åˆ«åˆ†å¸ƒ
        dist = fed_dataset.get_class_distribution(dataset.indices)
        print(f"    ç±»åˆ«åˆ†å¸ƒ: {dist}")

    # æ¼”ç¤º2ï¼šLabel Skew Non-IID
    print("\n--- 2. Label Skew Non-IIDï¼ˆæ¯å®¢æˆ·ç«¯2ä¸ªç±»åˆ«ï¼‰---")
    client_datasets_label = fed_dataset.partition(
        num_clients=5,
        strategy='non_iid_label',
        labels_per_client=2
    )

    for client_id, dataset in client_datasets_label.items():
        print(f"  Client {client_id}: {len(dataset)} æ ·æœ¬")
        dist = fed_dataset.get_class_distribution(dataset.indices)
        print(f"    ç±»åˆ«åˆ†å¸ƒ: {dist}")

    # æ¼”ç¤º3ï¼šDirichlet Non-IID
    print("\n--- 3. Dirichlet Non-IID (alpha=0.5) ---")
    client_datasets_dir = fed_dataset.partition(
        num_clients=5,
        strategy='dirichlet',
        alpha=0.5
    )

    for client_id, dataset in client_datasets_dir.items():
        print(f"  Client {client_id}: {len(dataset)} æ ·æœ¬")
        dist = fed_dataset.get_class_distribution(dataset.indices)
        print(f"    ç±»åˆ«åˆ†å¸ƒ: {dist}")


def demo_model_usage():
    """æ¼”ç¤ºæ¨¡å‹ä½¿ç”¨"""
    print("\n" + "=" * 80)
    print("æ¨¡å‹ä½¿ç”¨æ¼”ç¤º")
    print("=" * 80)

    # ä»æ³¨å†Œè¡¨è·å–æ¨¡å‹ç±»
    SimpleCNNCls = registry.get_model('simple_cnn')
    AdvancedCNNCls = registry.get_model('advanced_cnn')

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    simple_model = SimpleCNNCls(num_classes=10)
    advanced_model = AdvancedCNNCls(num_classes=10)

    print("\n--- Simple CNN ---")
    print(f"å‚æ•°æ•°é‡: {count_parameters(simple_model):,}")
    print_model_summary(simple_model, input_shape=(1, 28, 28))

    print("\n--- Advanced CNN (FederatedModel) ---")
    print(f"å‚æ•°æ•°é‡: {advanced_model.get_param_count():,}")
    print(f"æ¨¡å‹å¤§å°: {advanced_model.get_model_size('MB'):.2f} MB")
    print(f"æƒé‡èŒƒæ•°: {advanced_model.get_weight_norm():.4f}")
    print(advanced_model.summary(input_shape=(1, 28, 28)))


def demo_registry_info():
    """æ¼”ç¤ºæ³¨å†Œè¡¨ä¿¡æ¯æŸ¥è¯¢"""
    print("\n" + "=" * 80)
    print("æ³¨å†Œè¡¨ä¿¡æ¯æŸ¥è¯¢")
    print("=" * 80)

    # åˆ—å‡ºæ‰€æœ‰ç»„ä»¶
    all_components = registry.list_all_components()
    print("\nå·²æ³¨å†Œçš„ç»„ä»¶:")
    for comp_type, names in all_components.items():
        if names:  # åªæ˜¾ç¤ºéç©ºçš„
            print(f"  {comp_type}: {names}")

    # ç»„ä»¶æ•°é‡ç»Ÿè®¡
    counts = registry.get_component_count()
    print("\nç»„ä»¶æ•°é‡ç»Ÿè®¡:")
    for comp_type, count in counts.items():
        print(f"  {comp_type}: {count}")

    # æ£€æŸ¥ç»„ä»¶æ˜¯å¦å­˜åœ¨
    print("\nç»„ä»¶å­˜åœ¨æ€§æ£€æŸ¥:")
    print(f"  mnist_federated (dataset): {registry.has_component('mnist_federated', 'dataset')}")
    print(f"  simple_cnn (model): {registry.has_component('simple_cnn', 'model')}")
    print(f"  non_existent (dataset): {registry.has_component('non_existent', 'dataset')}")


if __name__ == '__main__':
    print("\nğŸš€ MOE-FedCL æ•°æ®é›†å’Œæ¨¡å‹ç®¡ç†ç³»ç»Ÿæ¼”ç¤º\n")

    # 1. æ•°æ®é›†åˆ’åˆ†æ¼”ç¤º
    demo_dataset_partitioning()

    # 2. æ¨¡å‹ä½¿ç”¨æ¼”ç¤º
    demo_model_usage()

    # 3. æ³¨å†Œè¡¨ä¿¡æ¯æŸ¥è¯¢
    demo_registry_info()

    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
