# mnist_process_demo.py
import asyncio
import multiprocessing as mp
import os
import sys
import time
import json
from typing import Dict, Any, List

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms

# æ·»åŠ è·¯å¾„ï¼ˆæ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„è°ƒæ•´ï¼‰
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from fedcl.types import (
    TrainingResult,
    EvaluationResult,
    ModelData,
    RoundResult,
)
from fedcl.utils.auto_logger import setup_auto_logging
from fedcl.federation.server import FederationServer
from fedcl.federation.client import FederationClient
from fedcl.learner.base_learner import BaseLearner
from fedcl.trainer.base_trainer import BaseTrainer
from fedcl.federation.coordinator import FederationCoordinator
from fedcl.types import FederationConfig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. å®šä¹‰æ¨¡å‹ï¼ˆç®€å• CNNï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MNISTNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2)
        self.fc1 = nn.Linear(8 * 14 * 14, 32)
        self.fc2 = nn.Linear(32, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return torch.log_softmax(x, dim=1)


# å°† PyTorch æ¨¡å‹çš„å‚æ•°ï¼ˆå³ state_dictï¼‰è½¬æ¢ä¸º ModelDataï¼ˆå­—å…¸ï¼Œå€¼ä¸ºåµŒå¥—åˆ—è¡¨ï¼‰
def model_to_state_dict(model: nn.Module) -> ModelData:
    return {k: v.cpu().numpy().tolist() for k, v in model.state_dict().items()}

# å°†ä¸€ä¸ª åºåˆ—åŒ–åçš„æ¨¡å‹å‚æ•°å­—å…¸ï¼ˆ ModelDataï¼‰é‡æ–°åŠ è½½å›ä¸€ä¸ª PyTorch æ¨¡å‹å®ä¾‹ä¸­
def state_dict_to_model(state_dict: ModelData, model_class=MNISTNet) -> nn.Module:
    model = model_class()   # åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹ï¼ˆç»“æ„å¿…é¡»ä¸€è‡´ï¼‰
    new_state = {}
    for k, v in state_dict.items():
        new_state[k] = torch.tensor(v)   # å°† list è½¬å› Tensor
    model.load_state_dict(new_state)
    return model


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. å®¢æˆ·ç«¯ Learnerï¼ˆçœŸå®è®­ç»ƒ MNISTï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MNISTLearner(BaseLearner):
    def __init__(self, client_id: str, config: Dict[str, Any], logger=None):
        super().__init__(client_id, config, logger)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = MNISTNet().to(self.device)
        self._local_model = model_to_state_dict(self.model)

        # åŠ è½½ MNIST æ•°æ®ï¼ˆæ¨¡æ‹Ÿé IID åˆ’åˆ†ï¼šæ¯ä¸ªå®¢æˆ·ç«¯åªå–ä¸€éƒ¨åˆ†ï¼‰
        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        full_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)

        # ç®€å•åˆ’åˆ†ï¼šclient_1 ç”¨ 0-29999ï¼Œclient_2 ç”¨ 30000-59999ï¼ˆå®é™…å¯æ›´å¤æ‚ï¼‰
        total = len(full_dataset)
        start = int(client_id.split('_')[-1]) - 1  # client_1 â†’ 0, client_2 â†’ 1
        indices = list(range(start * total // 2, (start + 1) * total // 2))
        self.train_dataset = Subset(full_dataset, indices)
        self.train_loader = DataLoader(self.train_dataset, batch_size=32, shuffle=True)
        self.local_samples = len(self.train_dataset)

        self.test_dataset = datasets.MNIST('./data', train=False, transform=transform)
        self.test_loader = DataLoader(self.test_dataset, batch_size=32, shuffle=False)

    async def train(self, training_params: Dict[str, Any]) -> TrainingResult:
        # æ¥æ”¶å¹¶åŠ è½½å…¨å±€æ¨¡å‹
        if "global_model" in training_params:
            global_state = training_params["global_model"]
            self.model = state_dict_to_model(global_state).to(self.device)
            self._local_model = global_state

        # è§£æè®­ç»ƒè¶…å‚æ•°
        epochs = training_params.get("epochs", 1)
        lr = training_params.get("learning_rate", 0.01)

        # è®¾ç½®è®­ç»ƒæ¨¡å¼ä¸ä¼˜åŒ–å™¨
        self.model.train()  # è®­ç»ƒæ¨¡å¼
        optimizer = optim.SGD(self.model.parameters(), lr=lr)
        criterion = nn.NLLLoss()

        # æœ¬åœ°è®­ç»ƒå¾ªç¯
        total_loss = 0.0
        correct = 0
        start_time = time.time()  # å¼€å§‹è®¡æ—¶
        for _ in range(epochs):
            for data, target in self.train_loader:
                data, target = data.to(self.device), target.to(self.device)
                optimizer.zero_grad()
                output = self.model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        training_time = time.time() - start_time    # ç»“æŸè®¡æ—¶

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        avg_loss = total_loss / (epochs * len(self.train_loader))
        accuracy = correct / self.local_samples

        #ä¿å­˜å¹¶è¿”å›è®­ç»ƒç»“æœ
        self._local_model = model_to_state_dict(self.model)

        raw_json = json.dumps(self._local_model)
        print(f"[DEBUG] æ¨¡å‹ JSON å¤§å°: {len(raw_json) / 1024:.1f} KB")

        return TrainingResult(
            client_id=self.client_id,
            success=True,
            loss=avg_loss,
            accuracy=accuracy,
            samples_count=self.local_samples,
            training_time=training_time,
            model_update=self._local_model
        )

    async def evaluate(self, evaluation_params: Dict[str, Any]) -> EvaluationResult:
        self.model.eval()   # è¯„ä¼°æ¨¡å¼
        test_loss = 0
        correct = 0
        criterion = nn.NLLLoss()
        start_time = time.time()  # å¼€å§‹è®¡æ—¶
        with torch.no_grad():
            for data, target in self.test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                test_loss += criterion(output, target).item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()

        evaluation_time = time.time() - start_time

        avg_loss = test_loss / len(self.test_loader)
        accuracy = correct / len(self.test_dataset)

        return EvaluationResult(
            client_id=self.client_id,
            success=True,
            loss=avg_loss,
            accuracy=accuracy,
            samples_count=len(self.test_dataset),
            evaluation_time=evaluation_time
        )

    async def get_local_model(self) -> ModelData:
        return self._local_model

    async def set_local_model(self, model_data: ModelData) -> bool:
        self.model = state_dict_to_model(model_data).to(self.device)
        self._local_model = model_data
        return True


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. æœåŠ¡ç«¯ Trainerï¼ˆFedAvg èšåˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MNISTTrainer(BaseTrainer):
    def __init__(self, global_model=None, training_config=None, logger=None):
        super().__init__(global_model, training_config, logger)
        self.round = 0

    async def train_round(self, round_num: int, client_ids: List[str]) -> RoundResult:
        print(f"\nğŸ”„ ç¬¬ {round_num} è½®è®­ç»ƒï¼šå®¢æˆ·ç«¯ {client_ids}")

        start_time = time.time()  # å¼€å§‹è®¡æ—¶

        client_results = {}     # ä¿å­˜æ¯ä¸ªæˆåŠŸå®¢æˆ·ç«¯çš„ TrainingResult
        successful_clients = []
        failed_clients = []

        # æ„å»ºå¼‚æ­¥ä»»åŠ¡åˆ—è¡¨ï¼ˆä¸ç«‹å³æ‰§è¡Œï¼‰
        tasks = []
        for cid in client_ids:
            if cid in self.learner_proxies and self.is_client_ready(cid):
                proxy = self.learner_proxies[cid]
                task = proxy.train({
                    "global_model": self.global_model,
                    "epochs": 1,
                    "learning_rate": 0.01
                })
                tasks.append((cid, task))
            else:
                failed_clients.append(cid)

        # å¹¶å‘ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for cid, task in tasks:
            try:
                result = await task
                client_results[cid] = result
                successful_clients.append(cid)
            except Exception as e:
                print(f"âŒ å®¢æˆ·ç«¯ {cid} è®­ç»ƒå¤±è´¥: {e}")
                failed_clients.append(cid)

        # èšåˆæ¨¡å‹æ›´æ–°
        aggregated_model = await self.aggregate_models(client_results)
        self.global_model = aggregated_model

        # è®¡ç®—æœ¬è½®åŠ æƒå¹³å‡æŒ‡æ ‡
        total_samples = sum(r.get("samples_count") for r in client_results.values())
        avg_loss = sum(r.get("loss") * r.get("samples_count") for r in client_results.values()) / max(total_samples, 1)
        avg_accuracy = sum(r.get("accuracy") * r.get("samples_count") for r in client_results.values()) / max(total_samples, 1)

        training_time = time.time() - start_time

        # è¿”å›æœ¬è½®ç»“æœ
        return RoundResult(
            participants=client_ids,
            successful_clients=successful_clients,
            failed_clients=failed_clients,
            aggregated_model=aggregated_model,
            round_metrics={
                "avg_loss": avg_loss,
                "avg_accuracy": avg_accuracy
            },
            training_time=training_time
        )

    async def aggregate_models(self, client_results: Dict[str, Any]) -> ModelData:
        print("ğŸ§® èšåˆæ¨¡å‹ï¼ˆFedAvgï¼‰...")
        total_samples = sum(r.get("samples_count", 0) for r in client_results.values())
        if total_samples == 0:
            return self.global_model

        # åˆå§‹åŒ–èšåˆå­—å…¸
        agg_state = None
        for result in client_results.values():
            weight = result.get("samples_count", 0) / total_samples
            client_state = result.get("model_update", None)
            if agg_state is None:
                agg_state = {k: torch.tensor(v) * weight for k, v in client_state.items()}
            else:
                for k in agg_state:
                    agg_state[k] += torch.tensor(client_state[k]) * weight

        # è½¬å› listï¼ˆJSON serializableï¼‰
        return {k: v.tolist() for k, v in agg_state.items()}

    async def evaluate_global_model(self) -> EvaluationResult:
        # å¯é€‰ï¼šæœåŠ¡ç«¯è¯„ä¼°ï¼ˆè¿™é‡Œç•¥ï¼Œæˆ–ç”¨è™šæ‹Ÿæ•°æ®ï¼‰
        return EvaluationResult(
            client_id="server",
            success=True,
            loss=0.0,
            accuracy=0.0,
            samples_count=0,
            evaluation_time=0.0
        )

    def should_stop_training(self, round_num: int, round_result: RoundResult) -> bool:
        return round_num >= 2  # è·‘ 2 è½®


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ä¸»å‡½æ•°ï¼ˆä½¿ç”¨ process æ¨¡å¼ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def run_federation():

    setup_auto_logging()
    config = {"mode": "process", "timeout": 30.0}

    # åˆå§‹å…¨å±€æ¨¡å‹
    initial_model = model_to_state_dict(MNISTNet())

    # å¯åŠ¨æœåŠ¡ç«¯
    server = FederationServer(config)
    await server.initialize_with_trainer(
        trainer_class=MNISTTrainer,
        global_model=initial_model,
        trainer_config={}
    )
    await server.start_server()
    print("âœ… æœåŠ¡ç«¯å¯åŠ¨")

    client1_config = {
        "mode": "process",
        "timeout": 30.0,
        "transport": {
            "specific_config": {
                'port': 0
            }
        }
    }
    # å¯åŠ¨å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å¤šè¿›ç¨‹ï¼‰
    client1 = FederationClient.create_client(client1_config, client_id="process_client_1")
    await client1.initialize_with_learner(MNISTLearner)
    await client1.start_client()
    print("âœ… å®¢æˆ·ç«¯ 1 å¯åŠ¨")

    client2_config = {
        "mode": "process",
        "timeout": 30.0,
        "transport": {
            "specific_config": {
                'port': 0
            }
        }
    }
    client2 = FederationClient.create_client(client2_config, client_id="process_client_2")
    await client2.initialize_with_learner(MNISTLearner)
    await client2.start_client()
    print("âœ… å®¢æˆ·ç«¯ 2 å¯åŠ¨")

    # åè°ƒå™¨
    coordinator = FederationCoordinator(
        federation_server=server,
        federation_config=FederationConfig(
            max_rounds=2,
            min_clients=2,
        )
    )

    result = await coordinator.start_federation()
    print(f"ğŸ‰ è”é‚¦è®­ç»ƒå®Œæˆï¼æœ€ç»ˆè½®å‡†ç¡®ç‡: {result.final_accuracy:.4f}, è½®æ•°: {result.completed_rounds}")

    await client1.stop_client()
    await client2.stop_client()
    await server.stop_server()


def main():
    # åœ¨ Windows æˆ– Jupyter ä¸­éœ€ä¿æŠ¤å…¥å£
    mp.set_start_method("spawn", force=True)
    asyncio.run(run_federation())


if __name__ == "__main__":
    main()