# FedCL è”é‚¦å­¦ä¹ æ¡†æ¶é…ç½®æ¨¡æ¿

æœ¬ç›®å½•æä¾›åŸºäº FedCL è”é‚¦å­¦ä¹ æ¡†æ¶çš„é…ç½®æ¨¡æ¿å’Œä½¿ç”¨æŒ‡å—ã€‚FedCL æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„è”é‚¦æŒç»­å­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒè£…é¥°å™¨é©±åŠ¨çš„ç»„ä»¶å¼€å‘ã€çµæ´»çš„é…ç½®ç®¡ç†å’Œå¼ºå¤§çš„Hookæ‰©å±•ç³»ç»Ÿã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
config_templates/
â”œâ”€â”€ README.md                           # æœ¬æ–‡æ¡£
â”œâ”€â”€ experiment_config.yaml              # é›†ä¸­å¼é…ç½®æ¨¡æ¿ï¼ˆå•æ–‡ä»¶åŒ…å«æ‰€æœ‰é…ç½®ï¼‰
â””â”€â”€ server_client_configs/              # åˆ†å¸ƒå¼é…ç½®æ¨¡æ¿ç›®å½•
    â”œâ”€â”€ README.md                       # åˆ†å¸ƒå¼é…ç½®è¯¦ç»†è¯´æ˜
    â”œâ”€â”€ server_config.yaml              # æœåŠ¡ç«¯é…ç½®æ¨¡æ¿
    â”œâ”€â”€ client_config_template.yaml     # å®¢æˆ·ç«¯é…ç½®æ¨¡æ¿ï¼ˆç”¨äºåˆ›å»ºæ–°å®¢æˆ·ç«¯ï¼‰
    â”œâ”€â”€ client_1_config.yaml            # å®¢æˆ·ç«¯1é…ç½®ç¤ºä¾‹ï¼ˆé»˜è®¤learnerï¼‰
    â”œâ”€â”€ client_2_config.yaml            # å®¢æˆ·ç«¯2é…ç½®ç¤ºä¾‹ï¼ˆEWC learnerï¼‰
    â””â”€â”€ client_3_config.yaml            # å®¢æˆ·ç«¯3é…ç½®ç¤ºä¾‹ï¼ˆå¤šlearneråä½œï¼‰
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¤åˆ¶é…ç½®æ¨¡æ¿
```bash
# å¤åˆ¶æ¨¡æ¿åˆ°æ‚¨çš„é¡¹ç›®ç›®å½•
cp examples/config_templates/experiment_config.yaml my_experiment_config.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim my_experiment_config.yaml
```

### 2. è¿è¡Œå®éªŒ
```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶è¿è¡Œå®éªŒ
python -m fedcl.experiment.experiment my_experiment_config.yaml

# æˆ–ä½¿ç”¨Python API
python -c "
import fedcl
experiment = fedcl.FedCLExperiment('my_experiment_config.yaml')
results = experiment.run()
print(f'Final accuracy: {results.get(\"accuracy\", \"N/A\")}')
"
```

### 3. æŸ¥çœ‹ç»“æœ
```bash
# æŸ¥çœ‹å®éªŒè¾“å‡º
ls experiments/fedcl_template_experiment/

# æŸ¥çœ‹æ—¥å¿—
tail -f experiments/fedcl_template_experiment/logs/*.log
```

## ğŸ“– é…ç½®æ–‡ä»¶è¯¦è§£

### ğŸ”§ æ ¸å¿ƒé…ç½®éƒ¨åˆ†

#### 1. å®éªŒé…ç½® (`experiment`)
```yaml
experiment:
  name: "my_experiment"              # å®éªŒåç§°ï¼ˆå¿…é¡»å”¯ä¸€ï¼‰
  description: "å®éªŒæè¿°"            # å®éªŒæè¿°
  seed: 42                          # éšæœºç§å­
  working_dir: "experiments/"       # å·¥ä½œç›®å½•
  save_checkpoints: true            # å¯ç”¨æ£€æŸ¥ç‚¹
  checkpoint_frequency: 1           # ä¿å­˜é¢‘ç‡
```

#### 2. æ•°æ®é…ç½® (`dataset`)
```yaml
dataset:
  name: "MNIST"                     # æ•°æ®é›†: MNIST/CIFAR10/è‡ªå®šä¹‰
  path: "data/MNIST"                # æ•°æ®è·¯å¾„
  type: "classification"            # ä»»åŠ¡ç±»å‹
  num_classes: 10                   # ç±»åˆ«æ•°
  split_config:
    num_clients: 3                  # å®¢æˆ·ç«¯æ•°é‡
    distribution: "iid"             # æ•°æ®åˆ†å¸ƒ: iid/non_iid
```

#### 3. è”é‚¦å­¦ä¹ é…ç½® (`federation`)
```yaml
federation:
  num_rounds: 5                     # è®­ç»ƒè½®æ¬¡
  min_clients: 2                    # æœ€å°‘å‚ä¸å®¢æˆ·ç«¯
  max_clients: 3                    # æœ€å¤šå‚ä¸å®¢æˆ·ç«¯
  aggregation_strategy: "fedavg"    # èšåˆç­–ç•¥
```

#### 4. æ¨¡å‹é…ç½® (`model`)
```yaml
model:
  type: "SimpleMLP"                 # æ¨¡å‹ç±»å‹
  input_size: 784                   # è¾“å…¥ç»´åº¦
  hidden_sizes: [256, 128]          # éšè—å±‚
  num_classes: 10                   # è¾“å‡ºç±»åˆ«
```

#### 5. è®­ç»ƒé…ç½® (`training`)
```yaml
training:
  local_epochs: 3                   # æœ¬åœ°è®­ç»ƒè½®æ¬¡
  batch_size: 32                    # æ‰¹æ¬¡å¤§å°
  optimizer:
    type: "SGD"                     # ä¼˜åŒ–å™¨
    lr: 0.01                        # å­¦ä¹ ç‡
    momentum: 0.9                   # åŠ¨é‡
```

## ğŸ”Œ Hookç³»ç»Ÿè¯¦è§£

FedCL çš„ Hook ç³»ç»Ÿæ˜¯æ¡†æ¶çš„æ ¸å¿ƒæ‰©å±•æœºåˆ¶ï¼Œæä¾›äº‹ä»¶é©±åŠ¨çš„æ’ä»¶åŒ–æ¶æ„ï¼Œæ”¯æŒç»„ä»¶æ³¨å†Œã€å¤šlearneråè°ƒã€ç‰¹å¾äº¤æ¢ç­‰é«˜çº§åŠŸèƒ½ã€‚

### ğŸ¯ Hookç³»ç»Ÿç‰¹æ€§

1. **äº‹ä»¶é©±åŠ¨**: åŸºäºè®­ç»ƒç”Ÿå‘½å‘¨æœŸçš„å„ä¸ªé˜¶æ®µè§¦å‘
2. **ç»„ä»¶æ³¨å†Œ**: é€šè¿‡è£…é¥°å™¨APIæ³¨å†Œlearnerã€èšåˆå™¨ã€è¯„ä¼°å™¨ç­‰ç»„ä»¶
3. **å¤šLearneræ”¯æŒ**: ä¸“é—¨çš„å¤šlearneråè°ƒå’Œç‰¹å¾äº¤æ¢æœºåˆ¶
4. **ä¼˜å…ˆçº§ç®¡ç†**: æ”¯æŒHookæ‰§è¡Œé¡ºåºæ§åˆ¶
5. **çµæ´»é…ç½®**: é€šè¿‡YAMLé…ç½®æ–‡ä»¶å’Œè£…é¥°å™¨åŒé‡ç®¡ç†
6. **å†…ç½®Hook**: æä¾›æ£€æŸ¥ç‚¹ã€æŒ‡æ ‡æ”¶é›†ã€å¯è§†åŒ–ç­‰å¸¸ç”¨Hook
7. **è‡ªå®šä¹‰æ‰©å±•**: æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰Hookå¼€å‘

### ğŸ“Š Hookæ‰§è¡Œé˜¶æ®µ

#### 1. åŸºç¡€æ‰§è¡Œé˜¶æ®µ
```python
class HookPhase(Enum):
    BEFORE_EXPERIMENT = "before_experiment"    # å®éªŒå¼€å§‹å‰
    AFTER_EXPERIMENT = "after_experiment"      # å®éªŒç»“æŸå
    BEFORE_ROUND = "before_round"              # è”é‚¦è½®æ¬¡å¼€å§‹å‰
    AFTER_ROUND = "after_round"                # è”é‚¦è½®æ¬¡ç»“æŸå
    BEFORE_TASK = "before_task"                # ä»»åŠ¡å¼€å§‹å‰
    AFTER_TASK = "after_task"                  # ä»»åŠ¡ç»“æŸå
    BEFORE_EPOCH = "before_epoch"              # è®­ç»ƒè½®å¼€å§‹å‰
    AFTER_EPOCH = "after_epoch"                # è®­ç»ƒè½®ç»“æŸå
    BEFORE_BATCH = "before_batch"              # æ‰¹æ¬¡å¼€å§‹å‰
    AFTER_BATCH = "after_batch"                # æ‰¹æ¬¡ç»“æŸå
    ON_ERROR = "on_error"                      # é”™è¯¯å‘ç”Ÿæ—¶
    ON_CHECKPOINT = "on_checkpoint"            # æ£€æŸ¥ç‚¹ä¿å­˜æ—¶
    ON_EVALUATION = "on_evaluation"            # è¯„ä¼°æ—¶
```

#### 2. å¤šLearnerä¸“ç”¨é˜¶æ®µ
```python
class MultiLearnerHookPhase(Enum):
    # åˆå§‹åŒ–é˜¶æ®µ
    MULTI_LEARNER_INIT = "multi_learner_init"
    LEARNERS_REGISTRATION = "learners_registration"
    LEARNERS_READY = "learners_ready"
    
    # æ‰§è¡Œè®¡åˆ’é˜¶æ®µ
    EXECUTION_PLANNING = "execution_planning"
    PLAN_OPTIMIZATION = "plan_optimization" 
    RESOURCE_ALLOCATION = "resource_allocation"
    
    # æ‰§è¡Œåè°ƒé˜¶æ®µ
    BEFORE_EXECUTION_GROUP = "before_execution_group"
    AFTER_EXECUTION_GROUP = "after_execution_group"
    BEFORE_LEARNER_EXECUTION = "before_learner_execution"
    AFTER_LEARNER_EXECUTION = "after_learner_execution"
    
    # ç‰¹å¾äº¤æ¢é˜¶æ®µ
    FEATURE_EXTRACTION = "feature_extraction"
    FEATURE_EXCHANGE = "feature_exchange"
    FEATURE_AGGREGATION = "feature_aggregation"
    FEATURE_DISTRIBUTION = "feature_distribution"
    
    # å®Œæˆé˜¶æ®µ
    ALL_LEARNERS_COMPLETE = "all_learners_complete"
    MULTI_LEARNER_AGGREGATION = "multi_learner_aggregation"
    EXECUTION_SUMMARY = "execution_summary"
```

### ğŸ—ï¸ ç»„ä»¶æ³¨å†Œç³»ç»Ÿ

#### 1. è£…é¥°å™¨APIæ³¨å†Œ

**å­¦ä¹ å™¨æ³¨å†Œ**
```python
import fedcl

@fedcl.learner("ewc_mnist")
class EWCLearner(fedcl.BaseLearner):
    """å¼¹æ€§æƒé‡å·©å›ºå­¦ä¹ å™¨"""
    
    def __init__(self, context, config, **kwargs):
        super().__init__(context, config, **kwargs)
        self.fisher_information = {}
        self.old_params = {}
    
    def train_task(self, task_data, task_id):
        """ä»»åŠ¡è®­ç»ƒé€»è¾‘"""
        # EWCç‰¹å®šçš„è®­ç»ƒé€»è¾‘
        loss = self.compute_loss(predictions, targets)
        ewc_loss = self.compute_ewc_penalty()
        total_loss = loss + self.lambda_ewc * ewc_loss
        return total_loss
    
    def after_task_training(self, task_id):
        """ä»»åŠ¡è®­ç»ƒåçš„å¤„ç†"""
        self.compute_fisher_information()
        self.save_old_parameters()
```

**èšåˆå™¨æ³¨å†Œ**
```python
@fedcl.aggregator("fedprox")
class FedProxAggregator(fedcl.BaseAggregator):
    """FedProxèšåˆå™¨"""
    
    def __init__(self, context, config):
        super().__init__(context, config)
        self.mu = config.get('mu', 0.01)  # æ­£åˆ™åŒ–å‚æ•°
    
    def aggregate(self, client_updates):
        """æ‰§è¡ŒFedProxèšåˆ"""
        aggregated_params = {}
        total_samples = sum(update['num_samples'] for update in client_updates)
        
        for param_name in client_updates[0]['params'].keys():
            weighted_sum = torch.zeros_like(client_updates[0]['params'][param_name])
            
            for update in client_updates:
                weight = update['num_samples'] / total_samples
                weighted_sum += weight * update['params'][param_name]
            
            aggregated_params[param_name] = weighted_sum
        
        return aggregated_params
```

**è¯„ä¼°å™¨æ³¨å†Œ**
```python
@fedcl.evaluator("continual_accuracy")
class ContinualAccuracyEvaluator(fedcl.BaseEvaluator):
    """æŒç»­å­¦ä¹ å‡†ç¡®ç‡è¯„ä¼°å™¨"""
    
    def evaluate(self, model, test_data, context):
        """è¯„ä¼°æ¨¡å‹åœ¨æ‰€æœ‰å·²å­¦ä»»åŠ¡ä¸Šçš„æ€§èƒ½"""
        task_accuracies = {}
        overall_accuracy = 0.0
        
        for task_id, task_test_data in test_data.items():
            accuracy = self.evaluate_task(model, task_test_data)
            task_accuracies[f'task_{task_id}_accuracy'] = accuracy
            overall_accuracy += accuracy
        
        overall_accuracy /= len(test_data)
        
        return {
            'overall_accuracy': overall_accuracy,
            'backward_transfer': self.compute_backward_transfer(task_accuracies),
            'forward_transfer': self.compute_forward_transfer(task_accuracies),
            **task_accuracies
        }
```

**æŸå¤±å‡½æ•°æ³¨å†Œ**
```python
@fedcl.loss("distillation_loss")
def knowledge_distillation_loss(student_logits, teacher_logits, targets, temperature=3.0):
    """çŸ¥è¯†è’¸é¦æŸå¤±å‡½æ•°"""
    soft_targets = F.softmax(teacher_logits / temperature, dim=1)
    soft_prob = F.log_softmax(student_logits / temperature, dim=1)
    
    # è½¯æ ‡ç­¾æŸå¤±
    soft_loss = -torch.sum(soft_targets * soft_prob) / student_logits.size(0)
    
    # ç¡¬æ ‡ç­¾æŸå¤±
    hard_loss = F.cross_entropy(student_logits, targets)
    
    # ç»„åˆæŸå¤±
    return 0.7 * soft_loss * (temperature ** 2) + 0.3 * hard_loss
```

**è¾…åŠ©æ¨¡å‹æ³¨å†Œ**
```python
@fedcl.model("teacher_network")
class TeacherNetwork:
    """æ•™å¸ˆç½‘ç»œè¾…åŠ©æ¨¡å‹"""
    
    def __init__(self, config=None, context=None):
        self.config = config or {}
        self.context = context
        
    def create_model(self):
        """åˆ›å»ºé¢„è®­ç»ƒçš„æ•™å¸ˆæ¨¡å‹"""
        model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)
        model.eval()
        
        # è¿”å›æ¨¡å‹å’Œç‰¹å¾æå–å™¨
        feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])
        
        return {
            'model': model,
            'feature_extractor': feature_extractor,
            'output_dim': model.fc.in_features
        }
```

#### 2. é…ç½®æ–‡ä»¶æ³¨å†Œ

```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œç»„ä»¶
components:
  learners:
    - name: "ewc_mnist"
      class_path: "my_learners.EWCLearner"
      config:
        lambda_ewc: 0.4
        fisher_samples: 200
        
  aggregators:
    - name: "fedprox"
      class_path: "my_aggregators.FedProxAggregator"
      config:
        mu: 0.01
        
  hooks:
    - name: "distillation_hook"
      class_path: "my_hooks.DistillationHook"
      phase: "after_task"
      priority: 10
      config:
        teacher_model: "teacher_network"
        temperature: 3.0
```

### ğŸ”„ å¤šLearneråè°ƒæœºåˆ¶

#### 1. å¤šLearneré…ç½®

```yaml
# å¤šlearnerå®éªŒé…ç½®
experiment:
  name: "multi_learner_continual"
  multi_learner:
    enabled: true
    coordination_strategy: "adaptive"
    feature_sharing: true
    
learners:
  - name: "ewc_learner"
    type: "EWCLearner" 
    tasks: [0, 1, 2]  # è´Ÿè´£çš„ä»»åŠ¡
    priority: 1
    
  - name: "si_learner"
    type: "SynapticIntelligenceLearner"
    tasks: [3, 4, 5]
    priority: 2
    
  - name: "replay_learner"
    type: "ExperienceReplayLearner"
    tasks: [0, 1, 2, 3, 4, 5]  # æ‰€æœ‰ä»»åŠ¡
    priority: 0  # æœ€é«˜ä¼˜å…ˆçº§

# å¤šlearner Hooké…ç½®
hooks:
  enabled: true
  
  # learneråè°ƒHook
  learner_coordination_hook:
    enabled: true
    phase: "execution_planning"
    priority: 0
    config:
      strategy: "adaptive"
      
  # ç‰¹å¾äº¤æ¢Hook
  feature_exchange_hook:
    enabled: true
    phase: "feature_exchange"
    priority: 5
    config:
      exchange_strategy: "selective"
      feature_dependencies:
        ewc_learner: ["si_learner"]
        si_learner: ["replay_learner"]
```

#### 2. å¤šLearner Hookå®ç°

**Learneråè°ƒHook**
```python
@fedcl.hook("execution_planning", priority=0)
class LearnerCoordinationHook(Hook):
    """å¤šlearneræ‰§è¡Œåè°ƒHook"""
    
    def __init__(self, coordination_strategy="adaptive"):
        super().__init__("execution_planning", 0)
        self.coordination_strategy = coordination_strategy
    
    def execute(self, context, **kwargs):
        learners = kwargs.get('learners', {})
        current_task = kwargs.get('current_task')
        
        if self.coordination_strategy == "priority_based":
            return self._optimize_by_priority(learners, current_task)
        elif self.coordination_strategy == "resource_based":
            return self._optimize_by_resources(learners, current_task)
        else:  # adaptive
            return self._adaptive_optimization(learners, current_task)
    
    def _adaptive_optimization(self, learners, current_task):
        """è‡ªé€‚åº”ä¼˜åŒ–æ‰§è¡Œè®¡åˆ’"""
        execution_plan = {
            'primary_learner': None,
            'support_learners': [],
            'execution_order': [],
            'resource_allocation': {}
        }
        
        # æ ¹æ®ä»»åŠ¡ç‰¹æ€§å’Œlearnerèƒ½åŠ›å†³å®šæ‰§è¡Œè®¡åˆ’
        for learner_id, learner in learners.items():
            if current_task in learner.config.get('tasks', []):
                if learner.config.get('priority', 0) == 0:
                    execution_plan['primary_learner'] = learner_id
                else:
                    execution_plan['support_learners'].append(learner_id)
        
        return execution_plan
```

**ç‰¹å¾äº¤æ¢Hook**
```python
@fedcl.hook("feature_exchange", priority=5)
class FeatureExchangeHook(Hook):
    """learneré—´ç‰¹å¾äº¤æ¢Hook"""
    
    def __init__(self, exchange_strategy="selective"):
        super().__init__("feature_exchange", 5)
        self.exchange_strategy = exchange_strategy
        self.feature_cache = {}
    
    def execute(self, context, **kwargs):
        learners = kwargs.get('learners', {})
        execution_results = kwargs.get('execution_results', {})
        
        # æ”¶é›†å„learnerçš„ç‰¹å¾
        features = self._collect_features(execution_results)
        
        # æ‰§è¡Œç‰¹å¾äº¤æ¢
        if self.exchange_strategy == "selective":
            return self._selective_exchange(features, learners, context)
        else:
            return self._broadcast_exchange(features, learners, context)
    
    def _selective_exchange(self, features, learners, context):
        """é€‰æ‹©æ€§ç‰¹å¾äº¤æ¢"""
        exchanges = []
        
        # æ ¹æ®é¢„å®šä¹‰çš„ä¾èµ–å…³ç³»äº¤æ¢ç‰¹å¾
        dependencies = context.config.get('feature_dependencies', {})
        
        for source_learner, target_learners in dependencies.items():
            if source_learner in features:
                source_features = features[source_learner]
                
                for target_learner in target_learners:
                    if target_learner in learners:
                        # å…±äº«ç‰¹å¾åˆ°ç›®æ ‡learner
                        context.share_features(
                            source_learner, 
                            source_features, 
                            target_learner
                        )
                        
                        exchanges.append({
                            'source': source_learner,
                            'target': target_learner,
                            'feature_type': 'intermediate_representations'
                        })
        
        return {'exchanges': exchanges, 'strategy': 'selective'}
```

### ğŸ—ï¸ Hooké…ç½®ç¤ºä¾‹

#### 1. åŸºç¡€Hooké…ç½®
```yaml
hooks:
  enabled: true                              # å¯ç”¨Hookç³»ç»Ÿ
  
  # æ£€æŸ¥ç‚¹Hook - ç”¨äºæ¨¡å‹çŠ¶æ€ä¿å­˜
  checkpoint_hook:
    enabled: true                            # å¯ç”¨æ£€æŸ¥ç‚¹Hook
    phase: "after_round"                     # åœ¨æ¯è½®ç»“æŸåæ‰§è¡Œ
    priority: 0                              # æœ€é«˜ä¼˜å…ˆçº§

  # å¤šlearneråè°ƒHook
  learner_coordination_hook:
    enabled: true
    phase: "execution_planning"
    priority: 0
    config:
      coordination_strategy: "adaptive"
      
  # ç‰¹å¾äº¤æ¢Hook
  feature_exchange_hook:
    enabled: true
    phase: "feature_exchange"
    priority: 5
    config:
      exchange_strategy: "selective"
```

#### 2. å†…ç½®Hookè¯¦è§£

**æ£€æŸ¥ç‚¹Hook (CheckpointHook)**
```yaml
checkpoint:
  enabled: true                              # å¯ç”¨æ£€æŸ¥ç‚¹
  save_frequency: 1                          # æ¯è½®ä¿å­˜
  save_model: true                           # ä¿å­˜æ¨¡å‹å‚æ•°
  save_optimizer: true                       # ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
  checkpoint_dir: "checkpoints/"             # ä¿å­˜ç›®å½•
  max_checkpoints: 3                         # æœ€å¤§ä¿ç•™æ•°é‡
  naming_pattern: "checkpoint_round_{round}_epoch_{epoch}"
```

**æŒ‡æ ‡æ”¶é›†Hook (MetricsHook)**
```yaml
metrics_hook:
  enabled: true                              # å¯ç”¨æŒ‡æ ‡æ”¶é›†
  phase: "after_evaluation"                  # è¯„ä¼°åæ‰§è¡Œ
  priority: 5                                # ä¸­ç­‰ä¼˜å…ˆçº§
  config:
    track_loss: true                         # è·Ÿè¸ªæŸå¤±
    track_accuracy: true                     # è·Ÿè¸ªå‡†ç¡®ç‡
    save_to_file: true                       # ä¿å­˜åˆ°æ–‡ä»¶
    track_continual_metrics: true            # è·Ÿè¸ªæŒç»­å­¦ä¹ æŒ‡æ ‡
```

**TensorBoard Hook**
```yaml
tensorboard_hook:
  enabled: true                              # å¯ç”¨TensorBoard
  phase: "after_epoch"                       # æ¯è½®åæ‰§è¡Œ
  priority: 10                               # è¾ƒä½ä¼˜å…ˆçº§
  config:
    log_dir: "runs/"                         # TensorBoardæ—¥å¿—ç›®å½•
    log_images: false                        # æ˜¯å¦è®°å½•å›¾åƒ
    log_histograms: true                     # è®°å½•å‚æ•°åˆ†å¸ƒ
    log_learner_metrics: true                # è®°å½•å„learneræŒ‡æ ‡
```

**Weights & Biases Hook**
```yaml
wandb_hook:
  enabled: false                             # é»˜è®¤å…³é—­
  phase: "after_round"                       # è½®æ¬¡åæ‰§è¡Œ
  priority: 20                               # ä½ä¼˜å…ˆçº§
  config:
    project: "fedcl_continual_learning"      # WandBé¡¹ç›®å
    entity: "your_team"                      # å›¢é˜Ÿåç§°
    tags: ["federated_learning", "continual", "multi_learner"]  # å®éªŒæ ‡ç­¾
    log_multi_learner_metrics: true          # è®°å½•å¤šlearneræŒ‡æ ‡
```

#### 3. è‡ªå®šä¹‰Hookå¼€å‘

**å®šä¹‰è‡ªå®šä¹‰Hook**
```python
import fedcl
from fedcl.core.hook import Hook
from fedcl.core.execution_context import ExecutionContext

@fedcl.hook("after_task", priority=15)
class CustomAnalysisHook(Hook):
    """è‡ªå®šä¹‰åˆ†æHook"""
    
    def __init__(self, config=None):
        super().__init__(
            phase="after_task",
            priority=15,
            name="CustomAnalysisHook"
        )
        self.config = config or {}
        self.analysis_results = {}
    
    def execute(self, context: ExecutionContext, **kwargs):
        """Hookæ‰§è¡Œé€»è¾‘"""
        # è·å–å½“å‰ä»»åŠ¡ä¿¡æ¯
        task_id = kwargs.get('task_id')
        model = kwargs.get('model')
        task_results = kwargs.get('task_results')
        
        # æ‰§è¡Œè‡ªå®šä¹‰åˆ†æ
        analysis = self.analyze_task_performance(model, task_results)
        
        # å­˜å‚¨åˆ†æç»“æœ
        self.analysis_results[task_id] = analysis
        
        # æ›´æ–°æ‰§è¡Œä¸Šä¸‹æ–‡
        context.set_analysis_results(self.analysis_results)
        
        logger.info(f"Task {task_id} analysis completed: {analysis}")
        
        return analysis
    
    def analyze_task_performance(self, model, task_results):
        """åˆ†æä»»åŠ¡æ€§èƒ½"""
        return {
            'accuracy': task_results.get('accuracy', 0),
            'loss': task_results.get('loss', float('inf')),
            'model_complexity': self.compute_model_complexity(model),
            'forgetting_measure': self.compute_forgetting(task_results)
        }
```

**å¤šLearnerä¸“ç”¨Hook**
```python
@fedcl.hook("learners_registration", priority=0)
class LearnerRegistrationHook(Hook):
    """Learneræ³¨å†Œç®¡ç†Hook"""
    
    def execute(self, context, **kwargs):
        """ç®¡ç†learneræ³¨å†Œè¿‡ç¨‹"""
        learner_configs = kwargs.get('learner_configs', [])
        registered_learners = {}
        
        for config in learner_configs:
            learner_id = config['name']
            learner_type = config['type']
            
            # ä»æ³¨å†Œè¡¨è·å–learnerç±»
            learner_class = context.registry.get_learner(learner_type)
            
            # åˆ›å»ºlearnerå®ä¾‹
            learner = learner_class(context, config.get('config', {}))
            
            # æ³¨å†Œåˆ°ä¸Šä¸‹æ–‡
            registered_learners[learner_id] = learner
            
            logger.info(f"Registered learner: {learner_id} ({learner_type})")
        
        # æ›´æ–°ä¸Šä¸‹æ–‡
        context.set_learners(registered_learners)
        
        return registered_learners

@fedcl.hook("feature_aggregation", priority=5) 
class FeatureAggregationHook(Hook):
    """ç‰¹å¾èšåˆHook"""
    
    def execute(self, context, **kwargs):
        """èšåˆå¤šä¸ªlearnerçš„ç‰¹å¾"""
        learner_features = kwargs.get('learner_features', {})
        aggregation_strategy = self.config.get('strategy', 'average')
        
        if aggregation_strategy == 'average':
            return self._average_aggregation(learner_features)
        elif aggregation_strategy == 'weighted':
            return self._weighted_aggregation(learner_features, context)
        else:
            return self._attention_aggregation(learner_features)
    
    def _weighted_aggregation(self, learner_features, context):
        """åŠ æƒç‰¹å¾èšåˆ"""
        # æ ¹æ®learneræ€§èƒ½è®¡ç®—æƒé‡
        learner_weights = {}
        for learner_id in learner_features.keys():
            performance = context.get_learner_performance(learner_id)
            learner_weights[learner_id] = performance.get('accuracy', 0.5)
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(learner_weights.values())
        learner_weights = {k: v/total_weight for k, v in learner_weights.items()}
        
        # åŠ æƒèšåˆ
        aggregated_features = None
        for learner_id, features in learner_features.items():
            weight = learner_weights[learner_id]
            if aggregated_features is None:
                aggregated_features = weight * features
            else:
                aggregated_features += weight * features
        
        return aggregated_features
```

**æ³¨å†Œè‡ªå®šä¹‰Hookçš„å¤šç§æ–¹å¼**

**æ–¹æ³•1ï¼šè£…é¥°å™¨æ³¨å†Œï¼ˆæ¨èï¼‰**
```python
import fedcl

@fedcl.hook("after_evaluation", priority=15)
def custom_metrics_hook(context, **kwargs):
    """å‡½æ•°å¼Hook"""
    metrics = kwargs.get('metrics', {})
    
    # è®¡ç®—è‡ªå®šä¹‰æŒ‡æ ‡
    custom_metrics = {
        'accuracy_improvement': metrics.get('accuracy', 0) - context.get_previous_accuracy(),
        'loss_reduction': context.get_previous_loss() - metrics.get('loss', 0),
        'stability_score': compute_stability_score(metrics)
    }
    
    # æ›´æ–°ä¸Šä¸‹æ–‡
    context.update_metrics(custom_metrics)
    
    logger.info(f"Custom metrics: {custom_metrics}")
    return custom_metrics

# ç±»å¼Hookæ³¨å†Œ
@fedcl.hook("before_round", priority=5)
class DataAugmentationHook(Hook):
    """æ•°æ®å¢å¼ºHook"""
    
    def execute(self, context, **kwargs):
        training_data = kwargs.get('training_data')
        
        # åº”ç”¨æ•°æ®å¢å¼º
        augmented_data = self.apply_augmentation(training_data)
        
        # æ›´æ–°è®­ç»ƒæ•°æ®
        context.set_training_data(augmented_data)
        
        return augmented_data
```

**æ–¹æ³•2ï¼šé…ç½®æ–‡ä»¶æ³¨å†Œ**
```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ è‡ªå®šä¹‰Hook
hooks:
  enabled: true
  
  custom_hooks:
    - name: "CustomAnalysisHook"
      class_path: "my_hooks.CustomAnalysisHook"
      enabled: true
      phase: "after_task"
      priority: 15
      config:
        analysis_type: "comprehensive"
        save_plots: true
        output_file: "analysis_results.json"
    
    - name: "LearnerCoordinationHook"
      class_path: "my_hooks.LearnerCoordinationHook"
      enabled: true
      phase: "execution_planning"
      priority: 0
      config:
        coordination_strategy: "adaptive"
        resource_constraints:
          max_memory: "8GB"
          max_compute_time: 300
```

**æ–¹æ³•3ï¼šè¿è¡Œæ—¶åŠ¨æ€æ³¨å†Œ**
```python
# åœ¨Pythonä»£ç ä¸­åŠ¨æ€æ³¨å†Œ
import fedcl

def setup_custom_hooks(experiment):
    """è®¾ç½®è‡ªå®šä¹‰Hook"""
    
    # æ³¨å†Œåˆ†æHook
    analysis_hook = CustomAnalysisHook({
        'analysis_type': 'detailed',
        'save_plots': True
    })
    experiment.register_hook(analysis_hook)
    
    # æ³¨å†Œå¤šlearneråè°ƒHook
    coordination_hook = LearnerCoordinationHook({
        'strategy': 'resource_aware'
    })
    experiment.register_hook(coordination_hook)
    
    # æ³¨å†Œæ¡ä»¶Hook
    def conditional_checkpoint_hook(context, **kwargs):
        # åªæœ‰åœ¨å‡†ç¡®ç‡æå‡æ—¶æ‰ä¿å­˜æ£€æŸ¥ç‚¹
        current_accuracy = kwargs.get('metrics', {}).get('accuracy', 0)
        previous_accuracy = context.get_previous_accuracy()
        
        if current_accuracy > previous_accuracy:
            context.save_checkpoint()
            logger.info("Checkpoint saved due to accuracy improvement")
    
    # æ³¨å†Œæ¡ä»¶Hook
    experiment.register_hook(
        fedcl.Hook("after_evaluation", 5, "ConditionalCheckpointHook"),
        conditional_checkpoint_hook
    )
```

### ğŸ”„ Hookæ‰§è¡Œæµç¨‹

Hookç³»ç»Ÿçš„æ‰§è¡Œæµç¨‹å¦‚ä¸‹ï¼š

1. **Hookæ³¨å†Œé˜¶æ®µ**: 
   - æ¡†æ¶å¯åŠ¨æ—¶æ‰«æè£…é¥°å™¨æ³¨å†Œçš„Hook
   - è§£æé…ç½®æ–‡ä»¶ä¸­çš„Hookå®šä¹‰
   - åˆ›å»ºHookå®ä¾‹å¹¶æ³¨å†Œåˆ°HookExecutor

2. **é˜¶æ®µè§¦å‘é˜¶æ®µ**:
   - åœ¨ç›¸åº”çš„æ‰§è¡Œé˜¶æ®µè§¦å‘å¯¹åº”çš„Hook
   - HookExecutoræŒ‰ä¼˜å…ˆçº§æ’åºæ‰€æœ‰Hook
   - ä¾æ¬¡æ‰§è¡Œæ¯ä¸ªHookçš„executeæ–¹æ³•

3. **ä¸Šä¸‹æ–‡ä¼ é€’é˜¶æ®µ**:
   - Hooké€šè¿‡ExecutionContextè·å–å½“å‰çŠ¶æ€
   - Hookå¯ä»¥ä¿®æ”¹ExecutionContextä¸­çš„æ•°æ®
   - ä¿®æ”¹åçš„æ•°æ®ä¼ é€’ç»™åç»­Hookå’Œæ¡†æ¶ç»„ä»¶

4. **é”™è¯¯å¤„ç†é˜¶æ®µ**:
   - Hookæ‰§è¡Œå¤±è´¥æ—¶è®°å½•é”™è¯¯æ—¥å¿—
   - æ ¹æ®é”™è¯¯å¤„ç†ç­–ç•¥å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œ
   - æä¾›Hookçº§åˆ«çš„é”™è¯¯æ¢å¤æœºåˆ¶

```python
# Hookæ‰§è¡Œæµç¨‹ç¤ºä¾‹
class HookExecutor:
    def execute_hooks(self, phase: str, context: ExecutionContext, **kwargs):
        """æ‰§è¡ŒæŒ‡å®šé˜¶æ®µçš„æ‰€æœ‰Hook"""
        hooks = self.get_hooks_for_phase(phase)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        hooks.sort(key=lambda h: h.priority)
        
        results = []
        for hook in hooks:
            try:
                # æ£€æŸ¥Hookæ˜¯å¦åº”è¯¥æ‰§è¡Œ
                if hook.should_execute(context, **kwargs):
                    # æ‰§è¡ŒHook
                    result = hook.execute(context, **kwargs)
                    results.append(result)
                    
                    # æ›´æ–°æ‰§è¡Œç»Ÿè®¡
                    hook.execution_count += 1
                    
            except Exception as e:
                # é”™è¯¯å¤„ç†
                logger.error(f"Hook {hook.name} failed: {e}")
                self.handle_hook_error(hook, e, context)
        
        return results
```

### ğŸ“ˆ Hookä½¿ç”¨æœ€ä½³å®è·µ

#### 1. æ€§èƒ½ä¼˜åŒ–
```yaml
# åˆç†è®¾ç½®Hookä¼˜å…ˆçº§
hooks:
  checkpoint_hook:
    priority: 0        # å…³é”®æ“ä½œæœ€é«˜ä¼˜å…ˆçº§
  
  learner_coordination_hook:
    priority: 1        # åè°ƒæ“ä½œæ¬¡ä¹‹
    
  feature_exchange_hook:  
    priority: 5        # ç‰¹å¾äº¤æ¢ä¸­ç­‰ä¼˜å…ˆçº§
    
  tensorboard_hook:
    priority: 10       # å¯è§†åŒ–è¾ƒä½ä¼˜å…ˆçº§
    
  custom_analysis_hook:
    priority: 20       # åˆ†ææ“ä½œæœ€ä½ä¼˜å…ˆçº§
```

#### 2. é”™è¯¯å¤„ç†
```python
class RobustHook(Hook):
    """é”™è¯¯å¤„ç†ç¤ºä¾‹Hook"""
    
    def execute(self, context, **kwargs):
        try:
            # Hookæ ¸å¿ƒé€»è¾‘
            result = self.core_logic(context, **kwargs)
            return result
            
        except CriticalError as e:
            # å…³é”®é”™è¯¯ï¼Œéœ€è¦ä¸­æ–­å®éªŒ
            logger.error(f"Critical error in {self.name}: {e}")
            context.set_error_state(e)
            raise
            
        except RecoverableError as e:
            # å¯æ¢å¤é”™è¯¯ï¼Œè®°å½•ä½†ç»§ç»­æ‰§è¡Œ
            logger.warning(f"Recoverable error in {self.name}: {e}")
            return self.get_fallback_result()
            
        except Exception as e:
            # æœªçŸ¥é”™è¯¯ï¼Œå®‰å…¨å¤„ç†
            logger.error(f"Unexpected error in {self.name}: {e}")
            return None  # è¿”å›å®‰å…¨é»˜è®¤å€¼
```

#### 3. èµ„æºç®¡ç†
```python
class ResourceAwareHook(Hook):
    """èµ„æºæ„ŸçŸ¥Hook"""
    
    def execute(self, context, **kwargs):
        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        if not self.check_resources():
            logger.warning(f"Insufficient resources for {self.name}, skipping")
            return None
        
        # æ£€æŸ¥æ—¶é—´é™åˆ¶
        if context.is_timeout_approaching():
            logger.info(f"Timeout approaching, executing lightweight version")
            return self.lightweight_execution(context, **kwargs)
        
        # æ­£å¸¸æ‰§è¡Œ
        return self.full_execution(context, **kwargs)
    
    def check_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³"""
        import psutil
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
        memory_usage = psutil.virtual_memory().percent
        if memory_usage > 90:
            return False
        
        # æ£€æŸ¥CPUä½¿ç”¨ç‡  
        cpu_usage = psutil.cpu_percent(interval=1)
        if cpu_usage > 95:
            return False
            
        return True
```

#### 4. Hooké—´é€šä¿¡
```python
class CommunicatingHook(Hook):
    """Hooké—´é€šä¿¡ç¤ºä¾‹"""
    
    def execute(self, context, **kwargs):
        # ä»å…¶ä»–Hookè·å–æ•°æ®
        analysis_results = context.get_hook_data('CustomAnalysisHook')
        coordination_plan = context.get_hook_data('LearnerCoordinationHook')
        
        # åŸºäºå…¶ä»–Hookçš„ç»“æœæ‰§è¡Œé€»è¾‘
        if analysis_results and analysis_results.get('accuracy') > 0.9:
            # é«˜å‡†ç¡®ç‡æ—¶çš„ç‰¹æ®Šå¤„ç†
            result = self.high_accuracy_processing(coordination_plan)
        else:
            # å¸¸è§„å¤„ç†
            result = self.normal_processing()
        
        # å…±äº«æ•°æ®ç»™å…¶ä»–Hook
        context.set_hook_data(self.name, result)
        
        return result
```

### ğŸ”„ Hookæ‰§è¡Œæµç¨‹

1. **Hookæ³¨å†Œ**: æ¡†æ¶å¯åŠ¨æ—¶æ³¨å†Œæ‰€æœ‰å¯ç”¨çš„Hook
2. **é˜¶æ®µè§¦å‘**: åœ¨ç›¸åº”é˜¶æ®µè§¦å‘å¯¹åº”çš„Hook
3. **ä¼˜å…ˆçº§æ’åº**: æŒ‰ä¼˜å…ˆçº§é¡ºåºæ‰§è¡ŒHookï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
4. **ä¸Šä¸‹æ–‡ä¼ é€’**: Hooké€šè¿‡ExecutionContextè·å–å’Œä¿®æ”¹çŠ¶æ€
5. **é”™è¯¯å¤„ç†**: Hookæ‰§è¡Œå¤±è´¥æ—¶çš„é”™è¯¯æ¢å¤æœºåˆ¶

### ğŸ“ˆ Hookä½¿ç”¨æœ€ä½³å®è·µ

#### 1. æ€§èƒ½ä¼˜åŒ–
```yaml
# åˆç†è®¾ç½®Hookä¼˜å…ˆçº§
checkpoint_hook:
  priority: 0        # å…³é”®æ“ä½œä¼˜å…ˆ
tensorboard_hook:
  priority: 10       # å¯è§†åŒ–æ¬¡ä¹‹
custom_analysis_hook:
  priority: 20       # åˆ†ææœ€å
```

#### 2. é”™è¯¯å¤„ç†
```python
class RobustHook(Hook):
    def execute(self, context):
        try:
            # Hooké€»è¾‘
            pass
        except Exception as e:
            logger.error(f"Hook {self.name} failed: {e}")
            # ä¸è¦æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒ
```

#### 3. èµ„æºç®¡ç†
```python
class ResourceAwareHook(Hook):
    def execute(self, context):
        # æ£€æŸ¥èµ„æºçŠ¶æ€
        if context.should_save_checkpoint():
            # æ‰§è¡Œèµ„æºå¯†é›†æ“ä½œ
            pass
        else:
            # è·³è¿‡æˆ–ç®€åŒ–æ“ä½œ
            pass
```

## ğŸ“Š å®éªŒç›‘æ§ä¸æ—¥å¿—

### æ—¥å¿—ç³»ç»Ÿç‰¹æ€§

1. **åˆ†å±‚æ—¥å¿—**: æ”¯æŒDEBUG/INFO/WARNING/ERRORå¤šçº§åˆ«
2. **å®¢æˆ·ç«¯æ ‡è¯†**: åœ¨æ—¥å¿—ä¸­è‡ªåŠ¨æ ‡è®°å®¢æˆ·ç«¯IDï¼Œä¾¿äºè°ƒè¯•
3. **ç»“æ„åŒ–è¾“å‡º**: JSONæ ¼å¼çš„ç»“æ„åŒ–æ—¥å¿—æ”¯æŒ
4. **å®æ—¶ç›‘æ§**: æ”¯æŒå®æ—¶æ—¥å¿—æµç›‘æ§

### æ—¥å¿—é…ç½®ç¤ºä¾‹

```yaml
experiment:
  logging:
    level: "INFO"                            # å…¨å±€æ—¥å¿—çº§åˆ«
    log_client_training: true                # å®¢æˆ·ç«¯è®­ç»ƒæ—¥å¿—æ ‡è¯†
    log_to_file: true                        # æ–‡ä»¶è¾“å‡º
    log_to_console: true                     # æ§åˆ¶å°è¾“å‡º
    log_dir: "logs/"                         # æ—¥å¿—ç›®å½•
```

### æ—¥å¿—æŸ¥çœ‹å‘½ä»¤

```bash
# å®æ—¶æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
tail -f experiments/*/logs/*.log

# è¿‡æ»¤å®¢æˆ·ç«¯è®­ç»ƒæ—¥å¿—
grep "å®¢æˆ·ç«¯\[" experiments/*/logs/*.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep "ERROR" experiments/*/logs/*.log

# æŸ¥çœ‹Hookæ‰§è¡Œæ—¥å¿—
grep "Hook" experiments/*/logs/*.log
```

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

1. **é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯**
   ```bash
   # éªŒè¯YAMLæ ¼å¼
   python -c "import yaml; yaml.safe_load(open('config.yaml'))"
   ```

2. **è·¯å¾„é—®é¢˜**
   ```yaml
   # ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºå·¥ä½œç›®å½•çš„è·¯å¾„
   paths:
     data_path: "data/MNIST"              # ç›¸å¯¹è·¯å¾„
     output_path: "/absolute/path/output" # ç»å¯¹è·¯å¾„
   ```

3. **Hookæ‰§è¡Œå¤±è´¥**
   ```bash
   # æŸ¥çœ‹Hookç›¸å…³æ—¥å¿—
   grep -A 5 -B 5 "Hook.*failed" logs/*.log
   ```

4. **å†…å­˜ä¸è¶³**
   ```yaml
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   training:
     batch_size: 16    # ä»32å‡å°‘åˆ°16
   
   # å‡å°‘æ£€æŸ¥ç‚¹ä¿å­˜é¢‘ç‡
   checkpoint:
     save_frequency: 5  # æ¯5è½®ä¿å­˜ä¸€æ¬¡
   ```

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
   ```yaml
   experiment:
     logging:
       level: "DEBUG"   # å¼€å¯DEBUGçº§åˆ«
   ```

2. **Hookè°ƒè¯•**
   ```python
   # åœ¨è‡ªå®šä¹‰Hookä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
   def execute(self, context):
       logger.debug(f"Hook {self.name} executing with context: {context}")
   ```

3. **æ€§èƒ½åˆ†æ**
   ```bash
   # æŸ¥çœ‹Hookæ‰§è¡Œæ—¶é—´
   grep "execution_time" logs/*.log
   ```

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [FedCL GitHubä»“åº“](https://github.com/UPC518/MOE-FedCL)
- [APIæ–‡æ¡£](docs/)
- [ç¤ºä¾‹ä»£ç ](examples/)

### é…ç½®æ¨¡æ¿
- [é›†ä¸­å¼é…ç½®æ¨¡æ¿](experiment_config.yaml) - å•æ–‡ä»¶åŒ…å«æ‰€æœ‰é…ç½®ï¼Œé€‚åˆå¿«é€Ÿå®éªŒ
- [åˆ†å¸ƒå¼é…ç½®æ¨¡æ¿](server_client_configs/) - æœåŠ¡ç«¯-å®¢æˆ·ç«¯åˆ†ç¦»ï¼Œé€‚åˆçœŸå®éƒ¨ç½²
  - [æœåŠ¡ç«¯é…ç½®](server_client_configs/server_config.yaml)
  - [å®¢æˆ·ç«¯é…ç½®æ¨¡æ¿](server_client_configs/client_config_template.yaml)
  - [å®¢æˆ·ç«¯1é…ç½®](server_client_configs/client_1_config.yaml) - é»˜è®¤learner
  - [å®¢æˆ·ç«¯2é…ç½®](server_client_configs/client_2_config.yaml) - EWC learner
  - [å®¢æˆ·ç«¯3é…ç½®](server_client_configs/client_3_config.yaml) - å¤šlearneråä½œ
  - [åˆ†å¸ƒå¼é…ç½®è¯´æ˜](server_client_configs/README.md)
- [å®é™…æµ‹è¯•é…ç½®](../../tests/configs/mnist_real_test/)

## ğŸ—ï¸ é…ç½®æ¶æ„é€‰æ‹©

### é›†ä¸­å¼ vs åˆ†å¸ƒå¼é…ç½®

| ç‰¹æ€§ | é›†ä¸­å¼é…ç½® | åˆ†å¸ƒå¼é…ç½® |
|------|------------|------------|
| **é…ç½®æ–‡ä»¶** | `experiment_config.yaml` | `server_config.yaml` + `client_*_config.yaml` |
| **é€‚ç”¨åœºæ™¯** | å¿«é€ŸåŸå‹ã€ç®—æ³•éªŒè¯ã€å•æœºæµ‹è¯• | çœŸå®éƒ¨ç½²ã€å¼‚æ„ç¯å¢ƒã€å¤šlearneråä½œ |
| **ç®¡ç†å¤æ‚åº¦** | ä½ | ä¸­ç­‰ |
| **å¼‚æ„å®¢æˆ·ç«¯** | âŒ | âœ… |
| **ä¸ªæ€§åŒ–é…ç½®** | âŒ | âœ… |
| **æ‰©å±•æ€§** | ä½ | é«˜ |

**é€‰æ‹©å»ºè®®:**
- ğŸ”¬ **ç®—æ³•ç ”ç©¶** â†’ ä½¿ç”¨é›†ä¸­å¼é…ç½®
- ğŸŒ **çœŸå®éƒ¨ç½²** â†’ ä½¿ç”¨åˆ†å¸ƒå¼é…ç½®
- ğŸ¤ **å¤šLearnerå®éªŒ** â†’ ä½¿ç”¨åˆ†å¸ƒå¼é…ç½®

## ğŸ“‹ å®Œæ•´é…ç½®ç¤ºä¾‹

### å•LearneræŒç»­å­¦ä¹ å®éªŒ
```yaml
# experiment_config.yaml
experiment:
  name: "single_learner_continual_mnist" 
  description: "å•ä¸€learnerçš„MNISTæŒç»­å­¦ä¹ å®éªŒ"
  output_dir: "experiments/single_learner_test"
  
  date_id: "20250805_120000"
  save_config: true
  save_logs: true

# æ•°æ®é…ç½®
data:
  dataset: "MNIST"
  dataset_path: "./data/MNIST"
  
  # ä»»åŠ¡åºåˆ—å®šä¹‰
  task_sequence:
    num_tasks: 5
    task_type: "split"
    split_method: "class_based"
    classes_per_task: 2
    
  # æ•°æ®é¢„å¤„ç†
  preprocessing:
    normalize: true
    augmentation:
      enabled: true
      methods: ["rotation", "translation"]

# è”é‚¦å­¦ä¹ é…ç½®
federation:
  num_clients: 3
  participation_rate: 1.0
  
  client_data:
    distribution: "iid"  # æˆ– "non_iid"
    samples_per_client: 1000
    
  communication:
    rounds: 10
    local_epochs: 5

# æ¨¡å‹é…ç½®
model:
  type: "simple_cnn"
  input_shape: [1, 28, 28]
  num_classes: 10
  
  architecture:
    conv_layers: 2
    hidden_dims: [128, 64]
    dropout: 0.2

# Learneré…ç½®  
learners:
  - name: "ewc_learner"
    type: "EWCLearner"
    config:
      lambda_ewc: 0.4
      sample_size: 200
      
# è®­ç»ƒé…ç½®
training:
  optimizer: "adam"
  learning_rate: 0.001
  batch_size: 32
  
  loss:
    type: "cross_entropy"
    
  metrics:
    - "accuracy"
    - "loss" 
    - "forgetting"

# è¯„ä¼°é…ç½®
evaluation:
  interval: 1  # æ¯è½®è¯„ä¼°
  metrics:
    - "accuracy"
    - "backward_transfer"
    - "forward_transfer"
    
  test_tasks: "all"  # è¯„ä¼°æ‰€æœ‰å·²å­¦ä¹ ä»»åŠ¡

# æ£€æŸ¥ç‚¹é…ç½®
checkpoint:
  enabled: true
  save_interval: 5
  save_best: true
  save_last: true

# Hooké…ç½®
hooks:
  enabled: true
  
  # åŸºæœ¬Hook
  checkpoint_hook:
    enabled: true
    priority: 0
    
  evaluation_hook:
    enabled: true
    priority: 5
    
  tensorboard_hook:
    enabled: true
    priority: 10
    config:
      log_dir: "runs"
      
  # è‡ªå®šä¹‰Hook
  custom_hooks:
    - name: "PerformanceAnalysisHook"
      class_path: "my_hooks.PerformanceAnalysisHook"
      enabled: true
      phase: "after_evaluation"
      priority: 15
      config:
        save_plots: true
        output_file: "performance_analysis.json"

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  save_to_file: true
  include_client_id: true  # åŒºåˆ†å®¢æˆ·ç«¯æ—¥å¿—
  
  formatters:
    default: "[%(asctime)s][%(name)s][%(levelname)s] %(message)s"
    client: "[%(asctime)s][Client-%(client_id)s][%(name)s][%(levelname)s] %(message)s"
```

### å¤šLearneråä½œå®éªŒ
```yaml
# experiment_config.yaml  
experiment:
  name: "multi_learner_collaboration_mnist"
  description: "å¤šlearneråä½œçš„MNISTæŒç»­å­¦ä¹ å®éªŒ"
  output_dir: "experiments/multi_learner_test"

# æ•°æ®é…ç½®ï¼ˆåŒä¸Šï¼‰
data:
  dataset: "MNIST"
  dataset_path: "./data/MNIST"
  task_sequence:
    num_tasks: 5
    task_type: "split"
    classes_per_task: 2

# è”é‚¦å­¦ä¹ é…ç½®ï¼ˆåŒä¸Šï¼‰
federation:
  num_clients: 5
  participation_rate: 0.8

# æ¨¡å‹é…ç½® - æ”¯æŒå¤šç§æ¨¡å‹
model:
  models:
    - name: "cnn_model"
      type: "simple_cnn"
      input_shape: [1, 28, 28]
      num_classes: 10
      
    - name: "resnet_model" 
      type: "resnet18"
      input_shape: [1, 28, 28]
      num_classes: 10

# å¤šLearneré…ç½®
learners:
  - name: "ewc_learner"
    type: "EWCLearner"
    model: "cnn_model"
    config:
      lambda_ewc: 0.4
      sample_size: 200
      
  - name: "mas_learner"
    type: "MASLearner" 
    model: "resnet_model"
    config:
      lambda_mas: 0.1
      accumulate_gradients: true
      
  - name: "replay_learner"
    type: "ReplayLearner"
    model: "cnn_model"
    config:
      buffer_size: 500
      replay_batch_size: 16

# å¤šLearneråè°ƒé…ç½®
multi_learner:
  coordination:
    enabled: true
    strategy: "feature_exchange"  # æˆ– "ensemble", "distillation"
    
    # ç‰¹å¾äº¤æ¢é…ç½®
    feature_exchange:
      frequency: 2  # æ¯2è½®äº¤æ¢ä¸€æ¬¡
      layer_names: ["fc1", "fc2"]  # äº¤æ¢çš„å±‚
      aggregation: "weighted_average"  # èšåˆæ–¹å¼
      
  # Learneræƒé‡åˆ†é…
  learner_weights:
    ewc_learner: 0.4
    mas_learner: 0.4  
    replay_learner: 0.2

# Hooké…ç½® - åŒ…å«å¤šLearnerä¸“ç”¨Hook
hooks:
  enabled: true
  
  # å¤šLearner Hook
  learner_coordination_hook:
    enabled: true
    priority: 0
    config:
      coordination_strategy: "adaptive"
      resource_aware: true
      
  feature_exchange_hook:
    enabled: true
    priority: 1
    config:
      exchange_frequency: 2
      aggregation_method: "attention"
      
  ensemble_evaluation_hook:
    enabled: true
    priority: 5
    config:
      voting_strategy: "weighted"
      confidence_threshold: 0.8
      
  # å…¶ä»–Hook
  checkpoint_hook:
    enabled: true
    priority: 0
    
  tensorboard_hook:
    enabled: true
    priority: 10
    config:
      log_multi_learner: true  # è®°å½•æ¯ä¸ªlearnerçš„æŒ‡æ ‡

# æ—¥å¿—é…ç½® - æ”¯æŒå¤šLearneråŒºåˆ†
logging:
  level: "INFO"
  save_to_file: true
  include_client_id: true
  include_learner_id: true  # åŒºåˆ†learneræ—¥å¿—
  
  formatters:
    multi_learner: "[%(asctime)s][Client-%(client_id)s][Learner-%(learner_id)s][%(name)s][%(levelname)s] %(message)s"
```

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å…‹éš†é¡¹ç›®
git clone <repository_url>
cd Moe-Fedcl

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æˆ–ä½¿ç”¨uvï¼ˆæ¨èï¼‰
uv sync
```

### 2. è¿è¡ŒåŸºç¡€å®éªŒ
```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp examples/config_templates/experiment_config.yaml my_experiment_config.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼ˆæ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
vim my_experiment_config.yaml

# è¿è¡Œå®éªŒ
python main.py --config my_experiment_config.yaml
```

### 3. å¸¸è§ä½¿ç”¨åœºæ™¯

#### åœºæ™¯1ï¼šMNISTåˆ†ç±»æŒç»­å­¦ä¹ 
```yaml
# åŸºç¡€MNISTé…ç½®
data:
  dataset: "MNIST"
  task_sequence:
    num_tasks: 5
    classes_per_task: 2
    
learners:
  - name: "ewc_learner"
    type: "EWCLearner"
    config:
      lambda_ewc: 0.4
```

#### åœºæ™¯2ï¼šå¤šå®¢æˆ·ç«¯è”é‚¦å­¦ä¹ 
```yaml
# å¤šå®¢æˆ·ç«¯é…ç½®
federation:
  num_clients: 10
  participation_rate: 0.8
  
  client_data:
    distribution: "non_iid"
    alpha: 0.5  # Dirichletåˆ†å¸ƒå‚æ•°
```

#### åœºæ™¯3ï¼šå¤šLearneré›†æˆ
```yaml
# å¤šlearneré…ç½®
learners:
  - name: "ewc_learner"
    type: "EWCLearner"
  - name: "replay_learner" 
    type: "ReplayLearner"
    
multi_learner:
  coordination:
    strategy: "ensemble"
```

### 4. è°ƒè¯•ä¸ç›‘æ§

#### å¯ç”¨è¯¦ç»†æ—¥å¿—
```yaml
logging:
  level: "DEBUG"
  include_client_id: true
  include_learner_id: true
```

#### ä½¿ç”¨TensorBoard
```yaml
hooks:
  tensorboard_hook:
    enabled: true
    config:
      log_dir: "runs"
      log_multi_learner: true
```

#### æ€§èƒ½ç›‘æ§
```yaml
hooks:
  resource_monitoring_hook:
    enabled: true
    config:
      monitor_memory: true
      monitor_gpu: true
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜ä¸è¶³
**é—®é¢˜**: è¿è¡Œå¤šlearnerå®éªŒæ—¶å†…å­˜æº¢å‡º
**è§£å†³**: 
```yaml
# å‡å°‘batch size
training:
  batch_size: 16  # ä»32å‡å°‘åˆ°16

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model:
  gradient_checkpointing: true

# é™åˆ¶å¹¶å‘learner
multi_learner:
  max_concurrent_learners: 2
```

#### 2. Hookæ‰§è¡Œé”™è¯¯
**é—®é¢˜**: è‡ªå®šä¹‰Hookå¯¼è‡´å®éªŒä¸­æ–­
**è§£å†³**:
```yaml
# ç¦ç”¨æœ‰é—®é¢˜çš„Hook
hooks:
  custom_hooks:
    - name: "ProblematicHook"
      enabled: false

# æˆ–è®¾ç½®é”™è¯¯å¤„ç†ç­–ç•¥
hooks:
  error_handling: "continue"  # ç»§ç»­æ‰§è¡Œå…¶ä»–Hook
```

#### 3. é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯
**é—®é¢˜**: YAMLæ ¼å¼é”™è¯¯å¯¼è‡´é…ç½®è§£æå¤±è´¥
**è§£å†³**:
```bash
# éªŒè¯YAMLæ ¼å¼
python -c "import yaml; yaml.safe_load(open('my_config.yaml'))"

# ä½¿ç”¨é…ç½®éªŒè¯å·¥å…·
python -m fedcl.config.validator my_config.yaml
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. æ•°æ®åŠ è½½ä¼˜åŒ–
```yaml
data:
  dataloader:
    num_workers: 4
    pin_memory: true
    prefetch_factor: 2
```

#### 2. Hookä¼˜å…ˆçº§ä¼˜åŒ–
```yaml
hooks:
  # å…³é”®Hookä½¿ç”¨ä½æ•°å­—ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
  checkpoint_hook:
    priority: 0
    
  # éå…³é”®Hookä½¿ç”¨é«˜æ•°å­—ï¼ˆä½ä¼˜å…ˆçº§ï¼‰  
  visualization_hook:
    priority: 20
```

#### 3. æ¨¡å‹å¹¶è¡ŒåŒ–
```yaml
model:
  parallel:
    enabled: true
    devices: [0, 1]  # ä½¿ç”¨å¤šGPU
```

## ğŸ“– æ€»ç»“

é€šè¿‡æœ¬æ–‡æ¡£ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿï¼š

1. âœ… **ç†è§£FedCLæ¡†æ¶æ¶æ„**ï¼šæŒæ¡è”é‚¦å­¦ä¹ ã€æŒç»­å­¦ä¹ ã€Hookç³»ç»Ÿçš„æ ¸å¿ƒæ¦‚å¿µ
2. âœ… **é…ç½®è‡ªå·±çš„å®éªŒ**ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„learnerã€æ¨¡å‹ã€Hookç»„åˆ
3. âœ… **å¼€å‘è‡ªå®šä¹‰ç»„ä»¶**ï¼šå®ç°è‡ªå·±çš„learnerã€Hookã€èšåˆå™¨ç­‰ç»„ä»¶
4. âœ… **ç›‘æ§å’Œè°ƒè¯•å®éªŒ**ï¼šä½¿ç”¨æ—¥å¿—ã€TensorBoardã€æ€§èƒ½ç›‘æ§ç­‰å·¥å…·
5. âœ… **ä¼˜åŒ–å®éªŒæ€§èƒ½**ï¼šåˆç†é…ç½®èµ„æºã€ä¼˜å…ˆçº§ã€å¹¶è¡ŒåŒ–ç­‰å‚æ•°

### ç¤¾åŒºèµ„æº
- æäº¤Issue: [GitHub Issues](https://github.com/UPC518/MOE-FedCL/issues)
- è®¨è®ºäº¤æµ: [GitHub Discussions](https://github.com/UPC518/MOE-FedCL/discussions)

---

**ğŸ’¡ æç¤º**: å»ºè®®ä»åŸºç¡€é…ç½®å¼€å§‹ï¼Œé€æ­¥æ·»åŠ é«˜çº§åŠŸèƒ½ã€‚Hookç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„æ‰©å±•èƒ½åŠ›ï¼Œä½†åº”æ ¹æ®å®é™…éœ€æ±‚è°¨æ…ä½¿ç”¨ï¼Œé¿å…è¿‡åº¦å¤æ‚åŒ–ã€‚

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£æˆ–æäº¤Issueã€‚ç¥æ‚¨å®éªŒé¡ºåˆ©ï¼ ğŸ‰
