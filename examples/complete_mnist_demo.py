"""
å®Œæ•´çš„MNISTè”é‚¦å­¦ä¹ æ¼”ç¤º
å±•ç¤ºå¤šè½®è®­ç»ƒå’Œæ€§èƒ½æ”¹è¿›
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from examples.fedavg_mnist_trainer import FedAvgMNISTTrainer
from examples.mnist_learner import MNISTLearner
from datetime import datetime


async def full_demo():
    """å®Œæ•´çš„è”é‚¦å­¦ä¹ æ¼”ç¤º"""
    print("ğŸš€ å®Œæ•´ MNIST è”é‚¦å­¦ä¹ æ¼”ç¤º")
    print("="*50)
    
    # é…ç½®å‚æ•°
    num_clients = 4
    num_rounds = 5
    clients_per_round = 3
    local_epochs = 2
    
    print(f"ğŸ“‹ å®éªŒé…ç½®:")
    print(f"   å®¢æˆ·ç«¯æ•°é‡: {num_clients}")
    print(f"   è®­ç»ƒè½®æ•°: {num_rounds}")
    print(f"   æ¯è½®å‚ä¸å®¢æˆ·ç«¯: {clients_per_round}")
    print(f"   æœ¬åœ°è®­ç»ƒè½®æ•°: {local_epochs}")
    print("="*50)
    
    # 1. åˆ›å»ºè®­ç»ƒå™¨
    trainer = FedAvgMNISTTrainer(
        trainer_id="full_server",
        model_config={"input_size": 784, "hidden_size": 128, "output_size": 10}
    )
    trainer.local_epochs = local_epochs
    
    # 2. åˆ›å»ºå®¢æˆ·ç«¯
    print("\nğŸ—ï¸  åˆ›å»ºå®¢æˆ·ç«¯")
    all_clients = []
    
    for i in range(num_clients):
        client_id = f"client_{i}"
        learner = MNISTLearner(
            client_id=client_id,
            training_config={
                "learning_rate": 0.05 + i * 0.01,  # ä¸åŒå­¦ä¹ ç‡
                "batch_size": 32
            }
        )
        trainer.add_learner(client_id, learner)
        all_clients.append(client_id)
        
        # æ˜¾ç¤ºå®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒ
        stats = learner.get_data_statistics()
        preferred = stats["preferred_classes"]
        total_samples = stats["total_samples"]
        print(f"   ğŸ“± {client_id}: {total_samples}æ ·æœ¬, åå¥½ç±»åˆ«{preferred}")
    
    # 3. æ‰§è¡Œå¤šè½®è”é‚¦å­¦ä¹ 
    print(f"\nğŸ“ å¼€å§‹{num_rounds}è½®è”é‚¦å­¦ä¹ ")
    print("-"*50)
    
    start_time = datetime.now()
    all_results = []
    
    try:
        for round_num in range(num_rounds):
            print(f"\nğŸ”„ ç¬¬ {round_num + 1} è½®è®­ç»ƒ")
            
            # éšæœºé€‰æ‹©å‚ä¸å®¢æˆ·ç«¯
            import random
            selected_clients = random.sample(all_clients, clients_per_round)
            print(f"   å‚ä¸å®¢æˆ·ç«¯: {selected_clients}")
            
            # æ‰§è¡Œè®­ç»ƒ
            round_start = datetime.now()
            result = await trainer.train_round_with_learners(round_num, selected_clients)
            round_time = (datetime.now() - round_start).total_seconds()
            
            # æ”¶é›†ç»“æœ
            all_results.append(result)
            agg_result = result["aggregation_result"]
            
            print(f"   âœ… å®Œæˆ: Loss={agg_result['average_loss']:.4f}, "
                  f"Acc={agg_result['average_accuracy']:.4f}, "
                  f"æ—¶é—´={round_time:.2f}ç§’")
            
            # æ¯è½®åè¯„ä¼°å…¨å±€æ¨¡å‹
            if (round_num + 1) % 2 == 0:  # æ¯2è½®è¯„ä¼°ä¸€æ¬¡
                print(f"   ğŸ“Š å…¨å±€è¯„ä¼°:")
                global_model = await trainer.get_current_model()
                
                total_acc = 0.0
                total_samples = 0
                
                for client_id in all_clients:
                    learner = trainer._direct_learners[client_id]
                    eval_result = await learner.evaluate({
                        "model": global_model["weights"],
                        "test_data": True
                    })
                    
                    acc = eval_result['accuracy']
                    samples = eval_result['samples_count']
                    total_acc += acc * samples
                    total_samples += samples
                    
                    print(f"      ğŸ“± {client_id}: Acc={acc:.4f}")
                
                # è®¡ç®—åŠ æƒå¹³å‡å‡†ç¡®ç‡
                global_acc = total_acc / total_samples if total_samples > 0 else 0.0
                print(f"   ğŸŒŸ å…¨å±€å‡†ç¡®ç‡: {global_acc:.4f}")
        
        end_time = datetime.now()
        total_time = (end_time - start_time).total_seconds()
        
        # 4. æœ€ç»ˆç»“æœæ±‡æ€»
        print("\n" + "="*50)
        print("ğŸ‰ è”é‚¦å­¦ä¹ å®Œæˆï¼")
        print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f}ç§’")
        
        # æ˜¾ç¤ºè®­ç»ƒè½¨è¿¹
        print("\nğŸ“ˆ è®­ç»ƒè½¨è¿¹:")
        for i, result in enumerate(all_results):
            agg_result = result["aggregation_result"]
            print(f"   è½®æ¬¡ {i+1}: Loss={agg_result['average_loss']:.4f}, "
                  f"Acc={agg_result['average_accuracy']:.4f}")
        
        # 5. æœ€ç»ˆå…¨å±€è¯„ä¼°
        print("\nğŸ“Š æœ€ç»ˆå…¨å±€æ¨¡å‹è¯„ä¼°:")
        global_model = await trainer.get_current_model()
        
        client_results = []
        for client_id in all_clients:
            learner = trainer._direct_learners[client_id]
            eval_result = await learner.evaluate({
                "model": global_model["weights"],
                "test_data": True
            })
            client_results.append(eval_result)
            
            acc = eval_result['accuracy']
            loss = eval_result['loss']
            samples = eval_result['samples_count']
            print(f"   ğŸ“± {client_id}: Acc={acc:.4f}, Loss={loss:.4f}, æ ·æœ¬={samples}")
        
        # è®¡ç®—å…¨å±€æŒ‡æ ‡
        total_samples = sum(r['samples_count'] for r in client_results)
        weighted_acc = sum(r['accuracy'] * r['samples_count'] for r in client_results) / total_samples
        weighted_loss = sum(r['loss'] * r['samples_count'] for r in client_results) / total_samples
        
        print(f"\nğŸŒŸ æœ€ç»ˆå…¨å±€æ€§èƒ½:")
        print(f"   å…¨å±€å‡†ç¡®ç‡: {weighted_acc:.4f} ({weighted_acc*100:.2f}%)")
        print(f"   å…¨å±€æŸå¤±: {weighted_loss:.4f}")
        print(f"   æ€»æµ‹è¯•æ ·æœ¬: {total_samples}")
        
        # 6. æ•°æ®åˆ†å¸ƒåˆ†æ
        print(f"\nğŸ“Š æ•°æ®åˆ†å¸ƒåˆ†æ:")
        for client_id in all_clients:
            learner = trainer._direct_learners[client_id]
            stats = learner.get_data_statistics()
            distribution = stats["label_distribution"]
            preferred = stats["preferred_classes"]
            
            # è®¡ç®—åˆ†å¸ƒç†µï¼ˆæ•°æ®å¼‚æ„ç¨‹åº¦ï¼‰
            import numpy as np
            counts = list(distribution.values())
            total_count = sum(counts)
            probs = [c/total_count for c in counts]
            entropy = -sum(p * np.log2(p + 1e-10) for p in probs)
            
            print(f"   ğŸ“± {client_id}:")
            print(f"      åå¥½ç±»åˆ«: {preferred}")
            print(f"      æ•°æ®å¼‚æ„åº¦: {entropy:.3f} (ç†µå€¼)")
            print(f"      æ ·æœ¬åˆ†å¸ƒ: {dict(list(distribution.items())[:5])}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(full_demo())
    
    if success:
        print("\nâœ… MOE-FedCL ç³»ç»ŸéªŒè¯æˆåŠŸï¼")
        print("="*50)
        print("ğŸ¯ éªŒè¯å®Œæˆçš„åŠŸèƒ½:")
        print("   âœ… FedAvgè”é‚¦å¹³å‡ç®—æ³•")
        print("   âœ… å¼‚æ„æ•°æ®åˆ†å¸ƒå¤„ç†")
        print("   âœ… å¤šè½®è®­ç»ƒå’Œèšåˆ") 
        print("   âœ… å…¨å±€æ¨¡å‹è¯„ä¼°")
        print("   âœ… å®¢æˆ·ç«¯é€‰æ‹©æœºåˆ¶")
        print("   âœ… æ¨¡å‹å‚æ•°åŒæ­¥")
        print("   âœ… æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡")
        print("\nğŸŒŸ ç³»ç»Ÿå·²å‡†å¤‡å¥½ç”¨äºå®é™…è”é‚¦å­¦ä¹ ä»»åŠ¡ï¼")
    else:
        print("\nâŒ ç³»ç»ŸéªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1)
