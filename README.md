# FedCL: é€æ˜è”é‚¦æŒç»­å­¦ä¹ æ¡†æ¶

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.8+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

FedCL (Federated Continual Learning) æ˜¯ä¸€ä¸ªå…¨æ–°çš„é€æ˜è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è®©çœŸè”é‚¦å’Œä¼ªè”é‚¦å¯¹ç”¨æˆ·å®Œå…¨é€æ˜ï¼Œä¸“æ³¨äºç®—æ³•é€»è¾‘è€Œéåˆ†å¸ƒå¼ç»†èŠ‚ã€‚

## ğŸ¯ æ ¸å¿ƒç†å¿µ

**åˆ†å¸ƒå¼è”é‚¦å†™ä»£ç è¿‡ç¨‹å’Œé›†ä¸­å¼ä¸€æ ·ï¼Œåº•å±‚è‡ªåŠ¨å¤„ç†æƒé‡ã€æ¢¯åº¦ã€ç‰¹å¾è·å–ç­‰ã€‚**

## âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸš€ **ä¸€è¡Œä»£ç å¯åŠ¨**: `fedcl.train(dataset="mnist", num_clients=3, rounds=10)`
- ğŸ”„ **é€æ˜æ‰§è¡Œæ¨¡å¼**: è‡ªåŠ¨æ£€æµ‹å’Œé€‚é…æœ¬åœ°/ä¼ªè”é‚¦/çœŸè”é‚¦æ¨¡å¼
- ğŸ§© **æ¨¡å—åŒ–è®¾è®¡**: å­¦ä¹ å™¨ã€èšåˆå™¨ã€è¯„ä¼°å™¨ã€è®­ç»ƒå™¨ç»„ä»¶åŒ–
- ğŸ¨ **è£…é¥°å™¨é©±åŠ¨**: `@fedcl.learner`, `@fedcl.aggregator` ç­‰ç®€åŒ–ç»„ä»¶æ³¨å†Œ
- âš™ï¸ **é…ç½®é©±åŠ¨**: YAMLé…ç½®æ–‡ä»¶ç®¡ç†å®éªŒå‚æ•°
- ğŸ”§ **ç”Ÿäº§å°±ç»ª**: æ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼å’Œé”™è¯¯å¤„ç†
- ğŸ“Š **å†…ç½®ç®—æ³•**: FedAvgã€FedProxã€SCAFFOLDç­‰ä¸»æµè”é‚¦å­¦ä¹ ç®—æ³•

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              API Layer              â”‚  â† ç”¨æˆ·æ¥å£å±‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Transparent Layer         â”‚  â† é€æ˜ä»£ç†å±‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Automation Layer          â”‚  â† è‡ªåŠ¨åŒ–å±‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Execution Layer           â”‚  â† æ‰§è¡Œå±‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Comm Layer                â”‚  â† é€šä¿¡å±‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Methods Layer             â”‚  â† ç®—æ³•å±‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Registry Layer            â”‚  â† æ³¨å†Œå±‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.8+
- CUDA (å¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿ)

### å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨pipå®‰è£…
pip install torch torchvision loguru omegaconf

# æˆ–ä½¿ç”¨condaå®‰è£…
conda install pytorch torchvision -c pytorch
pip install loguru omegaconf
```

### å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/your-username/Moe-Fedcl.git
cd Moe-Fedcl
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸€è¡Œä»£ç å¯åŠ¨

```python
import fedcl

# æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
result = fedcl.train(
    dataset="mnist",
    num_clients=3,
    rounds=10
)
print(f"æœ€ç»ˆå‡†ç¡®ç‡: {result.accuracy:.4f}")
```

### 2. è‡ªå®šä¹‰æ¨¡å‹

```python
import torch.nn as nn
from fedcl.methods.learners import DefaultLearner

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )
        self.criterion = nn.CrossEntropyLoss()
    
    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³è¾“å…¥
        return self.network(x)
    
    def forward_with_loss(self, x, target):
        output = self.forward(x)
        loss = self.criterion(output, target)
        return output, loss

# åˆ›å»ºå­¦ä¹ å™¨
config = {
    "model": {"instance": MyModel()},
    "optimizer": {"type": "adam", "learning_rate": 0.01},
    "local_epochs": 2
}
learner = DefaultLearner("client_0", config)
```

### 3. ä½¿ç”¨StandardFederationTrainer

```python
from fedcl.methods.trainers import StandardFederationTrainer

# é…ç½®è®­ç»ƒå™¨
config = {
    "num_clients": 3,
    "local_epochs": 2,
    "learning_rate": 0.01,
    "batch_size": 32,
    "aggregator": "fedavg",
    "learner": "default"
}

# åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
trainer = StandardFederationTrainer(config)
result = await trainer.train()
print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆå‡†ç¡®ç‡: {result.accuracy:.4f}")
```

### 4. è‡ªå®šä¹‰èšåˆå™¨

```python
from fedcl.api import aggregator
from fedcl.methods.aggregators import AbstractAggregator

@aggregator
class MyAggregator(AbstractAggregator):
    def aggregate(self, client_results):
        # å®ç°è‡ªå®šä¹‰èšåˆé€»è¾‘
        aggregated_weights = {}
        total_samples = sum(r["num_samples"] for r in client_results)
        
        for key in client_results[0]["model_weights"].keys():
            aggregated_weights[key] = sum(
                r["model_weights"][key] * r["num_samples"] / total_samples
                for r in client_results
            )
        
        return {
            "aggregated_weights": aggregated_weights,
            "num_clients": len(client_results)
        }
```

## ğŸ“š æ–‡æ¡£

- [é¡¹ç›®è®¾è®¡æ–‡æ¡£](docs/é¡¹ç›®è®¾è®¡æ–‡æ¡£.md) - è¯¦ç»†çš„è®¾è®¡æ€è·¯å’Œæ¶æ„è¯´æ˜
- [å¿«é€Ÿå…¥é—¨æŒ‡å—](docs/å¿«é€Ÿå…¥é—¨æŒ‡å—.md) - å¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹
- [APIå‚è€ƒæ–‡æ¡£](docs/APIå‚è€ƒæ–‡æ¡£.md) - å®Œæ•´çš„APIæ–‡æ¡£
- [æ•°æ®é›†åŠ è½½æœºåˆ¶åˆ†æ](docs/æ•°æ®é›†åŠ è½½æœºåˆ¶åˆ†æ.md) - æ•°æ®ç®¡ç†è¯¦è§£

## ğŸ§ª ç¤ºä¾‹

### MNISTè”é‚¦å­¦ä¹ ç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
å®Œæ•´çš„MNISTè”é‚¦å­¦ä¹ ç¤ºä¾‹
"""

import torch.nn as nn
from fedcl.methods.learners import DefaultLearner
from fedcl.methods.trainers import StandardFederationTrainer

# 1. å®šä¹‰æ¨¡å‹
class MNISTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )
        self.criterion = nn.CrossEntropyLoss()
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        return self.network(x)
    
    def forward_with_loss(self, x, target):
        output = self.forward(x)
        loss = self.criterion(output, target)
        return output, loss

# 2. é…ç½®è®­ç»ƒå™¨
config = {
    "num_clients": 3,
    "local_epochs": 2,
    "learning_rate": 0.01,
    "batch_size": 32,
    "aggregator": "fedavg",
    "learner": "default"
}

# 3. åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
trainer = StandardFederationTrainer(config)
result = await trainer.train()

print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼")
print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {result.accuracy:.4f}")
print(f"   è®­ç»ƒè½®æ•°: {result.rounds}")
print(f"   å®¢æˆ·ç«¯æ•°é‡: {result.num_clients}")
```

è¿è¡Œç¤ºä¾‹ï¼š
```bash
python example_mnist_federation.py
```

## ğŸ”§ é…ç½®é€‰é¡¹

### åŸºç¡€é…ç½®

```python
config = {
    # æ•°æ®é›†é…ç½®
    "dataset": "mnist",
    "data_path": "./data",
    "batch_size": 32,
    
    # è”é‚¦å­¦ä¹ é…ç½®
    "num_clients": 3,
    "rounds": 10,
    "local_epochs": 2,
    "client_selection_ratio": 1.0,
    
    # ç»„ä»¶é…ç½®
    "learner": "default",
    "aggregator": "fedavg",
    "evaluator": "prototype",
    
    # æ¨¡å‹é…ç½®
    "model": {
        "type": "mlp",
        "input_dim": 784,
        "hidden_dims": [128, 64],
        "output_dim": 10
    },
    
    # ä¼˜åŒ–å™¨é…ç½®
    "optimizer": {
        "type": "adam",
        "learning_rate": 0.01
    }
}
```

### é«˜çº§é…ç½®

```python
config = {
    # æ‰§è¡Œæ¨¡å¼é…ç½®
    "execution": {
        "mode": "auto",  # auto, local, pseudo, distributed
        "num_workers": 4,
        "timeout": 300
    },
    
    # é€šä¿¡é…ç½®
    "communication": {
        "transport": "auto",  # auto, memory, process, network
        "host": "localhost",
        "port": 8080
    },
    
    # æ•°æ®åˆ†åŒºé…ç½®
    "data_partition": {
        "type": "iid",  # iid, non_iid_label, non_iid_quantity
        "alpha": 0.5  # ç”¨äºnon_iid_labelçš„Dirichletåˆ†å¸ƒå‚æ•°
    }
}
```

## ğŸ¯ æ‰§è¡Œæ¨¡å¼

### æœ¬åœ°æ¨¡æ‹Ÿæ¨¡å¼
- **ç‰¹ç‚¹**: å•æœºå¤šè¿›ç¨‹æ¨¡æ‹Ÿè”é‚¦å­¦ä¹ 
- **é€‚ç”¨åœºæ™¯**: ç®—æ³•éªŒè¯ã€å¿«é€ŸåŸå‹
- **ä¼˜åŠ¿**: å¼€å‘æ•ˆç‡é«˜ï¼Œè°ƒè¯•æ–¹ä¾¿

### ä¼ªè”é‚¦æ¨¡å¼
- **ç‰¹ç‚¹**: å•æœºå¤šè¿›ç¨‹ï¼ŒçœŸå®ç½‘ç»œé€šä¿¡
- **é€‚ç”¨åœºæ™¯**: é€šä¿¡åè®®æµ‹è¯•ã€æ€§èƒ½åŸºå‡†
- **ä¼˜åŠ¿**: çœŸå®é€šä¿¡ï¼Œå•æœºéƒ¨ç½²

### çœŸè”é‚¦æ¨¡å¼
- **ç‰¹ç‚¹**: å¤šæœºåˆ†å¸ƒå¼ï¼ŒçœŸå®ç½‘ç»œé€šä¿¡
- **é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡éƒ¨ç½²
- **ä¼˜åŠ¿**: çœŸå®åˆ†å¸ƒå¼ï¼Œå¯æ‰©å±•æ€§å¼º

## ğŸ” ç»„ä»¶ç®¡ç†

### æŸ¥çœ‹å¯ç”¨ç»„ä»¶

```python
# åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ç»„ä»¶
components = fedcl.list_components()
print("å¯ç”¨ç»„ä»¶:", components)

# è·å–ç»„ä»¶è¯¦ç»†ä¿¡æ¯
info = fedcl.get_component_info("fedavg")
print("FedAvgèšåˆå™¨ä¿¡æ¯:", info)
```

### å†…ç½®ç»„ä»¶

- **å­¦ä¹ å™¨**: `default`, `contrastive`, `personalized_client`, `meta`
- **èšåˆå™¨**: `fedavg`, `fedprox`, `scaffold`, `fednova`, `fedadam`, `fedyogi`, `feddyn`
- **è¯„ä¼°å™¨**: `prototype`, `fairness`
- **è®­ç»ƒå™¨**: `standard_federation`, `personalized_federation`

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### è‡ªå®šä¹‰ç»„ä»¶

```python
from fedcl.api import learner
from fedcl.execution.base_learner import AbstractLearner

@learner
class CustomLearner(AbstractLearner):
    def __init__(self, client_id: str, config: Dict[str, Any]):
        super().__init__(client_id, config)
        # åˆå§‹åŒ–ä»£ç 
    
    async def train_epoch(self, **kwargs):
        # è®­ç»ƒé€»è¾‘
        return {"model_weights": weights, "loss": loss}
    
    async def evaluate(self, **kwargs):
        # è¯„ä¼°é€»è¾‘
        return {"accuracy": acc, "loss": loss}
    
    def get_model_weights(self):
        return self.model.state_dict()
    
    def set_model_weights(self, weights):
        self.model.load_state_dict(weights)
```

### æœ€ä½³å®è·µ

1. **æ¨¡å‹è®¾è®¡**: å®ç° `forward_with_loss` æ–¹æ³•ï¼Œæ”¯æŒå†…ç½®æŸå¤±è®¡ç®—
2. **å­¦ä¹ å™¨è®¾è®¡**: ç»§æ‰¿ `AbstractLearner`ï¼Œå®ç°æ‰€æœ‰æŠ½è±¡æ–¹æ³•
3. **é…ç½®ç®¡ç†**: ä½¿ç”¨YAMLæ–‡ä»¶ç®¡ç†é…ç½®ï¼Œåˆ†ç¦»å¼€å‘å’Œç”Ÿäº§é…ç½®
4. **é”™è¯¯å¤„ç†**: å®ç°é€‚å½“çš„å¼‚å¸¸å¤„ç†ï¼Œä½¿ç”¨æ—¥å¿—è®°å½•å…³é”®ä¿¡æ¯
5. **æ€§èƒ½ä¼˜åŒ–**: é€‰æ‹©åˆé€‚çš„æ‰§è¡Œæ¨¡å¼ï¼Œä¼˜åŒ–æ•°æ®ä¼ è¾“

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç»„ä»¶æœªæ³¨å†Œ**
   ```
   ValueError: å­¦ä¹ å™¨ 'my_learner' æœªæ³¨å†Œ
   ```
   **è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿ä½¿ç”¨ `@fedcl.learner` è£…é¥°å™¨æ³¨å†Œç»„ä»¶

2. **é…ç½®é”™è¯¯**
   ```
   ValueError: é…ç½®é¡¹ 'dataset' ç¼ºå¤±
   ```
   **è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥é…ç½®æ–‡ä»¶ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€é¡¹éƒ½å­˜åœ¨

3. **æ¨¡å‹æƒé‡ä¸åŒ¹é…**
   ```
   RuntimeError: size mismatch
   ```
   **è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿æ‰€æœ‰å®¢æˆ·ç«¯çš„æ¨¡å‹ç»“æ„ä¸€è‡´

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è°ƒè¯•æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# ä½¿ç”¨æœ¬åœ°æ¨¡å¼å¿«é€Ÿè°ƒè¯•
config = {"execution": {"mode": "local"}}

# æ£€æŸ¥ç»„ä»¶æ³¨å†ŒçŠ¶æ€
print(fedcl.list_components())
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è´¡çŒ®æŒ‡å—ã€‚

### è´¡çŒ®æ–¹å¼

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“ è”ç³»æˆ‘ä»¬

- é¡¹ç›®ä¸»é¡µ: [https://github.com/your-username/Moe-Fedcl](https://github.com/your-username/Moe-Fedcl)
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/your-username/Moe-Fedcl/issues)
- è®¨è®ºåŒº: [Discussions](https://github.com/your-username/Moe-Fedcl/discussions)

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºè¿™ä¸ªé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…å’Œç ”ç©¶äººå‘˜ï¼

---

**FedCL** - è®©è”é‚¦å­¦ä¹ å˜å¾—ç®€å•é€æ˜ï¼ ğŸš€
