# fedcl/api/trainer.py
"""
ç»Ÿä¸€çš„è”é‚¦è®­ç»ƒå™¨

æä¾›ç®€æ´ç»Ÿä¸€çš„è”é‚¦å­¦ä¹ æŽ¥å£ï¼Œæ”¯æŒå¤šç§åˆå§‹åŒ–æ–¹å¼å’Œè‡ªåŠ¨æ¨¡å¼æ£€æµ‹ã€‚
å®žçŽ°çœŸè”é‚¦å’Œä¼ªè”é‚¦çš„å®Œå…¨é€æ˜Žåˆ‡æ¢ã€‚
"""

import time
import warnings
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import torch
from loguru import logger
from omegaconf import DictConfig, OmegaConf

from ..transparent.base_federation_engine import BaseFederationEngine as TransparentExecutionEngine


@dataclass
class TrainingResult:
    """è”é‚¦è®­ç»ƒç»“æžœ"""

    experiment_name: str
    total_rounds: int
    final_metrics: Dict[str, float]
    round_history: List[Dict[str, Any]]
    training_time: float
    client_results: Dict[str, Any] = field(default_factory=dict)
    global_model_path: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

    @property
    def average_accuracy(self) -> float:
        """èŽ·å–å¹³å‡å‡†ç¡®çŽ‡"""
        if "average_accuracy" in self.final_metrics:
            return self.final_metrics["average_accuracy"]
        return 0.0

    @property
    def forgetting(self) -> float:
        """èŽ·å–é—å¿˜åº¦"""
        if "forgetting" in self.final_metrics:
            return self.final_metrics["forgetting"]
        return 0.0


@dataclass
class EvaluationResult:
    """è¯„ä¼°ç»“æžœ"""

    metrics: Dict[str, float]
    task_accuracies: Dict[str, float] = field(default_factory=dict)
    evaluation_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)


class FederatedTrainer:
    """
    ç»Ÿä¸€çš„è”é‚¦è®­ç»ƒå™¨

    æä¾›ç®€æ´ç»Ÿä¸€çš„è”é‚¦å­¦ä¹ æŽ¥å£ï¼Œæ”¯æŒï¼š
    1. å¤šç§åˆå§‹åŒ–æ–¹å¼ï¼ˆé…ç½®æ–‡ä»¶ã€å­—å…¸ã€å‚æ•°ï¼‰
    2. è‡ªåŠ¨æ¨¡å¼æ£€æµ‹ï¼ˆçœŸè”é‚¦/ä¼ªè”é‚¦/æœ¬åœ°æ¨¡æ‹Ÿï¼‰
    3. é€æ˜Žçš„æ‰§è¡Œå¼•æ“Ž
    4. ç»Ÿä¸€çš„è®­ç»ƒå’Œè¯„ä¼°æŽ¥å£

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # æ–¹å¼1ï¼šæœ€ç®€å•çš„ä½¿ç”¨
        trainer = FederatedTrainer(
            learner="ewc_mnist",
            dataset="mnist",
            num_clients=3
        )
        result = trainer.train(num_rounds=10)

        # æ–¹å¼2ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶
        trainer = FederatedTrainer.from_config("config.yaml")
        result = trainer.train()

        # æ–¹å¼3ï¼šä½¿ç”¨é…ç½®å­—å…¸
        config = {"learner": "ewc_mnist", "dataset": "mnist"}
        trainer = FederatedTrainer(config)
        result = trainer.train()
    """

    def __init__(
        self,
        config: Optional[Union[str, Path, Dict[str, Any], DictConfig]] = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–è”é‚¦è®­ç»ƒå™¨

        Args:
            config: é…ç½®æ–‡ä»¶è·¯å¾„ã€é…ç½®å­—å…¸æˆ–DictConfigå¯¹è±¡
            **kwargs: é¢å¤–çš„é…ç½®å‚æ•°ï¼Œä¼šè¦†ç›–configä¸­çš„è®¾ç½®

        æ”¯æŒçš„kwargså‚æ•°ï¼š
            - learner: å­¦ä¹ å™¨åç§°
            - aggregator: èšåˆå™¨åç§°
            - evaluator: è¯„ä¼°å™¨åç§°
            - dataset: æ•°æ®é›†åç§°
            - num_clients: å®¢æˆ·ç«¯æ•°é‡
            - num_rounds: è®­ç»ƒè½®æ¬¡
            - execution_mode: æ‰§è¡Œæ¨¡å¼ï¼ˆauto/true_federation/pseudo_federationï¼‰
            - experiment_name: å®žéªŒåç§°
        """
        self.start_time = time.time()

        # è§£æžå’Œåˆå¹¶é…ç½®
        self.config = self._parse_config(config, **kwargs)

        # è®¾ç½®å®žéªŒåç§°
        self.experiment_name = self.config.get(
            "experiment_name", "federated_experiment"
        )

        # åˆ›å»ºç»„ä»¶æ—¥å¿—å™¨
        self.logger = logger.bind(component="FederatedTrainer", experiment=self.experiment_name)

        # å»¶è¿Ÿåˆå§‹åŒ–çš„ç»„ä»¶ï¼ˆåœ¨éœ€è¦æ—¶åˆ›å»ºï¼‰
        self._execution_engine = None
        self._is_initialized = False

        self.logger.info(f"âœ… FederatedTrainer åˆå§‹åŒ–å®Œæˆ: {self.experiment_name}")
        self.logger.debug(f"ðŸ“ é…ç½®: {dict(self.config)}")

    @classmethod
    def from_config(cls, config_path: Union[str, Path], **kwargs) -> "FederatedTrainer":
        """
        ä»Žé…ç½®æ–‡ä»¶åˆ›å»ºè®­ç»ƒå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            **kwargs: é¢å¤–å‚æ•°ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®

        Returns:
            FederatedTrainerå®žä¾‹
        """
        return cls(config=config_path, **kwargs)

    def _parse_config(
        self, config: Optional[Union[str, Path, Dict[str, Any], DictConfig]], **kwargs
    ) -> DictConfig:
        """
        è§£æžå’Œåˆå¹¶é…ç½®

        ä¼˜å…ˆçº§ï¼ˆä»Žé«˜åˆ°ä½Žï¼‰ï¼š
        1. kwargså‚æ•°
        2. configå‚æ•°
        3. é»˜è®¤é…ç½®
        """
        # é»˜è®¤é…ç½®
        default_config = {
            "experiment_name": "federated_experiment",
            "execution_mode": "auto",  # auto, true_federation, pseudo_federation
            "learner": "simple_learner",
            "learner_name": None,  # ðŸ†• ä»Žæ³¨å†Œè¡¨èŽ·å–ç”¨æˆ·è‡ªå®šä¹‰learner
            "learner_type": "standard",  # ðŸ†• å†…ç½®learnerç±»åž‹å›žé€€
            "aggregator": "fedavg",
            "aggregator_name": None,  # ðŸ†• ä»Žæ³¨å†Œè¡¨èŽ·å–ç”¨æˆ·è‡ªå®šä¹‰èšåˆå™¨
            "aggregator_type": "fedavg",  # ðŸ†• å†…ç½®èšåˆå™¨ç±»åž‹å›žé€€
            "evaluator": "accuracy",
            "evaluator_name": None,  # ðŸ†• ä»Žæ³¨å†Œè¡¨èŽ·å–ç”¨æˆ·è‡ªå®šä¹‰è¯„ä¼°å™¨
            "evaluator_type": "accuracy",  # ðŸ†• å†…ç½®è¯„ä¼°å™¨ç±»åž‹å›žé€€
            "trainer_name": None,  # ðŸ†• ä»Žæ³¨å†Œè¡¨èŽ·å–ç”¨æˆ·è‡ªå®šä¹‰trainer
            "trainer_type": "standard",  # ðŸ†• å†…ç½®trainerç±»åž‹å›žé€€
            "dataset": "mnist",
            "num_clients": 3,
            "num_rounds": 10,
            "federation": {"client_selection": "random", "participation_rate": 1.0},
            "training": {"local_epochs": 1, "batch_size": 32, "learning_rate": 0.01},
            "logging": {"level": "INFO", "enable_debug": False},
        }

        # åˆ›å»ºåŸºç¡€é…ç½®
        final_config = OmegaConf.create(default_config)

        # åˆå¹¶è¾“å…¥é…ç½®
        if config is not None:
            if isinstance(config, (str, Path)):
                # é…ç½®æ–‡ä»¶è·¯å¾„
                try:
                    file_config = OmegaConf.load(config)
                    final_config = OmegaConf.merge(final_config, file_config)
                except Exception as e:
                    warnings.warn(f"æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config}: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            elif isinstance(config, dict):
                # é…ç½®å­—å…¸
                dict_config = OmegaConf.create(config)
                final_config = OmegaConf.merge(final_config, dict_config)
            elif isinstance(config, DictConfig):
                # DictConfigå¯¹è±¡
                final_config = OmegaConf.merge(final_config, config)

        # åˆå¹¶kwargså‚æ•°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if kwargs:
            # å¤„ç†åµŒå¥—é…ç½®å‚æ•°
            processed_kwargs = {}
            for key, value in kwargs.items():
                if key in ["local_epochs", "batch_size", "learning_rate"]:
                    # è¿™äº›å‚æ•°å±žäºŽtrainingé…ç½®
                    if "training" not in processed_kwargs:
                        processed_kwargs["training"] = {}
                    processed_kwargs["training"][key] = value
                elif key in ["client_selection", "participation_rate"]:
                    # è¿™äº›å‚æ•°å±žäºŽfederationé…ç½®
                    if "federation" not in processed_kwargs:
                        processed_kwargs["federation"] = {}
                    processed_kwargs["federation"][key] = value
                elif key in ["level", "enable_debug"]:
                    # è¿™äº›å‚æ•°å±žäºŽloggingé…ç½®
                    if "logging" not in processed_kwargs:
                        processed_kwargs["logging"] = {}
                    processed_kwargs["logging"][key] = value
                else:
                    # é¡¶çº§é…ç½®
                    processed_kwargs[key] = value
            
            kwargs_config = OmegaConf.create(processed_kwargs)
            final_config = OmegaConf.merge(final_config, kwargs_config)

        # ðŸ†• éªŒè¯å’Œè§„èŒƒåŒ–è£…é¥°å™¨ç»„ä»¶é…ç½®
        final_config = self._normalize_component_config(final_config)

        return final_config
    
    def _normalize_component_config(self, config: DictConfig) -> DictConfig:
        """
        ðŸ†• éªŒè¯å’Œè§„èŒƒåŒ–è£…é¥°å™¨ç»„ä»¶é…ç½®
        
        å¤„ç†ä¼˜å…ˆçº§ï¼š
        1. xxx_name (ä»Žæ³¨å†Œè¡¨èŽ·å–ç”¨æˆ·è‡ªå®šä¹‰ç»„ä»¶) - æœ€é«˜ä¼˜å…ˆçº§
        2. xxx (å…¼å®¹æ€§å­—æ®µï¼Œæ˜ å°„åˆ°xxx_name)
        3. xxx_type (å†…ç½®ç»„ä»¶ç±»åž‹) - å›žé€€é€‰é¡¹
        
        Args:
            config: åŽŸå§‹é…ç½®
            
        Returns:
            DictConfig: è§„èŒƒåŒ–åŽçš„é…ç½®
        """
        from ..registry import registry
        
        # å¯¹äºŽlearneré…ç½®çš„å¤„ç†
        self._normalize_single_component_config(
            config, "learner", registry.learners, 
            "learner_name", "learner_type"
        )
        
        # å¯¹äºŽaggregatoré…ç½®çš„å¤„ç†
        self._normalize_single_component_config(
            config, "aggregator", registry.aggregators,
            "aggregator_name", "aggregator_type"
        )
        
        # å¯¹äºŽevaluatoré…ç½®çš„å¤„ç†
        self._normalize_single_component_config(
            config, "evaluator", registry.evaluators,
            "evaluator_name", "evaluator_type"
        )
        
        # å¯¹äºŽtraineré…ç½®çš„å¤„ç†
        self._normalize_single_component_config(
            config, "trainer", registry.trainers,
            "trainer_name", "trainer_type"
        )
        
        return config
    
    def _normalize_single_component_config(self, config: DictConfig, 
                                         legacy_key: str, registry_dict: dict,
                                         name_key: str, type_key: str) -> None:
        """
        è§„èŒƒåŒ–å•ä¸ªç»„ä»¶çš„é…ç½®
        
        Args:
            config: é…ç½®å¯¹è±¡
            legacy_key: é—ç•™å­—æ®µå (learner/aggregator/evaluator/trainer)
            registry_dict: æ³¨å†Œè¡¨å­—å…¸
            name_key: ç”¨æˆ·è‡ªå®šä¹‰ç»„ä»¶åå­—æ®µ (learner_name/aggregator_name...)
            type_key: å†…ç½®ç±»åž‹å­—æ®µ (learner_type/aggregator_type...)
        """
        # èŽ·å–å„ç§é…ç½®å€¼
        name_value = config.get(name_key)
        legacy_value = config.get(legacy_key) 
        type_value = config.get(type_key)
        
        # ä¼˜å…ˆçº§å¤„ç†ï¼š
        # 1. å¦‚æžœæŒ‡å®šäº†xxx_nameï¼Œä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰ç»„ä»¶
        if name_value and name_value in registry_dict:
            self.logger.debug(f"ðŸ†• ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰{legacy_key}: {name_value}")
            return
        
        # 2. å¦‚æžœæŒ‡å®šäº†legacyå­—æ®µï¼Œå°è¯•æ˜ å°„åˆ°æ³¨å†Œè¡¨
        if legacy_value and legacy_value in registry_dict:
            config[name_key] = legacy_value
            self.logger.debug(f"ðŸ†• å°†{legacy_key}='{legacy_value}'æ˜ å°„åˆ°{name_key}")
            return
        
        # 3. éƒ½æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨å†…ç½®ç±»åž‹ä½œä¸ºå›žé€€
        if not type_value:
            # è®¾ç½®é»˜è®¤çš„å†…ç½®ç±»åž‹
            default_types = {
                "learner": "standard",
                "aggregator": "fedavg", 
                "evaluator": "accuracy",
                "trainer": "standard"
            }
            config[type_key] = default_types.get(legacy_key, "standard")
            self.logger.debug(f"ðŸ†• ä½¿ç”¨é»˜è®¤{type_key}: {config[type_key]}")

    def _get_execution_engine(self) -> TransparentExecutionEngine:
        """èŽ·å–æ‰§è¡Œå¼•æ“Žï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._execution_engine is None:
            self.logger.info("ðŸ”§ åˆå§‹åŒ–é€æ˜Žæ‰§è¡Œå¼•æ“Ž")
            self._execution_engine = TransparentExecutionEngine(self.config)
            self._is_initialized = True
        return self._execution_engine

    def train(self, num_rounds: Optional[int] = None, **kwargs) -> TrainingResult:
        """
        æ‰§è¡Œè”é‚¦è®­ç»ƒ

        Args:
            num_rounds: è®­ç»ƒè½®æ¬¡ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„å€¼
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            TrainingResult: è®­ç»ƒç»“æžœ
        """
        if num_rounds is None:
            num_rounds = self.config.get("num_rounds", 10)

        self.logger.info(f"ðŸš€ å¼€å§‹è”é‚¦è®­ç»ƒ - è½®æ¬¡: {num_rounds}")
        self.logger.info(f"ðŸ“Š å®žéªŒ: {self.experiment_name}")

        # èŽ·å–æ‰§è¡Œå¼•æ“Ž
        execution_engine = self._get_execution_engine()

        # æ‰§è¡Œè®­ç»ƒ
        result = execution_engine.execute_training(num_rounds, **kwargs)

        # åˆ›å»ºè®­ç»ƒç»“æžœ
        training_result = TrainingResult(
            experiment_name=self.experiment_name,
            total_rounds=result.total_rounds,
            final_metrics=result.final_metrics,
            round_history=result.round_history,
            training_time=result.training_time,
            client_results=result.client_results,
            global_model_path=result.global_model_path,
            metadata={
                "execution_mode": result.execution_mode,
                "config": dict(self.config),
                **getattr(result, 'metadata', {})
            }
        )

        self.logger.info(f"âœ… è®­ç»ƒå®Œæˆ - è€—æ—¶: {training_result.training_time:.2f}ç§’")
        self.logger.info(f"ðŸ“Š æœ€ç»ˆå‡†ç¡®çŽ‡: {training_result.average_accuracy:.4f}")

        return training_result

    def continue_training(
        self, additional_rounds: int = 5, **kwargs
    ) -> TrainingResult:
        """
        ç»§ç»­è®­ç»ƒ

        Args:
            additional_rounds: é¢å¤–çš„è®­ç»ƒè½®æ¬¡
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            TrainingResult: è®­ç»ƒç»“æžœ
        """
        self.logger.info(f"ðŸ”„ ç»§ç»­è®­ç»ƒ - é¢å¤–è½®æ¬¡: {additional_rounds}")
        
        # ç›®å‰ç®€åŒ–å®žçŽ°ï¼Œç›´æŽ¥è°ƒç”¨train
        return self.train(num_rounds=additional_rounds, **kwargs)

    def evaluate(self, test_data: Optional[Any] = None, **kwargs) -> EvaluationResult:
        """
        æ‰§è¡Œæ¨¡åž‹è¯„ä¼°

        Args:
            test_data: æµ‹è¯•æ•°æ®
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            EvaluationResult: è¯„ä¼°ç»“æžœ
        """
        self.logger.info("ðŸ” å¼€å§‹æ¨¡åž‹è¯„ä¼°")

        # èŽ·å–æ‰§è¡Œå¼•æ“Ž
        execution_engine = self._get_execution_engine()

        # æ‰§è¡Œè¯„ä¼°
        result = execution_engine.execute_evaluation(test_data, **kwargs)

        # åˆ›å»ºè¯„ä¼°ç»“æžœ
        evaluation_result = EvaluationResult(
            metrics=result.metrics,
            task_accuracies=result.task_accuracies,
            evaluation_time=result.evaluation_time,
            metadata={
                "experiment_name": self.experiment_name,
                "config": dict(self.config),
                **result.metadata
            }
        )

        self.logger.info(f"âœ… è¯„ä¼°å®Œæˆ - è€—æ—¶: {evaluation_result.evaluation_time:.2f}ç§’")
        self.logger.info(f"ðŸ“Š å‡†ç¡®çŽ‡: {evaluation_result.metrics.get('accuracy', 0):.4f}")

        return evaluation_result

    def get_config(self) -> DictConfig:
        """èŽ·å–å½“å‰é…ç½®"""
        return self.config

    def get_execution_mode(self) -> Optional[str]:
        """èŽ·å–å½“å‰æ‰§è¡Œæ¨¡å¼"""
        if self._execution_engine:
            mode = self._execution_engine.get_current_mode()
            return mode.value if mode else None
        return None

    def reset(self):
        """é‡ç½®è®­ç»ƒå™¨çŠ¶æ€"""
        self.logger.info("ðŸ”„ é‡ç½®è®­ç»ƒå™¨çŠ¶æ€")
        if self._execution_engine:
            self._execution_engine.reset_state()
        self._is_initialized = False

    def __repr__(self) -> str:
        return (
            f"FederatedTrainer("
            f"experiment='{self.experiment_name}', "
            f"learner='{self.config.get('learner', 'unknown')}', "
            f"clients={self.config.get('num_clients', 0)}, "
            f"mode='{self.get_execution_mode() or 'auto'}'"
            f")"
        )