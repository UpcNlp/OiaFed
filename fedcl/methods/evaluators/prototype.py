"""
åŸå‹è¯„ä¼°å™¨

åŸºäºåŸå‹ï¼ˆprototypeï¼‰çš„è¯„ä¼°æ–¹æ³•ï¼Œé€‚ç”¨äºè”é‚¦å­¦ä¹ ä¸­çš„è¡¨å¾å­¦ä¹ è¯„ä¼°ã€‚
é€šè¿‡è®¡ç®—ç±»åŸå‹æ¥è¯„ä¼°æ¨¡å‹çš„è¡¨å¾è´¨é‡ã€‚
"""

import torch
from typing import Dict, Any, Optional, List
from loguru import logger

from ...api.decorators import evaluator


@evaluator("prototype", description="åŸºäºåŸå‹çš„è”é‚¦è¯„ä¼°å™¨")
class PrototypeEvaluator:
    """åŸå‹è¯„ä¼°å™¨å®ç°"""
    
    def __init__(self, config: Dict[str, Any] = None, context: Optional[Any] = None):
        self.config = config or {}
        self.context = context
        
        # è¯„ä¼°å‚æ•°
        self.num_classes = self.config.get("num_classes", 10)
        self.prototype_momentum = self.config.get("prototype_momentum", 0.9)
        
        # åŸå‹çŠ¶æ€
        self.class_prototypes: Optional[torch.Tensor] = None
        self.prototype_counts: Optional[torch.Tensor] = None
        
        logger.info(f"âœ… åŸå‹è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ - ç±»åˆ«æ•°: {self.num_classes}")
    
    def evaluate(self, model: Any, test_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒåŸºäºåŸå‹çš„è¯„ä¼°"""
        # éªŒè¯å¿…éœ€å‚æ•°
        if model is None:
            raise ValueError("å¿…é¡»æä¾›æœ‰æ•ˆçš„æ¨¡å‹å¯¹è±¡")
        
        if "data" not in test_data:
            raise ValueError("ç¼ºå°‘å¿…éœ€çš„æµ‹è¯•æ•°æ® 'data'")
        
        if "labels" not in test_data:
            raise ValueError("ç¼ºå°‘å¿…éœ€çš„æ ‡ç­¾æ•°æ® 'labels'")
        
        # è·å–æ•°æ®
        data = test_data["data"]
        labels = test_data["labels"]
        
        # éªŒè¯æ•°æ®ç±»å‹
        if not isinstance(data, torch.Tensor):
            raise ValueError("data å¿…é¡»æ˜¯ torch.Tensor ç±»å‹")
        
        if not isinstance(labels, torch.Tensor):
            raise ValueError("labels å¿…é¡»æ˜¯ torch.Tensor ç±»å‹")
        
        if data.shape[0] != labels.shape[0]:
            raise ValueError(f"æ•°æ®å’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…: {data.shape[0]} vs {labels.shape[0]}")
        
        # æå–ç‰¹å¾
        features = self._extract_features(model, data)
        
        # è®¡ç®—æˆ–æ›´æ–°åŸå‹
        if self.class_prototypes is None:
            self._initialize_prototypes(features, labels)
        else:
            self._update_prototypes(features, labels)
        
        # åŸºäºåŸå‹çš„åˆ†ç±»
        prototype_predictions = self._classify_with_prototypes(features)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = self._compute_prototype_metrics(prototype_predictions, labels, features)
        
        return metrics
    
    def _extract_features(self, model: Any, data: torch.Tensor) -> torch.Tensor:
        """æå–æ¨¡å‹ç‰¹å¾ï¼ˆå¿…é¡»ä½¿ç”¨çœŸå®æ¨¡å‹ï¼‰"""
        if not hasattr(model, 'forward') and not callable(model):
            raise ValueError("æ¨¡å‹å¿…é¡»æ˜¯å¯è°ƒç”¨çš„æˆ–å…·æœ‰ forward æ–¹æ³•")
        
        # å°è¯•ä½¿ç”¨æ¨¡å‹çš„ç‰¹å¾æå–æ–¹æ³•
        if hasattr(model, 'extract_features'):
            with torch.no_grad():
                return model.extract_features(data)
        elif hasattr(model, 'forward_features'):
            with torch.no_grad():
                return model.forward_features(data)
        elif hasattr(model, 'feature_extractor'):
            with torch.no_grad():
                return model.feature_extractor(data)
        else:
            # å¦‚æœæ¨¡å‹æ²¡æœ‰ç‰¹å¾æå–æ–¹æ³•ï¼ŒæŠ›å‡ºé”™è¯¯
            raise NotImplementedError(
                f"æ¨¡å‹ {type(model).__name__} å¿…é¡»å®ç°ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š"
                f"extract_features(), forward_features(), æˆ–æä¾› feature_extractor å±æ€§ã€‚"
                f"åŸå‹è¯„ä¼°å™¨éœ€è¦çœŸå®çš„ç‰¹å¾è¡¨ç¤ºï¼Œä¸å…è®¸ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€‚"
            )
    
    def _initialize_prototypes(self, features: torch.Tensor, labels: torch.Tensor):
        """åˆå§‹åŒ–ç±»åŸå‹"""
        feature_dim = features.shape[1]
        self.class_prototypes = torch.zeros(self.num_classes, feature_dim)
        self.prototype_counts = torch.zeros(self.num_classes)
        
        # è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹
        for class_id in range(self.num_classes):
            class_mask = (labels == class_id)
            if class_mask.sum() > 0:
                class_features = features[class_mask]
                self.class_prototypes[class_id] = class_features.mean(dim=0)
                self.prototype_counts[class_id] = class_mask.sum().float()
        
        logger.debug("ç±»åŸå‹åˆå§‹åŒ–å®Œæˆ")
    
    def _update_prototypes(self, features: torch.Tensor, labels: torch.Tensor):
        """æ›´æ–°ç±»åŸå‹"""
        for class_id in range(self.num_classes):
            class_mask = (labels == class_id)
            if class_mask.sum() > 0:
                class_features = features[class_mask]
                new_prototype = class_features.mean(dim=0)
                
                # åŠ¨é‡æ›´æ–°
                self.class_prototypes[class_id] = (
                    self.prototype_momentum * self.class_prototypes[class_id] +
                    (1 - self.prototype_momentum) * new_prototype
                )
                
                # æ›´æ–°è®¡æ•°
                self.prototype_counts[class_id] += class_mask.sum().float()
    
    def _classify_with_prototypes(self, features: torch.Tensor) -> torch.Tensor:
        """åŸºäºåŸå‹è¿›è¡Œåˆ†ç±»"""
        # è®¡ç®—ç‰¹å¾ä¸åŸå‹çš„ç›¸ä¼¼åº¦
        similarities = torch.matmul(features, self.class_prototypes.T)
        
        # è¿”å›æœ€ç›¸ä¼¼çš„ç±»åˆ«
        predictions = torch.argmax(similarities, dim=1)
        return predictions
    
    def _compute_prototype_metrics(self, predictions: torch.Tensor, 
                                 labels: torch.Tensor, features: torch.Tensor) -> Dict[str, Any]:
        """è®¡ç®—åŸå‹ç›¸å…³çš„è¯„ä¼°æŒ‡æ ‡"""
        # åŸºç¡€å‡†ç¡®ç‡
        accuracy = (predictions == labels).float().mean().item()
        
        # åŸå‹è´¨é‡æŒ‡æ ‡
        prototype_metrics = self._compute_prototype_quality()
        
        # ç‰¹å¾èšç±»è´¨é‡
        clustering_metrics = self._compute_clustering_quality(features, labels)
        
        # ç±»é—´åˆ†ç¦»åº¦
        separation_metrics = self._compute_class_separation()
        
        return {
            "prototype_accuracy": accuracy,
            "overall_accuracy": accuracy,  # å…¼å®¹æ ‡å‡†æ¥å£
            **prototype_metrics,
            **clustering_metrics,
            **separation_metrics
        }
    
    def _compute_prototype_quality(self) -> Dict[str, float]:
        """è®¡ç®—åŸå‹è´¨é‡æŒ‡æ ‡"""
        if self.class_prototypes is None:
            return {}
        
        # åŸå‹èŒƒæ•°
        prototype_norms = torch.norm(self.class_prototypes, dim=1)
        avg_prototype_norm = prototype_norms.mean().item()
        std_prototype_norm = prototype_norms.std().item()
        
        # åŸå‹ç¨³å®šæ€§ï¼ˆåŸºäºè®¡æ•°ï¼‰
        min_count = self.prototype_counts.min().item()
        max_count = self.prototype_counts.max().item()
        count_balance = min_count / max(max_count, 1)
        
        return {
            "avg_prototype_norm": avg_prototype_norm,
            "std_prototype_norm": std_prototype_norm,
            "prototype_balance": count_balance
        }
    
    def _compute_clustering_quality(self, features: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:
        """è®¡ç®—èšç±»è´¨é‡æŒ‡æ ‡"""
        # ç±»å†…è·ç¦»
        intra_class_distances = []
        for class_id in range(self.num_classes):
            class_mask = (labels == class_id)
            if class_mask.sum() > 1:
                class_features = features[class_mask]
                class_center = class_features.mean(dim=0)
                distances = torch.norm(class_features - class_center, dim=1)
                intra_class_distances.append(distances.mean().item())
        
        avg_intra_distance = sum(intra_class_distances) / max(len(intra_class_distances), 1)
        
        # ç±»é—´è·ç¦»
        inter_class_distances = []
        for i in range(self.num_classes):
            for j in range(i + 1, self.num_classes):
                if self.prototype_counts[i] > 0 and self.prototype_counts[j] > 0:
                    distance = torch.norm(self.class_prototypes[i] - self.class_prototypes[j]).item()
                    inter_class_distances.append(distance)
        
        avg_inter_distance = sum(inter_class_distances) / max(len(inter_class_distances), 1)
        
        # èšç±»è´¨é‡æ¯”ç‡
        clustering_ratio = avg_inter_distance / max(avg_intra_distance, 1e-8)
        
        return {
            "avg_intra_class_distance": avg_intra_distance,
            "avg_inter_class_distance": avg_inter_distance,
            "clustering_quality_ratio": clustering_ratio
        }
    
    def _compute_class_separation(self) -> Dict[str, float]:
        """è®¡ç®—ç±»é—´åˆ†ç¦»åº¦"""
        if self.class_prototypes is None:
            return {}
        
        # æœ€å°ç±»é—´è·ç¦»
        min_separation = float('inf')
        max_separation = 0.0
        
        for i in range(self.num_classes):
            for j in range(i + 1, self.num_classes):
                if self.prototype_counts[i] > 0 and self.prototype_counts[j] > 0:
                    distance = torch.norm(self.class_prototypes[i] - self.class_prototypes[j]).item()
                    min_separation = min(min_separation, distance)
                    max_separation = max(max_separation, distance)
        
        return {
            "min_class_separation": min_separation if min_separation != float('inf') else 0.0,
            "max_class_separation": max_separation,
            "separation_ratio": max_separation / max(min_separation, 1e-8) if min_separation != float('inf') else 1.0
        }
    
    def get_prototypes(self) -> Optional[torch.Tensor]:
        """è·å–å½“å‰çš„ç±»åŸå‹"""
        return self.class_prototypes
    
    def reset_prototypes(self):
        """é‡ç½®åŸå‹çŠ¶æ€"""
        self.class_prototypes = None
        self.prototype_counts = None
        logger.info("ğŸ”„ åŸå‹è¯„ä¼°å™¨çŠ¶æ€å·²é‡ç½®")