"""
FedProx èšåˆå™¨

å®žçŽ° FedProx (Federated Optimization in Heterogeneous Networks) èšåˆç®—æ³•ã€‚
åœ¨FedAvgåŸºç¡€ä¸Šæ·»åŠ æ­£åˆ™åŒ–é¡¹ï¼Œæ›´å¥½åœ°å¤„ç†å¼‚æž„æ•°æ®å’Œç³»ç»Ÿå¼‚æž„æ€§ã€‚

è®ºæ–‡ï¼šFederated Optimization in Heterogeneous Networks
ä½œè€…ï¼šTian Li et al.
å‘è¡¨ï¼šMLSys 2020

ç®—æ³•ç‰¹ç‚¹ï¼š
1. åœ¨å®¢æˆ·ç«¯æœ¬åœ°ç›®æ ‡å‡½æ•°ä¸­æ·»åŠ è¿‘ç«¯é¡¹
2. çº¦æŸå®¢æˆ·ç«¯æ¨¡åž‹ä¸è¦åç¦»å…¨å±€æ¨¡åž‹å¤ªè¿œ
3. æ›´å¥½çš„æ”¶æ•›æ€§å’Œç¨³å®šæ€§
4. é€‚åˆæ•°æ®å¼‚æž„çš„è”é‚¦å­¦ä¹ åœºæ™¯
"""

import torch
from typing import Dict, List, Any, Union
from loguru import logger

from ...api.decorators import aggregator


@aggregator("fedprox", description="FedProxå¸¦æ­£åˆ™åŒ–çš„è”é‚¦èšåˆå™¨")
class FedProxAggregator:
    """
    FedProx èšåˆå™¨å®žçŽ°
    
    åœ¨FedAvgåŸºç¡€ä¸Šï¼Œè€ƒè™‘è¿‘ç«¯é¡¹çš„å½±å“ï¼š
    å®¢æˆ·ç«¯æŸå¤±: L_k(w) + (Î¼/2)||w - w_t||Â²
    
    å…¶ä¸­ï¼š
    - L_k(w): å®¢æˆ·ç«¯kçš„åŽŸå§‹æŸå¤±å‡½æ•°
    - Î¼: è¿‘ç«¯é¡¹ç³»æ•°ï¼ŒæŽ§åˆ¶ä¸Žå…¨å±€æ¨¡åž‹çš„åç¦»ç¨‹åº¦
    - w_t: å½“å‰è½®æ¬¡çš„å…¨å±€æ¨¡åž‹å‚æ•°
    
    å‚æ•°ï¼š
    - mu: è¿‘ç«¯é¡¹ç³»æ•°ï¼Œé»˜è®¤0.01
    - weighted: æ˜¯å¦æŒ‰æ ·æœ¬æ•°é‡åŠ æƒï¼Œé»˜è®¤True
    - normalize_weights: æ˜¯å¦æ ‡å‡†åŒ–æƒé‡ï¼Œé»˜è®¤True
    """
    
    def __init__(self, config: Dict[str, Any] = None, **kwargs):
        """åˆå§‹åŒ–FedProxèšåˆå™¨"""
        self.config = config or {}
        
        # FedProxç‰¹å®šå‚æ•°
        self.mu = self.config.get("mu", 0.01)  # è¿‘ç«¯é¡¹ç³»æ•°
        self.weighted = self.config.get("weighted", True)
        self.normalize_weights = self.config.get("normalize_weights", True)
        
        # è®¾å¤‡é…ç½®
        self.device = self.config.get("device", "auto")
        if self.device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # èšåˆåŽ†å²
        self.round_count = 0
        self.convergence_history = []
        
        # å…¼å®¹å‚æ•°
        self.global_model = kwargs.get("global_model")
        
        logger.info(f"âœ… FedProxèšåˆå™¨åˆå§‹åŒ–å®Œæˆ - Î¼: {self.mu}, åŠ æƒ: {self.weighted}")
    
    def aggregate(self, client_updates: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒFedProxèšåˆ
        
        Args:
            client_updates: å®¢æˆ·ç«¯æ›´æ–°åˆ—è¡¨ï¼ŒåŒ…å«ï¼š
                - model_weights: æ¨¡åž‹æƒé‡
                - num_samples: æ ·æœ¬æ•°é‡
                - proximal_term: è¿‘ç«¯é¡¹å€¼ï¼ˆå¯é€‰ï¼‰
                - client_id: å®¢æˆ·ç«¯ID
        
        Returns:
            èšåˆç»“æžœï¼ŒåŒ…å«FedProxç‰¹å®šçš„ç»Ÿè®¡ä¿¡æ¯
        """
        if not client_updates:
            raise ValueError("æ²¡æœ‰å®¢æˆ·ç«¯æ›´æ–°å¯èšåˆ")
        
        self.round_count += 1
        logger.debug(f"ðŸ”„ FedProxèšåˆè½®æ¬¡ {self.round_count} - {len(client_updates)} ä¸ªå®¢æˆ·ç«¯")
        
        # 1. è®¡ç®—èšåˆæƒé‡ï¼ˆè€ƒè™‘è¿‘ç«¯é¡¹å½±å“ï¼‰
        weights = self._compute_fedprox_weights(client_updates)
        
        # 2. æ‰§è¡ŒåŠ æƒèšåˆ
        aggregated_weights = self._fedprox_aggregation(client_updates, weights)
        
        # 3. è®¡ç®—æ”¶æ•›æŒ‡æ ‡
        convergence_metrics = self._compute_convergence_metrics(client_updates, aggregated_weights)
        
        # 4. æž„å»ºç»“æžœ
        total_samples = sum(update.get("num_samples", 0) for update in client_updates)
        
        result = {
            "aggregated_weights": aggregated_weights,
            "total_samples": total_samples,
            "num_participants": len(client_updates),
            "aggregation_weights": {
                update.get("client_id", f"client_{i}"): weights[i] 
                for i, update in enumerate(client_updates)
            },
            "algorithm": "FedProx",
            "mu": self.mu,
            "round": self.round_count,
            "convergence_metrics": convergence_metrics
        }
        
        # è®°å½•æ”¶æ•›åŽ†å²
        self.convergence_history.append(convergence_metrics)
        
        logger.debug(f"âœ… FedProxèšåˆå®Œæˆ - æ”¶æ•›åº¦: {convergence_metrics.get('avg_divergence', 0):.6f}")
        return result
    
    def _compute_fedprox_weights(self, client_updates: List[Dict[str, Any]]) -> List[float]:
        """è®¡ç®—FedProxèšåˆæƒé‡"""
        if not self.weighted:
            num_clients = len(client_updates)
            return [1.0 / num_clients] * num_clients
        
        # åŸºç¡€æƒé‡ï¼šæŒ‰æ ·æœ¬æ•°é‡
        sample_counts = [update.get("num_samples", 1) for update in client_updates]
        total_samples = sum(sample_counts)
        
        if total_samples == 0:
            num_clients = len(client_updates)
            return [1.0 / num_clients] * num_clients
        
        base_weights = [count / total_samples for count in sample_counts]
        
        # FedProxè°ƒæ•´ï¼šè€ƒè™‘è¿‘ç«¯é¡¹çš„å½±å“
        # è¿‘ç«¯é¡¹å€¼è¶Šå°ï¼ˆè¶ŠæŽ¥è¿‘å…¨å±€æ¨¡åž‹ï¼‰ï¼Œæƒé‡è¶Šå¤§
        if self.mu > 0:
            adjusted_weights = []
            for i, update in enumerate(client_updates):
                proximal_term = update.get("proximal_term", 0.0)
                # ä½¿ç”¨æŒ‡æ•°è¡°å‡è°ƒæ•´æƒé‡
                adjustment = torch.exp(-self.mu * proximal_term)
                adjusted_weights.append(base_weights[i] * adjustment)
            
            # é‡æ–°æ ‡å‡†åŒ–
            if self.normalize_weights:
                total_weight = sum(adjusted_weights)
                if total_weight > 0:
                    adjusted_weights = [w / total_weight for w in adjusted_weights]
            
            return adjusted_weights
        
        return base_weights
    
    def _fedprox_aggregation(self, client_updates: List[Dict[str, Any]], 
                            weights: List[float]) -> Dict[str, torch.Tensor]:
        """æ‰§è¡ŒFedProxèšåˆ"""
        aggregated_weights = {}
        
        # èŽ·å–æ¨¡åž‹ç»“æž„
        first_weights = client_updates[0]["model_weights"]
        param_names = list(first_weights.keys())
        
        # åˆå§‹åŒ–èšåˆç»“æžœ
        for param_name in param_names:
            param_tensor = first_weights[param_name]
            if isinstance(param_tensor, torch.Tensor):
                aggregated_weights[param_name] = torch.zeros_like(param_tensor, device=self.device)
            else:
                aggregated_weights[param_name] = 0.0
        
        # åŠ æƒèšåˆ
        for i, update in enumerate(client_updates):
            client_weights = update["model_weights"]
            weight = weights[i]
            
            for param_name in param_names:
                if param_name in client_weights:
                    param_value = client_weights[param_name]
                    
                    if isinstance(param_value, torch.Tensor):
                        param_value = param_value.to(self.device)
                        aggregated_weights[param_name] += weight * param_value
                    else:
                        aggregated_weights[param_name] += weight * param_value
        
        return aggregated_weights
    
    def _compute_convergence_metrics(self, client_updates: List[Dict[str, Any]], 
                                   aggregated_weights: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """è®¡ç®—æ”¶æ•›æŒ‡æ ‡"""
        metrics = {}
        
        # è®¡ç®—å®¢æˆ·ç«¯æ¨¡åž‹ä¸Žèšåˆæ¨¡åž‹çš„å·®å¼‚
        divergences = []
        
        for update in client_updates:
            client_weights = update["model_weights"]
            divergence = 0.0
            param_count = 0
            
            for param_name in aggregated_weights.keys():
                if param_name in client_weights:
                    global_param = aggregated_weights[param_name]
                    client_param = client_weights[param_name]
                    
                    if isinstance(global_param, torch.Tensor) and isinstance(client_param, torch.Tensor):
                        client_param = client_param.to(self.device)
                        diff = torch.norm(global_param - client_param).item()
                        divergence += diff
                        param_count += 1
            
            if param_count > 0:
                divergences.append(divergence / param_count)
        
        if divergences:
            metrics["avg_divergence"] = sum(divergences) / len(divergences)
            metrics["max_divergence"] = max(divergences)
            metrics["min_divergence"] = min(divergences)
            metrics["std_divergence"] = torch.std(torch.tensor(divergences)).item()
        
        # è¿‘ç«¯é¡¹ç»Ÿè®¡
        proximal_terms = [update.get("proximal_term", 0.0) for update in client_updates]
        if proximal_terms:
            metrics["avg_proximal_term"] = sum(proximal_terms) / len(proximal_terms)
            metrics["max_proximal_term"] = max(proximal_terms)
        
        return metrics
    
    def get_convergence_trend(self) -> Dict[str, List[float]]:
        """èŽ·å–æ”¶æ•›è¶‹åŠ¿"""
        if not self.convergence_history:
            return {}
        
        trends = {}
        metric_names = self.convergence_history[0].keys()
        
        for metric_name in metric_names:
            trends[metric_name] = [round_metrics.get(metric_name, 0.0) 
                                 for round_metrics in self.convergence_history]
        
        return trends
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–èšåˆå™¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "algorithm": "FedProx",
            "mu": self.mu,
            "weighted": self.weighted,
            "total_rounds": self.round_count,
            "device": str(self.device)
        }
        
        # æ·»åŠ æ”¶æ•›ç»Ÿè®¡
        if self.convergence_history:
            latest_metrics = self.convergence_history[-1]
            stats["latest_convergence"] = latest_metrics
            
            # è®¡ç®—æ•´ä½“è¶‹åŠ¿
            divergences = [m.get("avg_divergence", 0) for m in self.convergence_history]
            if len(divergences) > 1:
                stats["convergence_trend"] = "improving" if divergences[-1] < divergences[0] else "degrading"
        
        return stats
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.round_count = 0
        self.convergence_history.clear()
        logger.info("ðŸ”„ FedProxèšåˆå™¨ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def __repr__(self) -> str:
        return f"FedProxAggregator(mu={self.mu}, weighted={self.weighted}, rounds={self.round_count})"