"""
FedAvg èšåˆå™¨

å®žçŽ°ç»å…¸çš„ FedAvg (Federated Averaging) èšåˆç®—æ³•ã€‚
æŒ‰å®¢æˆ·ç«¯æ ·æœ¬æ•°é‡è¿›è¡ŒåŠ æƒå¹³å‡èšåˆï¼Œæ˜¯æœ€åŸºç¡€å’Œå¹¿æ³›ä½¿ç”¨çš„è”é‚¦å­¦ä¹ èšåˆæ–¹æ³•ã€‚

è®ºæ–‡ï¼šCommunication-Efficient Learning of Deep Networks from Decentralized Data
ä½œè€…ï¼šH. Brendan McMahan et al.
å‘è¡¨ï¼šAISTATS 2017

ç®—æ³•ç‰¹ç‚¹ï¼š
1. ç®€å•é«˜æ•ˆçš„åŠ æƒå¹³å‡èšåˆ
2. æŒ‰å®¢æˆ·ç«¯æ•°æ®é‡åˆ†é…æƒé‡
3. é€‚åˆå¤§å¤šæ•°è”é‚¦å­¦ä¹ åœºæ™¯
"""

import torch
from typing import Dict, List, Any, Union
from loguru import logger

from ...api.decorators import aggregator


@aggregator("fedavg", description="ç»å…¸FedAvgåŠ æƒå¹³å‡èšåˆå™¨")
class FedAvgAggregator:
    """
    FedAvg èšåˆå™¨å®žçŽ°
    
    æ‰§è¡ŒæŒ‰æ ·æœ¬æ•°é‡åŠ æƒçš„å‚æ•°å¹³å‡èšåˆï¼š
    w_global = Î£(n_k * w_k) / Î£(n_k)
    
    å…¶ä¸­ï¼š
    - w_k: å®¢æˆ·ç«¯kçš„æ¨¡åž‹å‚æ•°
    - n_k: å®¢æˆ·ç«¯kçš„æ ·æœ¬æ•°é‡
    - w_global: èšåˆåŽçš„å…¨å±€æ¨¡åž‹å‚æ•°
    
    å‚æ•°ï¼š
    - weighted: æ˜¯å¦æŒ‰æ ·æœ¬æ•°é‡åŠ æƒï¼Œé»˜è®¤True
    - clip_norm: æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼Œé»˜è®¤Noneï¼ˆä¸è£å‰ªï¼‰
    - device: è®¡ç®—è®¾å¤‡ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
    """
    
    def __init__(self, config: Dict[str, Any] = None, **kwargs):
        """åˆå§‹åŒ–FedAvgèšåˆå™¨"""
        self.config = config or {}
        
        # èšåˆé…ç½®
        self.weighted = self.config.get("weighted", True)
        self.clip_norm = self.config.get("clip_norm", None)
        self.device = self.config.get("device", "auto")
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if self.device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.round_count = 0
        self.total_aggregations = 0
        
        # å…¼å®¹çŽ°æœ‰æ¡†æž¶çš„å‚æ•°
        self.global_model = kwargs.get("global_model")
        
        logger.info(f"âœ… FedAvgèšåˆå™¨åˆå§‹åŒ–å®Œæˆ - åŠ æƒ: {self.weighted}, è®¾å¤‡: {self.device}")
    
    def aggregate(self, client_updates: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒFedAvgèšåˆ
        
        Args:
            client_updates: å®¢æˆ·ç«¯æ›´æ–°åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¿…é¡»åŒ…å«ï¼š
                - model_weights: æ¨¡åž‹æƒé‡å­—å…¸
                - num_samples: æ ·æœ¬æ•°é‡  
                - client_id: å®¢æˆ·ç«¯ID
                - å…¶ä»–åŠ¨æ€æŒ‡æ ‡ï¼ˆæ”¯æŒä»»æ„æŒ‡æ ‡åç§°ï¼‰
        
        Returns:
            èšåˆç»“æžœå­—å…¸ï¼ŒåŒ…å«ï¼š
                - aggregated_weights: èšåˆåŽçš„æ¨¡åž‹æƒé‡
                - total_samples: æ€»æ ·æœ¬æ•°
                - num_participants: å‚ä¸Žå®¢æˆ·ç«¯æ•°é‡
                - aggregation_weights: å„å®¢æˆ·ç«¯æƒé‡
                - åŠ¨æ€èšåˆçš„æŒ‡æ ‡
        """
        if not client_updates:
            raise ValueError("æ²¡æœ‰å®¢æˆ·ç«¯æ›´æ–°å¯èšåˆ")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        for i, update in enumerate(client_updates):
            if "model_weights" not in update:
                raise ValueError(f"å®¢æˆ·ç«¯æ›´æ–° {i} ç¼ºå°‘å¿…éœ€å­—æ®µ 'model_weights'")
            if "num_samples" not in update:
                raise ValueError(f"å®¢æˆ·ç«¯æ›´æ–° {i} ç¼ºå°‘å¿…éœ€å­—æ®µ 'num_samples'")
        
        self.round_count += 1
        self.total_aggregations += 1
        
        logger.debug(f"ðŸ”„ FedAvgèšåˆè½®æ¬¡ {self.round_count} - {len(client_updates)} ä¸ªå®¢æˆ·ç«¯")
        
        # 1. è®¡ç®—èšåˆæƒé‡
        weights = self._compute_aggregation_weights(client_updates)
        
        # 2. æ‰§è¡ŒåŠ æƒèšåˆ
        aggregated_weights = self._fedavg_aggregation(client_updates, weights)
        
        # 3. èšåˆæ‰€æœ‰æ•°å€¼æŒ‡æ ‡ï¼ˆåŠ¨æ€æ”¯æŒä»»æ„æŒ‡æ ‡ï¼‰
        aggregated_metrics = self._aggregate_metrics(client_updates, weights)
        
        # 4. è®¡ç®—åŸºç¡€ç»Ÿè®¡
        total_samples = sum(update["num_samples"] for update in client_updates)
        
        # 5. æž„å»ºç»“æžœ
        result = {
            "aggregated_weights": aggregated_weights,
            "total_samples": total_samples,
            "num_participants": len(client_updates),
            "aggregation_weights": {
                update.get("client_id", f"client_{i}"): weights[i] 
                for i, update in enumerate(client_updates)
            },
            "algorithm": "FedAvg",
            "round": self.round_count
        }
        
        # æ·»åŠ èšåˆçš„æŒ‡æ ‡
        result.update(aggregated_metrics)
        
        logger.debug(f"âœ… FedAvgèšåˆå®Œæˆ - æ€»æ ·æœ¬: {total_samples}")
        return result
    
    def _compute_aggregation_weights(self, client_updates: List[Dict[str, Any]]) -> List[float]:
        """è®¡ç®—èšåˆæƒé‡"""
        if not self.weighted:
            # å‡ç­‰æƒé‡
            num_clients = len(client_updates)
            return [1.0 / num_clients] * num_clients
        
        # æŒ‰æ ·æœ¬æ•°é‡åŠ æƒ
        sample_counts = [update["num_samples"] for update in client_updates]
        total_samples = sum(sample_counts)
        
        if total_samples == 0:
            raise ValueError("æ‰€æœ‰å®¢æˆ·ç«¯çš„æ ·æœ¬æ•°éƒ½ä¸º0ï¼Œæ— æ³•è¿›è¡ŒåŠ æƒèšåˆ")
        
        weights = [count / total_samples for count in sample_counts]
        return weights
    
    def _aggregate_metrics(self, client_updates: List[Dict[str, Any]], weights: List[float]) -> Dict[str, Any]:
        """èšåˆæ‰€æœ‰æ•°å€¼æŒ‡æ ‡ï¼ˆæ”¯æŒä»»æ„æŒ‡æ ‡åç§°ï¼‰"""
        aggregated_metrics = {}
        
        # èŽ·å–æ‰€æœ‰å¯èšåˆçš„æ•°å€¼æŒ‡æ ‡
        metric_names = set()
        for update in client_updates:
            for key, value in update.items():
                # è·³è¿‡éžæ•°å€¼å­—æ®µ
                if key in ["model_weights", "client_id"]:
                    continue
                # åªèšåˆæ•°å€¼ç±»åž‹
                if isinstance(value, (int, float, torch.Tensor)):
                    if isinstance(value, torch.Tensor) and value.numel() == 1:
                        metric_names.add(key)
                    elif not isinstance(value, torch.Tensor):
                        metric_names.add(key)
        
        # å¯¹æ¯ä¸ªæŒ‡æ ‡è¿›è¡ŒåŠ æƒèšåˆ
        for metric_name in metric_names:
            if metric_name == "num_samples":  # è·³è¿‡æ ·æœ¬æ•°ï¼Œå·²ç»å•ç‹¬å¤„ç†
                continue
                
            metric_values = []
            metric_weights = []
            
            for i, update in enumerate(client_updates):
                if metric_name in update:
                    value = update[metric_name]
                    if isinstance(value, torch.Tensor):
                        value = value.item() if value.numel() == 1 else value
                    
                    if isinstance(value, (int, float)):
                        metric_values.append(value)
                        metric_weights.append(weights[i])
            
            # è®¡ç®—åŠ æƒå¹³å‡
            if metric_values:
                weighted_sum = sum(val * weight for val, weight in zip(metric_values, metric_weights))
                weight_sum = sum(metric_weights)
                
                if weight_sum > 0:
                    aggregated_metrics[f"avg_{metric_name}"] = weighted_sum / weight_sum
                    aggregated_metrics[f"total_{metric_name}"] = sum(metric_values)
                    aggregated_metrics[f"min_{metric_name}"] = min(metric_values)
                    aggregated_metrics[f"max_{metric_name}"] = max(metric_values)
        
        return aggregated_metrics
    
    def _fedavg_aggregation(self, client_updates: List[Dict[str, Any]], 
                           weights: List[float]) -> Dict[str, torch.Tensor]:
        """æ‰§è¡ŒFedAvgåŠ æƒå¹³å‡èšåˆ"""
        aggregated_weights = {}
        
        # èŽ·å–å‚æ•°ç»“æž„
        first_update = client_updates[0]
        if "model_weights" not in first_update:
            raise ValueError("å®¢æˆ·ç«¯æ›´æ–°ç¼ºå°‘ model_weights å­—æ®µ")
        
        model_weights = first_update["model_weights"]
        param_names = list(model_weights.keys())
        
        # åˆå§‹åŒ–èšåˆæƒé‡
        for param_name in param_names:
            param_shape = model_weights[param_name].shape
            aggregated_weights[param_name] = torch.zeros(param_shape, device=self.device)
        
        # åŠ æƒèšåˆ
        for i, update in enumerate(client_updates):
            client_weights = update["model_weights"]
            client_weight = weights[i]
            
            for param_name in param_names:
                if param_name not in client_weights:
                    logger.warning(f"å®¢æˆ·ç«¯ {update.get('client_id', i)} ç¼ºå°‘å‚æ•° {param_name}")
                    continue
                
                # å°†å‚æ•°ç§»åˆ°æ­£ç¡®è®¾å¤‡å¹¶åŠ æƒ
                param_value = client_weights[param_name]
                if isinstance(param_value, torch.Tensor):
                    param_value = param_value.to(self.device)
                    
                    # å¯é€‰ï¼šæ¢¯åº¦è£å‰ª
                    if self.clip_norm is not None:
                        param_value = torch.clamp(param_value, -self.clip_norm, self.clip_norm)
                    
                    aggregated_weights[param_name] += client_weight * param_value
                else:
                    # å¤„ç†éžå¼ é‡å‚æ•°ï¼ˆå¦‚æ ‡é‡ï¼‰
                    aggregated_weights[param_name] += client_weight * param_value
        
        return aggregated_weights
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–èšåˆå™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "algorithm": "FedAvg",
            "total_rounds": self.round_count,
            "total_aggregations": self.total_aggregations,
            "weighted": self.weighted,
            "clip_norm": self.clip_norm,
            "device": str(self.device)
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.round_count = 0
        self.total_aggregations = 0
        logger.info("ðŸ”„ FedAvgèšåˆå™¨ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def __repr__(self) -> str:
        return f"FedAvgAggregator(weighted={self.weighted}, device={self.device}, rounds={self.round_count})"