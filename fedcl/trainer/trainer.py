"""
MOE-FedCL æœåŠ¡ç«¯è®­ç»ƒå™¨æŠ½è±¡åŸºç±»
moe_fedcl/trainer/base_trainer.py
"""

import asyncio
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, List, Optional, Callable
from logging import Logger
from ..communication.layer_event import ProxyManagerEventHandler
from ..exceptions import FederationError
from ..learner.proxy import LearnerProxy
from ..types import ModelData, EvaluationResult, RoundResult
from ..utils.auto_logger import get_train_logger, get_sys_logger

class FederationResult:
    """è”é‚¦å­¦ä¹ è®­ç»ƒç»“æœ"""

    def __init__(self):
        self.success = False
        self.total_rounds = 0
        self.completed_rounds = 0
        self.final_accuracy = 0.0
        self.final_loss = float('inf')
        self.total_time = 0.0
        self.convergence_round = None
        self.best_model: Optional[ModelData] = None
        self.training_history: List[RoundResult] = []
        self.error_message: Optional[str] = None
        self.termination_reason = "unknown"


class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    
    def __init__(self,
                 max_rounds: int = 100,
                 min_clients: int = 2,
                 client_selection_ratio: float = 1.0,
                 round_timeout: float = 300.0,
                 client_timeout: float = 120.0,
                 convergence_threshold: float = 0.001,
                 patience: int = 10,
                 save_checkpoints: bool = True,
                 checkpoint_interval: int = 10):
        self.max_rounds = max_rounds
        self.min_clients = min_clients
        self.client_selection_ratio = client_selection_ratio
        self.round_timeout = round_timeout
        self.client_timeout = client_timeout
        self.convergence_threshold = convergence_threshold
        self.patience = patience
        self.save_checkpoints = save_checkpoints
        self.checkpoint_interval = checkpoint_interval


class TrainingStatus:
    """è®­ç»ƒçŠ¶æ€"""
    
    def __init__(self):
        self.current_round = 0
        self.total_rounds = 0
        self.is_training = False
        self.start_time: Optional[datetime] = None
        self.end_time: Optional[datetime] = None
        self.selected_clients: List[str] = []
        self.active_clients: List[str] = []
        self.failed_clients: List[str] = []
        self.round_results: List[RoundResult] = []
        self.best_accuracy = 0.0
        self.patience_counter = 0
        self.convergence_history: List[float] = []


class RoundStatistics:
    """è½®æ¬¡ç»Ÿè®¡"""
    
    def __init__(self):
        self.round_number = 0
        self.participants_count = 0
        self.successful_participants = 0
        self.failed_participants = 0
        self.average_training_time = 0.0
        self.average_loss = 0.0
        self.average_accuracy = 0.0
        self.model_size_bytes = 0
        self.communication_time = 0.0
        self.aggregation_time = 0.0
        self.total_round_time = 0.0
        self.convergence_metric = 0.0


class ClientStatistics:
    """å®¢æˆ·ç«¯ç»Ÿè®¡"""
    
    def __init__(self, client_id: str):
        self.client_id = client_id
        self.participation_count = 0
        self.successful_rounds = 0
        self.failed_rounds = 0
        self.average_training_time = 0.0
        self.total_samples_trained = 0
        self.last_participation_time: Optional[datetime] = None
        self.connection_stability = 1.0  # 0.0-1.0
        self.performance_score = 0.0


class ProxyManager:
    """ä»£ç†ç®¡ç†å™¨ - è´Ÿè´£LearnerProxyçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    
    def __init__(self, trainer: 'BaseTrainer', server_id: Optional[str] = None):
        """åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨

        Args:
            trainer: BaseTrainer å®ä¾‹
            server_id: æœåŠ¡å™¨èŠ‚ç‚¹IDï¼ˆç”¨äºæ—¥å¿—å½’å±ï¼‰
        """
        self.trainer = trainer
        self.proxies: Dict[str, LearnerProxy] = {}
        self._lock = asyncio.Lock()

        # å¯¼å…¥æ—¥å¿—è®°å½•å™¨
        from ..utils.auto_logger import get_logger
        # ProxyManager æ˜¯ Server ç«¯ç»„ä»¶ï¼Œä½¿ç”¨ server_id çš„è¿è¡Œæ—¥å¿—
        if server_id:
            self.logger = get_logger("runtime", server_id)
        else:
            # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰ server_idï¼Œä½¿ç”¨é€šç”¨çš„ server
            self.logger = get_logger("runtime", "server")
    
    async def on_proxy_ready(self, client_id: str, proxy: LearnerProxy):
        """æ¥æ”¶ä¸šåŠ¡é€šä¿¡å±‚åˆ›å»ºçš„ä»£ç†"""
        self.logger.info(f" [ä»£ç†ç®¡ç†å™¨] æ”¶åˆ°ä»£ç†å°±ç»ªé€šçŸ¥: {client_id}")
        
        async with self._lock:
            self.proxies[client_id] = proxy
            
            # æ›´æ–°trainerçš„å®¢æˆ·ç«¯ç»Ÿè®¡
            self.trainer.client_statistics[client_id] = ClientStatistics(client_id)
            
            self.logger.debug(f"[ä»£ç†ç®¡ç†å™¨] å­¦ä¹ å™¨ä»£ç†å·²æ³¨å†Œ: {client_id}, å½“å‰æ€»æ•°: {len(self.proxies)}")
            self.logger.info(f"[ä»£ç†ç®¡ç†å™¨] å¯ç”¨å®¢æˆ·ç«¯åˆ—è¡¨: {list(self.proxies.keys())}")
    
    async def on_proxy_disconnected(self, client_id: str):
        """å¤„ç†ä»£ç†æ–­å¼€"""
        self.logger.warning(f"[ä»£ç†ç®¡ç†å™¨] æ”¶åˆ°ä»£ç†æ–­å¼€é€šçŸ¥: {client_id}")
        
        async with self._lock:
            if client_id in self.proxies:
                del self.proxies[client_id]
                
                # æ¸…ç†trainerçš„å®¢æˆ·ç«¯ç»Ÿè®¡
                if client_id in self.trainer.client_statistics:
                    del self.trainer.client_statistics[client_id]
                
                self.logger.debug(f"ğŸ—‘ï¸ [ä»£ç†ç®¡ç†å™¨] å­¦ä¹ å™¨ä»£ç†å·²ç§»é™¤: {client_id}, å‰©ä½™æ•°é‡: {len(self.proxies)}")
    
    def get_proxy(self, client_id: str) -> Optional[LearnerProxy]:
        """è·å–æŒ‡å®šå®¢æˆ·ç«¯çš„ä»£ç†"""
        return self.proxies.get(client_id)
    
    def get_all_proxies(self) -> Dict[str, LearnerProxy]:
        """è·å–æ‰€æœ‰ä»£ç†"""
        return self.proxies.copy()
    
    def get_available_clients(self) -> List[str]:
        """è·å–å¯ç”¨å®¢æˆ·ç«¯åˆ—è¡¨"""
        available_clients = []
        self.logger.debug(f"[ä»£ç†ç®¡ç†å™¨] æ£€æŸ¥å¯ç”¨å®¢æˆ·ç«¯ï¼Œæ€»ä»£ç†æ•°: {len(self.proxies)}")
        
        for client_id, proxy in self.proxies.items():
            if proxy.is_client_ready():
                available_clients.append(client_id)
                self.logger.debug(f"[ä»£ç†ç®¡ç†å™¨] å®¢æˆ·ç«¯[{client_id}]å¯ç”¨")
            else:
                self.logger.warning(f"[ä»£ç†ç®¡ç†å™¨] å®¢æˆ·ç«¯[{client_id}]ä¸å¯ç”¨")
        
        self.logger.info(f"[ä»£ç†ç®¡ç†å™¨] å¯ç”¨å®¢æˆ·ç«¯æ€»æ•°: {len(available_clients)}/{len(self.proxies)}")
        return available_clients


class BaseTrainer(ABC):
    """æœåŠ¡ç«¯è®­ç»ƒå™¨æŠ½è±¡åŸºç±» - ç”¨æˆ·ç»§æ‰¿å®ç°è”é‚¦å­¦ä¹ ç®—æ³•

    ä½¿ç”¨ç»Ÿä¸€çš„ç»„ä»¶åˆå§‹åŒ–ç­–ç•¥ï¼š
    1. æ¥æ”¶åŒ…å«ç»„ä»¶ç±»å¼•ç”¨å’Œå‚æ•°çš„é…ç½®å­—å…¸
    2. æ”¯æŒå»¶è¿ŸåŠ è½½ï¼ˆé»˜è®¤ï¼‰æˆ–ç«‹å³åˆå§‹åŒ–
    3. ç”¨æˆ·å¯è¦†ç›–é»˜è®¤åˆ›å»ºæ–¹æ³•
    """

    def __init__(self,
                 config: Optional[Dict[str, Any]] = None,
                 lazy_init: bool = True,
                 logger: Optional[Logger] = None,
                 server_id: Optional[str] = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            config: ç»„ä»¶é…ç½®å­—å…¸ï¼ŒåŒ…å«ç±»å¼•ç”¨å’Œå‚æ•°
                   ç”±ComponentBuilder.parse_config()ç”Ÿæˆ
            lazy_init: æ˜¯å¦å»¶è¿Ÿåˆå§‹åŒ–ç»„ä»¶ï¼ˆé»˜è®¤Trueï¼‰
            logger: æ—¥å¿—è®°å½•å™¨
            server_id: æœåŠ¡å™¨èŠ‚ç‚¹IDï¼ˆç”¨äºæ—¥å¿—å½’å±å’Œç»„ä»¶åˆå§‹åŒ–ï¼‰
        """
        self.config = config or {}
        self.lazy_init = lazy_init
        self.server_id = server_id  # ä¿å­˜ server_id

        # å¦‚æœæä¾›äº† server_idï¼Œä½¿ç”¨å¯¹åº”çš„è®­ç»ƒæ—¥å¿—ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤çš„ server
        if server_id:
            self.logger = logger if logger else get_train_logger(server_id)
        else:
            self.logger = logger if logger else get_train_logger("server")

        # æå–trainerè‡ªå·±çš„é…ç½®å‚æ•°
        trainer_config = self.config.get('trainer', {})
        trainer_params = trainer_config.get('params', {})

        # åº”ç”¨trainerå‚æ•°åˆ°å®ä¾‹å±æ€§
        for key, value in trainer_params.items():
            setattr(self, key, value)

        # å¦‚æœæ²¡æœ‰ä»å‚æ•°è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not hasattr(self, 'max_rounds'):
            self.max_rounds = 100
        if not hasattr(self, 'min_clients'):
            self.min_clients = 2

        # åˆ›å»ºTrainingConfigï¼ˆå‘åå…¼å®¹ï¼‰
        self.training_config = TrainingConfig(
            max_rounds=getattr(self, 'max_rounds', 100),
            min_clients=getattr(self, 'min_clients', 2),
            client_selection_ratio=getattr(self, 'client_selection_ratio', 1.0)
        )

        #  è‡ªåŠ¨å®ä¾‹åŒ–ä»£ç†ç®¡ç†å™¨ï¼ˆç”¨æˆ·æ— æ„ŸçŸ¥ï¼‰ï¼Œä¼ é€’ server_id
        self._proxy_manager = ProxyManager(self, server_id=server_id)

        # åˆ›å»ºäº‹ä»¶å¤„ç†å™¨ï¼Œç”¨äºæ¥æ”¶ä¸šåŠ¡å±‚çš„ä»£ç†åˆ›å»ºäº‹ä»¶ï¼Œä¼ é€’ server_id
        self._proxy_event_handler = ProxyManagerEventHandler(self._proxy_manager, server_id=server_id)

        # learner_proxieså˜æˆä»£ç†ç®¡ç†å™¨çš„ä»£ç†å±æ€§
        self.learner_proxies = self._proxy_manager.proxies

        # ç»„ä»¶å ä½ç¬¦ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self._aggregator = None
        self._global_model = None
        self._evaluator = None

        # å¦‚æœä¸å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç«‹å³åˆ›å»ºæ‰€æœ‰ç»„ä»¶
        if not self.lazy_init:
            self._initialize_all_components()

        self.logger.info(f"BaseTrainer initialized (lazy_init={self.lazy_init})")

        # è®­ç»ƒçŠ¶æ€
        self.training_status = TrainingStatus()
        self.training_status.total_rounds = self.training_config.max_rounds
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.round_statistics: Dict[int, RoundStatistics] = {}
        self.client_statistics: Dict[str, ClientStatistics] = {}
        
        # å›è°ƒå‡½æ•°
        self.round_callbacks: List[Callable] = []
        self.training_callbacks: List[Callable] = []

        # å›è°ƒæœºåˆ¶ï¼ˆç”¨äºå®éªŒè®°å½•ç­‰æ‰©å±•åŠŸèƒ½ï¼‰
        self._callbacks: Dict[str, List[Callable]] = {
            'before_round': [],
            'after_round': [],
            'after_evaluation': []
        }

        # å†…éƒ¨çŠ¶æ€
        self._lock = asyncio.Lock()
        self._best_model: Optional[ModelData] = None
        self._checkpoint_models: Dict[int, ModelData] = {}
    
    # ==================== æ ¸å¿ƒè®­ç»ƒæ–¹æ³• (ç”¨æˆ·å¿…é¡»å®ç°) ====================
    
    @abstractmethod
    async def train_round(self, round_num: int, client_ids: List[str]) -> RoundResult:
        """æ‰§è¡Œä¸€è½®è”é‚¦è®­ç»ƒ
        
        Args:
            round_num: å½“å‰è½®æ¬¡ç¼–å·
            client_ids: å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯IDåˆ—è¡¨
            
        Returns:
            RoundResult: è½®æ¬¡è®­ç»ƒç»“æœï¼Œåº”åŒ…å«ï¼š
                - participants: å‚ä¸å®¢æˆ·ç«¯åˆ—è¡¨
                - successful_clients: æˆåŠŸçš„å®¢æˆ·ç«¯åˆ—è¡¨
                - failed_clients: å¤±è´¥çš„å®¢æˆ·ç«¯åˆ—è¡¨
                - aggregated_model: èšåˆåçš„æ¨¡å‹
                - round_metrics: è½®æ¬¡æŒ‡æ ‡ï¼ˆæŸå¤±ã€å‡†ç¡®ç‡ç­‰ï¼‰
                - training_time: è®­ç»ƒæ€»æ—¶é—´
                
        Raises:
            TrainingError: è®­ç»ƒè¿‡ç¨‹ä¸­çš„é”™è¯¯
        
        ä½¿ç”¨ç¤ºä¾‹:
            # å¹¶å‘è°ƒç”¨å¤šä¸ªå®¢æˆ·ç«¯è®­ç»ƒ
            tasks = []
            for client_id in client_ids:
                task = self.learner_proxies[client_id].train({
                    "global_model": self.global_model,
                    "epochs": 5,
                    "learning_rate": 0.01
                })
                tasks.append((client_id, task))
            
            # æ”¶é›†ç»“æœ
            client_results = {}
            for client_id, task in tasks:
                try:
                    result = await task
                    client_results[client_id] = result
                except Exception as e:
                    print(f"Client {client_id} failed: {e}")
            
            # èšåˆæ¨¡å‹
            aggregated_model = await self.aggregate_models(client_results)
            
            return {
                "participants": client_ids,
                "successful_clients": list(client_results.keys()),
                "aggregated_model": aggregated_model,
                "round_metrics": {"avg_loss": 0.1, "avg_accuracy": 0.9}
            }
        """
        pass
    
    @abstractmethod
    async def aggregate_models(self, client_results: Dict[str, Any]) -> ModelData:
        """èšåˆå®¢æˆ·ç«¯æ¨¡å‹
        
        Args:
            client_results: å®¢æˆ·ç«¯è®­ç»ƒç»“æœ {client_id: training_result}
            
        Returns:
            ModelData: èšåˆåçš„å…¨å±€æ¨¡å‹
            
        Raises:
            TrainingError: èšåˆè¿‡ç¨‹ä¸­çš„é”™è¯¯
        
        ä½¿ç”¨ç¤ºä¾‹:
            # FedAvgç®—æ³•ç¤ºä¾‹
            model_updates = []
            total_samples = 0
            
            for client_id, result in client_results.items():
                model_update = result.get("model_update", {})
                samples_count = result.get("samples_count", 1)
                
                model_updates.append((model_update, samples_count))
                total_samples += samples_count
            
            # åŠ æƒå¹³å‡
            aggregated_model = {}
            for layer_name in model_updates[0][0].keys():
                weighted_sum = 0
                for model_update, samples_count in model_updates:
                    weight = samples_count / total_samples
                    weighted_sum += model_update[layer_name] * weight
                aggregated_model[layer_name] = weighted_sum
            
            return aggregated_model
        """
        pass
    
    @abstractmethod
    async def evaluate_global_model(self) -> EvaluationResult:
        """è¯„ä¼°å…¨å±€æ¨¡å‹
        
        Returns:
            EvaluationResult: è¯„ä¼°ç»“æœï¼Œåº”åŒ…å«ï¼š
                - accuracy: å‡†ç¡®ç‡
                - loss: æŸå¤±å€¼
                - metrics: å…¶ä»–è¯„ä¼°æŒ‡æ ‡
                - samples_count: è¯„ä¼°æ ·æœ¬æ•°
                
        Raises:
            TrainingError: è¯„ä¼°è¿‡ç¨‹ä¸­çš„é”™è¯¯
        
        ä½¿ç”¨ç¤ºä¾‹:
            # é€‰æ‹©éƒ¨åˆ†å®¢æˆ·ç«¯è¿›è¡Œè¯„ä¼°
            eval_clients = self.select_evaluation_clients()
            
            eval_results = []
            for client_id in eval_clients:
                try:
                    result = await self.learner_proxies[client_id].evaluate({
                        "model": self.global_model
                    })
                    eval_results.append(result)
                except Exception as e:
                    print(f"Evaluation on client {client_id} failed: {e}")
            
            # è®¡ç®—å…¨å±€è¯„ä¼°æŒ‡æ ‡
            if eval_results:
                avg_accuracy = sum(r.get("accuracy", 0) for r in eval_results) / len(eval_results)
                avg_loss = sum(r.get("loss", 0) for r in eval_results) / len(eval_results)
                
                return {
                    "accuracy": avg_accuracy,
                    "loss": avg_loss,
                    "participants": len(eval_results)
                }
            
            return {"accuracy": 0.0, "loss": float('inf')}
        """
        pass
    
    @abstractmethod
    def should_stop_training(self, round_num: int, round_result: RoundResult) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ
        
        Args:
            round_num: å½“å‰è½®æ¬¡
            round_result: è½®æ¬¡ç»“æœ
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ
        
        ä½¿ç”¨ç¤ºä¾‹:
            # æ£€æŸ¥æ”¶æ•›æ¡ä»¶
            if round_num >= self.training_config.max_rounds:
                return True
            
            # æ£€æŸ¥å‡†ç¡®ç‡æ”¶æ•›
            current_accuracy = round_result.get("round_metrics", {}).get("avg_accuracy", 0)
            if abs(current_accuracy - self.training_status.best_accuracy) < self.training_config.convergence_threshold:
                self.training_status.patience_counter += 1
                if self.training_status.patience_counter >= self.training_config.patience:
                    return True
            else:
                self.training_status.patience_counter = 0
                if current_accuracy > self.training_status.best_accuracy:
                    self.training_status.best_accuracy = current_accuracy
            
            return False
        """
        pass

    # ==================== ç»„ä»¶ç®¡ç†æ–¹æ³• (ç»Ÿä¸€åˆå§‹åŒ–ç­–ç•¥) ====================

    def _initialize_all_components(self):
        """ç«‹å³åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        # è§¦å‘æ‰€æœ‰propertyï¼Œå¼ºåˆ¶åˆ›å»ºå®ä¾‹
        _ = self.aggregator
        _ = self.global_model
        if 'evaluator' in self.config:
            _ = self.evaluator

        self.logger.info("All trainer components initialized")

    @property
    def aggregator(self):
        """å»¶è¿ŸåŠ è½½èšåˆå™¨"""
        if self._aggregator is None:
            self._aggregator = self._create_component('aggregator')
            self.logger.debug("Aggregator created")
        return self._aggregator

    @property
    def global_model(self):
        """å»¶è¿ŸåŠ è½½å…¨å±€æ¨¡å‹"""
        if self._global_model is None:
            self._global_model = self._create_component('global_model')
            self.logger.debug("Global model created")
        return self._global_model

    @property
    def evaluator(self):
        """å»¶è¿ŸåŠ è½½è¯„ä¼°å™¨ï¼ˆå¯é€‰ï¼‰"""
        if self._evaluator is None and 'evaluator' in self.config:
            self._evaluator = self._create_component('evaluator')
            self.logger.debug("Evaluator created")
        return self._evaluator

    def _create_component(self, component_name: str):
        """
        é€šç”¨ç»„ä»¶åˆ›å»ºæ–¹æ³•ï¼ˆåŸºç±»å®ç°ï¼‰

        ä¼˜å…ˆçº§ï¼š
        1. é…ç½®ä¸­çš„ç±» + å‚æ•°
        2. å­ç±»çš„é»˜è®¤åˆ›å»ºæ–¹æ³•
        3. æŠ›å‡ºå¼‚å¸¸

        Args:
            component_name: ç»„ä»¶åç§°

        Returns:
            åˆ›å»ºçš„ç»„ä»¶å®ä¾‹
        """
        component_config = self.config.get(component_name)

        # ä¼˜å…ˆä½¿ç”¨é…ç½®
        if component_config and 'class' in component_config:
            component_class = component_config['class']
            component_params = component_config.get('params', {})

            self.logger.debug(
                f"Creating {component_name} from config: "
                f"{component_class.__name__}({component_params})"
            )

            return component_class(**component_params)

        # å›é€€åˆ°é»˜è®¤åˆ›å»ºæ–¹æ³•
        default_method = getattr(self, f'_create_default_{component_name}', None)
        if default_method and callable(default_method):
            self.logger.debug(f"Creating {component_name} using default method")
            return default_method()

        # éƒ½æ²¡æœ‰åˆ™æŠ›å‡ºå¼‚å¸¸
        raise ValueError(
            f"ç»„ä»¶ '{component_name}' æœªåœ¨é…ç½®ä¸­æŒ‡å®šï¼Œ"
            f"ä¸”å­ç±»æœªæä¾› _create_default_{component_name}() æ–¹æ³•"
        )

    # å­ç±»å¯ä»¥è¦†ç›–è¿™äº›æ–¹æ³•æä¾›é»˜è®¤å®ç°
    def _create_default_aggregator(self):
        """å­ç±»å¯è¦†ç›–ï¼šæä¾›é»˜è®¤èšåˆå™¨"""
        raise NotImplementedError(
            "å¿…é¡»åœ¨é…ç½®ä¸­æŒ‡å®š aggregator æˆ–è¦†ç›– _create_default_aggregator()"
        )

    def _create_default_global_model(self):
        """å­ç±»å¯è¦†ç›–ï¼šæä¾›é»˜è®¤å…¨å±€æ¨¡å‹"""
        raise NotImplementedError(
            "å¿…é¡»åœ¨é…ç½®ä¸­æŒ‡å®š global_model æˆ–è¦†ç›– _create_default_global_model()"
        )

    def _create_default_evaluator(self):
        """å­ç±»å¯è¦†ç›–ï¼šæä¾›é»˜è®¤è¯„ä¼°å™¨ï¼ˆå¯é€‰ï¼‰"""
        return None  # è¯„ä¼°å™¨æ˜¯å¯é€‰çš„ï¼Œé»˜è®¤è¿”å›None

    # ==================== çŠ¶æ€ç®¡ç†æ–¹æ³• (æ¡†æ¶æä¾›) ====================
    
    def get_training_status(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒçŠ¶æ€
        
        Returns:
            Dict[str, Any]: è®­ç»ƒçŠ¶æ€ä¿¡æ¯
        """
        return {
            "current_round": self.training_status.current_round,
            "total_rounds": self.training_status.total_rounds,
            "is_training": self.training_status.is_training,
            "start_time": self.training_status.start_time.isoformat() if self.training_status.start_time else None,
            "end_time": self.training_status.end_time.isoformat() if self.training_status.end_time else None,
            "selected_clients": self.training_status.selected_clients,
            "active_clients": self.training_status.active_clients,
            "failed_clients": self.training_status.failed_clients,
            "best_accuracy": self.training_status.best_accuracy,
            "patience_counter": self.training_status.patience_counter,
            "progress": self.training_status.current_round / self.training_status.total_rounds if self.training_status.total_rounds > 0 else 0
        }
    
    def get_round_statistics(self, round_num: int = None) -> Optional[Dict[str, Any]]:
        """è·å–è½®æ¬¡ç»Ÿè®¡
        
        Args:
            round_num: è½®æ¬¡ç¼–å·ï¼ŒNoneè¡¨ç¤ºè·å–æœ€æ–°è½®æ¬¡
            
        Returns:
            Optional[Dict[str, Any]]: è½®æ¬¡ç»Ÿè®¡ä¿¡æ¯
        """
        if round_num is None:
            round_num = self.training_status.current_round
        
        if round_num in self.round_statistics:
            stats = self.round_statistics[round_num]
            return {
                "round_number": stats.round_number,
                "participants_count": stats.participants_count,
                "successful_participants": stats.successful_participants,
                "failed_participants": stats.failed_participants,
                "success_rate": stats.successful_participants / max(stats.participants_count, 1),
                "average_training_time": stats.average_training_time,
                "average_loss": stats.average_loss,
                "average_accuracy": stats.average_accuracy,
                "model_size_bytes": stats.model_size_bytes,
                "communication_time": stats.communication_time,
                "aggregation_time": stats.aggregation_time,
                "total_round_time": stats.total_round_time,
                "convergence_metric": stats.convergence_metric
            }
        
        return None
    
    def get_client_statistics(self, client_id: str = None) -> Dict[str, Any]:
        """è·å–å®¢æˆ·ç«¯ç»Ÿè®¡
        
        Args:
            client_id: å®¢æˆ·ç«¯IDï¼ŒNoneè¡¨ç¤ºè·å–æ‰€æœ‰å®¢æˆ·ç«¯
            
        Returns:
            Dict[str, Any]: å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯
        """
        if client_id:
            if client_id in self.client_statistics:
                stats = self.client_statistics[client_id]
                return {
                    "client_id": stats.client_id,
                    "participation_count": stats.participation_count,
                    "successful_rounds": stats.successful_rounds,
                    "failed_rounds": stats.failed_rounds,
                    "success_rate": stats.successful_rounds / max(stats.participation_count, 1),
                    "average_training_time": stats.average_training_time,
                    "total_samples_trained": stats.total_samples_trained,
                    "last_participation_time": stats.last_participation_time.isoformat() if stats.last_participation_time else None,
                    "connection_stability": stats.connection_stability,
                    "performance_score": stats.performance_score
                }
            return {}
        else:
            # è¿”å›æ‰€æœ‰å®¢æˆ·ç«¯ç»Ÿè®¡
            all_stats = {}
            for cid, stats in self.client_statistics.items():
                all_stats[cid] = {
                    "participation_count": stats.participation_count,
                    "success_rate": stats.successful_rounds / max(stats.participation_count, 1),
                    "average_training_time": stats.average_training_time,
                    "connection_stability": stats.connection_stability,
                    "performance_score": stats.performance_score
                }
            return all_stats
    
    async def save_checkpoint(self, checkpoint_path: str) -> bool:
        """ä¿å­˜æ£€æŸ¥ç‚¹
        
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            checkpoint_data = {
                "round_number": self.training_status.current_round,
                "global_model": self.global_model,
                "training_status": self.get_training_status(),
                "round_statistics": {k: vars(v) for k, v in self.round_statistics.items()},
                "client_statistics": {k: vars(v) for k, v in self.client_statistics.items()},
                "best_model": self._best_model,
                "timestamp": datetime.now().isoformat()
            }
            
            import pickle
            with open(checkpoint_path, 'wb') as f:
                pickle.dump(checkpoint_data, f)

            self.logger.debug(f"Checkpoint saved: {checkpoint_path}")
            return True
            
        except Exception as e:
            self.logger.exception(f"Failed to save checkpoint: {e}")
            return False
    
    async def load_checkpoint(self, checkpoint_path: str) -> bool:
        """åŠ è½½æ£€æŸ¥ç‚¹
        
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            import pickle
            with open(checkpoint_path, 'rb') as f:
                checkpoint_data = pickle.load(f)
            
            # æ¢å¤çŠ¶æ€
            self.training_status.current_round = checkpoint_data["round_number"]
            self.global_model = checkpoint_data["global_model"]
            self._best_model = checkpoint_data.get("best_model")
            
            self.logger.debug(f"Checkpoint loaded: {checkpoint_path}")
            return True
            
        except Exception as e:
            self.logger.exception(f"Failed to load checkpoint: {e}")
            return False
    
    # ==================== å®¢æˆ·ç«¯ç®¡ç†æ–¹æ³• ====================
    
    def select_clients_for_round(self, round_num: int) -> List[str]:
        """é€‰æ‹©å‚ä¸è¯¥è½®è®­ç»ƒçš„å®¢æˆ·ç«¯
        
        Args:
            round_num: è½®æ¬¡ç¼–å·
            
        Returns:
            List[str]: é€‰ä¸­çš„å®¢æˆ·ç«¯IDåˆ—è¡¨
        """
        available_clients = []
        
        # æ£€æŸ¥å®¢æˆ·ç«¯å¯ç”¨æ€§
        available_clients = self.get_available_clients()
        
        # æ£€æŸ¥æœ€å°å®¢æˆ·ç«¯æ•°é‡
        if len(available_clients) < self.training_config.min_clients:
            raise FederationError(f"Insufficient clients available: {len(available_clients)} < {self.training_config.min_clients}")
        
        # æŒ‰æ¯”ä¾‹é€‰æ‹©å®¢æˆ·ç«¯
        selection_count = max(
            self.training_config.min_clients,
            int(len(available_clients) * self.training_config.client_selection_ratio)
        )
        
        # å¯ä»¥åœ¨è¿™é‡Œå®ç°ä¸åŒçš„é€‰æ‹©ç­–ç•¥ï¼šéšæœºé€‰æ‹©ã€åŸºäºæ€§èƒ½é€‰æ‹©ã€åŸºäºæ•°æ®åˆ†å¸ƒé€‰æ‹©ç­‰
        import random
        selected_clients = random.sample(available_clients, min(selection_count, len(available_clients)))
        
        return selected_clients
    
    async def check_client_readiness(self, client_ids: List[str]) -> Dict[str, bool]:
        """æ£€æŸ¥å®¢æˆ·ç«¯å°±ç»ªçŠ¶æ€ï¼ˆçœŸæ­£çš„å¹¶å‘ç‰ˆæœ¬ï¼‰

        Args:
            client_ids: è¦æ£€æŸ¥çš„å®¢æˆ·ç«¯IDåˆ—è¡¨

        Returns:
            Dict[str, bool]: å®¢æˆ·ç«¯å°±ç»ªçŠ¶æ€æ˜ å°„
        """
        readiness = {}

        # åˆ›å»ºæ‰€æœ‰pingä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
        ping_tasks = {}
        for client_id in client_ids:
            if client_id in self.learner_proxies:
                # åœ¨åˆ›å»ºæ—¶åŒ…è£…è¶…æ—¶
                ping_tasks[client_id] = asyncio.wait_for(
                    self.learner_proxies[client_id].ping(),
                    timeout=5.0
                )

        # çœŸæ­£çš„å¹¶å‘ç­‰å¾…æ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(
            *ping_tasks.values(),
            return_exceptions=True  # æ•è·å¼‚å¸¸è€Œä¸æ˜¯ä¸­æ–­å…¶ä»–ä»»åŠ¡
        )

        # å¤„ç†ç»“æœ
        for client_id, result in zip(ping_tasks.keys(), results):
            if isinstance(result, Exception):
                self.logger.exception(f"Ping failed for {client_id}: {type(result).__name__}: {result}")
                readiness[client_id] = False
            else:
                readiness[client_id] = True

        return readiness
    
    def get_available_clients(self) -> List[str]:
        """è·å–å¯ç”¨å®¢æˆ·ç«¯åˆ—è¡¨
        
        Returns:
            List[str]: å¯ç”¨çš„å®¢æˆ·ç«¯IDåˆ—è¡¨
        """
        return self._proxy_manager.get_available_clients()
    
    def is_client_ready(self, client_id: str) -> bool:
        """æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å°±ç»ª
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            
        Returns:
            bool: å®¢æˆ·ç«¯æ˜¯å¦å°±ç»ª
        """
        proxy = self._proxy_manager.get_proxy(client_id)
        return proxy is not None and proxy.is_client_ready()
    
    # ==================== ç»Ÿè®¡æ›´æ–°æ–¹æ³• ====================
    
    async def _update_round_statistics(self, round_num: int, round_result: RoundResult, start_time: datetime):
        """æ›´æ–°è½®æ¬¡ç»Ÿè®¡"""
        async with self._lock:
            stats = RoundStatistics()
            stats.round_number = round_num
            stats.total_round_time = (datetime.now() - start_time).total_seconds()
            
            # ä»è½®æ¬¡ç»“æœä¸­æå–ç»Ÿè®¡ä¿¡æ¯
            participants = round_result.get("participants", [])
            successful = round_result.get("successful_clients", [])
            failed = round_result.get("failed_clients", [])
            
            stats.participants_count = len(participants)
            stats.successful_participants = len(successful)
            stats.failed_participants = len(failed)
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            round_metrics = round_result.get("round_metrics", {})
            stats.average_loss = round_metrics.get("avg_loss", 0.0)
            stats.average_accuracy = round_metrics.get("avg_accuracy", 0.0)
            stats.convergence_metric = round_metrics.get("convergence", 0.0)
            
            self.round_statistics[round_num] = stats
    
    async def _update_client_statistics(self, client_id: str, success: bool, training_time: float, samples_count: int = 0):
        """æ›´æ–°å®¢æˆ·ç«¯ç»Ÿè®¡"""
        async with self._lock:
            if client_id not in self.client_statistics:
                self.client_statistics[client_id] = ClientStatistics(client_id)
            
            stats = self.client_statistics[client_id]
            stats.participation_count += 1
            stats.last_participation_time = datetime.now()
            
            if success:
                stats.successful_rounds += 1
                # æ›´æ–°å¹³å‡è®­ç»ƒæ—¶é—´
                if stats.successful_rounds == 1:
                    stats.average_training_time = training_time
                else:
                    stats.average_training_time = (
                        (stats.average_training_time * (stats.successful_rounds - 1) + training_time) / 
                        stats.successful_rounds
                    )
                stats.total_samples_trained += samples_count
            else:
                stats.failed_rounds += 1
            
            # æ›´æ–°è¿æ¥ç¨³å®šæ€§è¯„åˆ†
            stats.connection_stability = stats.successful_rounds / stats.participation_count
            
            # æ›´æ–°æ€§èƒ½è¯„åˆ†ï¼ˆå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´è®¡ç®—æ–¹å¼ï¼‰
            stats.performance_score = (
                stats.connection_stability * 0.4 +
                (1.0 / max(stats.average_training_time, 0.1)) * 0.3 +  # è®­ç»ƒé€Ÿåº¦
                (stats.total_samples_trained / 10000.0) * 0.3  # æ•°æ®è´¡çŒ®
            )
    
    # ==================== ç”Ÿå‘½å‘¨æœŸæ–¹æ³• (æ¡†æ¶æä¾›) ====================
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥å®¢æˆ·ç«¯è¿æ¥ (å…è®¸ä¸º0ï¼Œåœ¨è®­ç»ƒæ—¶å†æ£€æŸ¥)
            self.logger.debug("Checking client connections...")
            available_clients = self.get_available_clients()
            self.logger.debug(f"Found {len(available_clients)} available clients: {available_clients}")
            
            # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
            if self.global_model is None:
                raise FederationError("Global model not provided")
            
            # æ‰§è¡Œç”¨æˆ·è‡ªå®šä¹‰åˆå§‹åŒ–
            await self._perform_custom_initialization()
            
            self.logger.debug("BaseTrainer initialized successfully")
            return True
            
        except Exception as e:
            self.logger.exception(f"Trainer initialization failed: {e}")
            return False
    
    async def _perform_custom_initialization(self):
        """æ‰§è¡Œè‡ªå®šä¹‰åˆå§‹åŒ– - å­ç±»å¯é‡å†™"""
        pass
    
    async def cleanup(self) -> None:
        """æ¸…ç†è®­ç»ƒå™¨èµ„æº"""
        async with self._lock:
            # é‡ç½®è®­ç»ƒçŠ¶æ€
            self.training_status = TrainingStatus()
            
            # æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
            self.round_statistics.clear()
            for stats in self.client_statistics.values():
                stats.__init__(stats.client_id)  # é‡ç½®ç»Ÿè®¡
            
            # æ¸…ç†å›è°ƒ
            self.round_callbacks.clear()
            self.training_callbacks.clear()
        
        self.logger.debug("BaseTrainer cleaned up")
    
    async def handle_client_failure(self, client_id: str) -> None:
        """å¤„ç†å®¢æˆ·ç«¯æ•…éšœ
        
        Args:
            client_id: æ•…éšœçš„å®¢æˆ·ç«¯ID
        """
        self.logger.debug(f"Handling client failure: {client_id}")
        
        # æ›´æ–°å¤±è´¥ç»Ÿè®¡
        await self._update_client_statistics(client_id, False, 0.0)
        
        # ä»æ´»è·ƒå®¢æˆ·ç«¯åˆ—è¡¨ä¸­ç§»é™¤
        if client_id in self.training_status.active_clients:
            self.training_status.active_clients.remove(client_id)
        
        # æ·»åŠ åˆ°å¤±è´¥å®¢æˆ·ç«¯åˆ—è¡¨
        if client_id not in self.training_status.failed_clients:
            self.training_status.failed_clients.append(client_id)
        
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å®¢æˆ·ç«¯æ¢å¤é€»è¾‘
        # ä¾‹å¦‚ï¼šå°è¯•é‡æ–°è¿æ¥ã€ä»å¤‡ç”¨å®¢æˆ·ç«¯åˆ—è¡¨ä¸­é€‰æ‹©ç­‰
    
    # ==================== å›è°ƒç®¡ç† ====================
    
    def register_round_callback(self, callback: Callable) -> str:
        """æ³¨å†Œè½®æ¬¡å›è°ƒ
        
        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œç­¾åä¸º callback(round_num: int, round_result: RoundResult)
            
        Returns:
            str: å›è°ƒID
        """
        callback_id = f"round_callback_{len(self.round_callbacks)}"
        self.round_callbacks.append((callback_id, callback))
        return callback_id
    
    def register_training_callback(self, callback: Callable) -> str:
        """æ³¨å†Œè®­ç»ƒå›è°ƒ
        
        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œç­¾åä¸º callback(event: str, data: Any)
            
        Returns:
            str: å›è°ƒID
        """
        callback_id = f"training_callback_{len(self.training_callbacks)}"
        self.training_callbacks.append((callback_id, callback))
        return callback_id
    
    def unregister_callback(self, callback_id: str) -> bool:
        """å–æ¶ˆæ³¨å†Œå›è°ƒ
        
        Args:
            callback_id: å›è°ƒID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        # æ£€æŸ¥è½®æ¬¡å›è°ƒ
        for i, (cid, callback) in enumerate(self.round_callbacks):
            if cid == callback_id:
                del self.round_callbacks[i]
                return True
        
        # æ£€æŸ¥è®­ç»ƒå›è°ƒ
        for i, (cid, callback) in enumerate(self.training_callbacks):
            if cid == callback_id:
                del self.training_callbacks[i]
                return True
        
        return False
    
    async def _trigger_round_callbacks(self, round_num: int, round_result: RoundResult):
        """è§¦å‘è½®æ¬¡å›è°ƒ"""
        for callback_id, callback in self.round_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(round_num, round_result)
                else:
                    callback(round_num, round_result)
            except Exception as e:
                self.logger.debug(f"Round callback {callback_id} error: {e}")
    
    async def _trigger_training_callbacks(self, event: str, data: Any):
        """è§¦å‘è®­ç»ƒå›è°ƒ"""
        for callback_id, callback in self.training_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(event, data)
                else:
                    callback(event, data)
            except Exception as e:
                self.logger.debug(f"Training callback {callback_id} error: {e}")

    # ==================== å›è°ƒæœºåˆ¶ï¼ˆç”¨äºå®éªŒè®°å½•ï¼‰ ====================

    def add_callback(self, event: str, callback: Callable):
        """æ·»åŠ å›è°ƒå‡½æ•°ï¼ˆç”¨äºå®éªŒè®°å½•ç­‰æ‰©å±•åŠŸèƒ½ï¼‰

        Args:
            event: äº‹ä»¶åç§°ï¼ˆ'before_round', 'after_round', 'after_evaluation'ï¼‰
            callback: å›è°ƒå‡½æ•°
        """
        if event in self._callbacks:
            self._callbacks[event].append(callback)
        else:
            self.logger.warning(f"Unknown callback event: {event}")

    def _trigger_callbacks(self, event: str, *args, **kwargs):
        """è§¦å‘å›è°ƒï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰

        Args:
            event: äº‹ä»¶åç§°
            *args, **kwargs: ä¼ é€’ç»™å›è°ƒçš„å‚æ•°
        """
        # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºåˆ¤æ–­æ¡ä»¶å’Œcallbacké˜Ÿåˆ—
        self.logger.info(f"[Callback Debug] è§¦å‘äº‹ä»¶: {event}")
        self.logger.info(f"[Callback Debug] åˆ¤æ–­æ¡ä»¶: event='{event}', _callbacks æ˜¯å¦æœ‰æ­¤äº‹ä»¶: {event in self._callbacks}")
        self.logger.info(f"[Callback Debug] Callbacké˜Ÿåˆ—ä¸­çš„å…ƒç´ : {list(self._callbacks.keys())}")
        self.logger.info(f"[Callback Debug] äº‹ä»¶ '{event}' çš„å›è°ƒæ•°é‡: {len(self._callbacks.get(event, []))}")

        for callback in self._callbacks.get(event, []):
            try:
                self.logger.info(f"[Callback Debug] æ‰§è¡Œå›è°ƒ: {callback}")
                if asyncio.iscoroutinefunction(callback):
                    asyncio.create_task(callback(*args, **kwargs))
                else:
                    callback(*args, **kwargs)
            except Exception as e:
                self.logger.warning(f"Callback {event} failed: {e}")

    # ==================== åŒ…è£…æ–¹æ³•ï¼ˆç”¨äºå›è°ƒæ³¨å…¥ï¼‰ ====================

    async def _train_round(self, round_num: int, client_ids: List[str]) -> RoundResult:
        """åŒ…è£…æ–¹æ³•ï¼šè´Ÿè´£å›è°ƒè§¦å‘ï¼Œè°ƒç”¨ç”¨æˆ·å®ç°çš„ train_round

        Args:
            round_num: è½®æ¬¡ç¼–å·
            client_ids: å®¢æˆ·ç«¯IDåˆ—è¡¨

        Returns:
            RoundResult: è½®æ¬¡è®­ç»ƒç»“æœ
        """
        # è§¦å‘å‰ç½®å›è°ƒ
        self._trigger_callbacks('before_round', round_num)

        # è°ƒç”¨ç”¨æˆ·å®ç°çš„è®­ç»ƒæ–¹æ³•
        result = await self.train_round(round_num, client_ids)

        # è§¦å‘åç½®å›è°ƒ
        self._trigger_callbacks('after_round', round_num, result)

        return result

    async def _evaluate_global_model(self) -> EvaluationResult:
        """åŒ…è£…æ–¹æ³•ï¼šè´Ÿè´£å›è°ƒè§¦å‘ï¼Œè°ƒç”¨ç”¨æˆ·å®ç°çš„ evaluate_global_model

        Returns:
            EvaluationResult: è¯„ä¼°ç»“æœ
        """
        # è°ƒç”¨ç”¨æˆ·å®ç°çš„è¯„ä¼°æ–¹æ³•
        result = await self.evaluate_global_model()

        # è§¦å‘å›è°ƒ
        self._trigger_callbacks('after_evaluation', result)

        return result

    # ==================== è®­ç»ƒå¾ªç¯æ–¹æ³• (æ¡†æ¶æä¾›) ====================

    async def run_training(self, max_rounds: int) -> FederationResult:
        """
        æ‰§è¡Œå®Œæ•´çš„è”é‚¦å­¦ä¹ è®­ç»ƒæµç¨‹

        Args:
            max_rounds: æœ€å¤§è®­ç»ƒè½®æ•°

        Returns:
            FederationResult: è®­ç»ƒç»“æœ

        Raises:
            FederationError: è®­ç»ƒå¤±è´¥
        """
        result = FederationResult()
        result.total_rounds = max_rounds
        self.training_status.total_rounds = max_rounds
        self.training_status.is_training = True
        self.training_status.start_time = datetime.now()

        self.logger.info(f"Starting federated training for {max_rounds} rounds...")

        try:
            # è§¦å‘è®­ç»ƒå¼€å§‹å›è°ƒ
            await self._trigger_training_callbacks("TRAINING_STARTED", {
                "start_time": self.training_status.start_time.isoformat(),
                "max_rounds": max_rounds
            })

            # è®­ç»ƒå¾ªç¯
            for round_num in range(1, max_rounds + 1):
                round_start_time = datetime.now()

                try:
                    # é€‰æ‹©å®¢æˆ·ç«¯
                    selected_clients = self.select_clients_for_round(round_num)
                    self.logger.info(f"\nRound {round_num}/{max_rounds}: Selected {len(selected_clients)} clients")

                    # æ£€æŸ¥å®¢æˆ·ç«¯å°±ç»ªçŠ¶æ€
                    client_readiness = await self.check_client_readiness(selected_clients)
                    ready_clients = [cid for cid, ready in client_readiness.items() if ready]

                    if len(ready_clients) < self.training_config.min_clients:
                        self.logger.info(f"Warning: Insufficient ready clients ({len(ready_clients)} < {self.training_config.min_clients})")
                        continue

                    # æ›´æ–°è®­ç»ƒçŠ¶æ€
                    self.training_status.current_round = round_num
                    self.training_status.selected_clients = selected_clients
                    self.training_status.active_clients = ready_clients

                    # æ‰§è¡Œè®­ç»ƒè½®æ¬¡ï¼ˆä½¿ç”¨åŒ…è£…æ–¹æ³•è§¦å‘å›è°ƒï¼‰
                    round_result = await self._train_round(round_num, ready_clients)

                    # æ›´æ–°å…¨å±€æ¨¡å‹
                    if "aggregated_model" in round_result:
                        self.global_model = round_result["aggregated_model"]
                        if self._best_model is None:
                            self._best_model = self.global_model

                    # è®¡ç®—è½®æ¬¡æ—¶é—´
                    round_time = (datetime.now() - round_start_time).total_seconds()
                    round_result["round_time"] = round_time
                    round_result["round_number"] = round_num

                    # æ›´æ–°ç»Ÿè®¡
                    await self._update_round_statistics(round_num, round_result, round_start_time)

                    # æ›´æ–°ç»“æœ
                    result.completed_rounds = round_num
                    result.training_history.append(round_result)

                    # æ›´æ–°æœ€ä½³æŒ‡æ ‡
                    round_metrics = round_result.get("round_metrics", {})
                    if "avg_accuracy" in round_metrics:
                        accuracy = round_metrics["avg_accuracy"]
                        if accuracy > result.final_accuracy:
                            result.final_accuracy = accuracy
                            result.best_model = (
                                self.global_model.copy()
                                if isinstance(self.global_model, dict)
                                else self.global_model
                            )

                    if "avg_loss" in round_metrics:
                        loss = round_metrics["avg_loss"]
                        if loss < result.final_loss:
                            result.final_loss = loss

                    # è§¦å‘è½®æ¬¡å›è°ƒ
                    await self._trigger_round_callbacks(round_num, round_result)

                    self.logger.info(f"Round {round_num} completed in {round_time:.2f}s")
                    self.logger.info(f"  Metrics: accuracy={round_metrics.get('avg_accuracy', 0):.4f}, loss={round_metrics.get('avg_loss', 0):.4f}")

                    # æ£€æŸ¥æ”¶æ•›æ¡ä»¶
                    if self.should_stop_training(round_num, round_result):
                        result.termination_reason = "converged"
                        result.convergence_round = round_num
                        self.logger.info(f"Training converged at round {round_num}")
                        break

                except Exception as e:
                    self.logger.exception(f"Round {round_num} failed: {e}")
                    # å¯ä»¥é€‰æ‹©ç»§ç»­ä¸‹ä¸€è½®æˆ–ç»ˆæ­¢è®­ç»ƒ
                    continue

            # æ­£å¸¸å®Œæˆæ‰€æœ‰è½®æ¬¡
            if result.termination_reason == "unknown":
                result.termination_reason = "max_rounds_reached"

            # æœ€ç»ˆè¯„ä¼°
            self.logger.info("Performing final evaluation...")
            try:
                final_evaluation = await self.evaluate_global_model()
                if final_evaluation.get("accuracy") is not None:
                    result.final_accuracy = final_evaluation["accuracy"]
                if final_evaluation.get("loss") is not None:
                    result.final_loss = final_evaluation["loss"]
            except Exception as e:
                self.logger.exception(f"Final evaluation failed: {e}")

            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            if result.best_model is None:
                result.best_model = self.global_model

            result.success = True

        except Exception as e:
            result.error_message = str(e)
            result.success = False
            self.logger.exception(f"Training failed: {e}")
            raise FederationError(f"Training failed: {str(e)}")

        finally:
            # æ›´æ–°è®­ç»ƒçŠ¶æ€
            self.training_status.is_training = False
            self.training_status.end_time = datetime.now()

            if self.training_status.start_time:
                result.total_time = (
                    self.training_status.end_time - self.training_status.start_time
                ).total_seconds()

            # è§¦å‘è®­ç»ƒå®Œæˆå›è°ƒ
            await self._trigger_training_callbacks("TRAINING_COMPLETED", {
                "end_time": self.training_status.end_time.isoformat(),
                "completed_rounds": result.completed_rounds,
                "final_accuracy": result.final_accuracy,
                "final_loss": result.final_loss,
                "total_time": result.total_time,
                "termination_reason": result.termination_reason
            })

            self.logger.info(f"Training completed: {result.completed_rounds}/{max_rounds} rounds")
            self.logger.info(f"  Final accuracy: {result.final_accuracy:.4f}")
            self.logger.info(f"  Final loss: {result.final_loss:.4f}")
            self.logger.info(f"  Total time: {result.total_time:.2f}s")
            self.logger.info(f"  Termination reason: {result.termination_reason}")

        return result
