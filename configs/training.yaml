# Training configuration for FedCL framework
training:
  # 基础训练参数
  num_epochs: 10
  batch_size: 32
  learning_rate: 0.001
  
  # 优化器配置
  optimization:
    optimizer: "adam"          # 优化器类型: adam, sgd, adamw
    lr_scheduler: "cosine"     # 学习率调度器: cosine, step, exponential, none
    weight_decay: 0.0001       # 权重衰减
    momentum: 0.9              # 动量（SGD专用）
    betas: [0.9, 0.999]       # Beta参数（Adam专用）
    eps: 1e-8                  # Epsilon参数（Adam专用）
    
    # 学习率调度器参数
    lr_scheduler_params:
      step_size: 30            # StepLR步长
      gamma: 0.1               # 学习率衰减因子
      T_max: 100               # CosineAnnealingLR周期
      eta_min: 0               # CosineAnnealingLR最小学习率
  
  # 早停配置
  early_stopping:
    enable: true               # 是否启用早停
    patience: 5                # 容忍轮数
    min_delta: 0.001          # 最小改进阈值
    monitor: "val_loss"        # 监控的指标
    mode: "min"                # 监控模式: min, max
    
  # 梯度配置
  gradient:
    clip_norm: 1.0             # 梯度裁剪范数
    accumulation_steps: 1      # 梯度累积步数
    clip_value: null           # 梯度值裁剪
    
  # 验证配置
  validation:
    interval: 1                # 验证间隔（轮数）
    metric: "accuracy"         # 主要验证指标
    split_ratio: 0.2          # 验证集比例
    
  # 检查点配置
  checkpointing:
    save_best: true            # 保存最佳模型
    save_interval: 5           # 保存间隔（轮数）
    save_last: true            # 保存最后一个检查点
    max_checkpoints: 3         # 最大检查点数量
    monitor: "val_loss"        # 监控指标
    
  # 数据加载配置
  data_loading:
    num_workers: 4             # 数据加载器工作进程数
    pin_memory: true           # 是否固定内存
    drop_last: false           # 是否丢弃最后不完整批次
    persistent_workers: true   # 是否保持工作进程
    prefetch_factor: 2         # 预取因子
    
  # 设备配置
  device:
    type: "auto"               # 设备类型: auto, cpu, cuda, mps
    gpu_ids: [0]              # GPU设备ID列表
    mixed_precision: false     # 是否使用混合精度训练
    
  # 分布式训练配置
  distributed:
    enable: false              # 是否启用分布式训练
    backend: "nccl"           # 分布式后端: nccl, gloo, mpi
    init_method: "env://"     # 初始化方法
    world_size: 1             # 世界大小
    rank: 0                   # 当前进程排名
    
  # 内存管理配置
  memory:
    max_memory_usage: 0.8     # 最大内存使用率
    memory_check_interval: 10  # 内存检查间隔（批次）
    auto_batch_size: false     # 是否自动调整批次大小
    gradient_checkpointing: false  # 是否使用梯度检查点
    
  # 调试配置
  debug:
    log_interval: 10           # 日志记录间隔（批次）
    save_gradients: false      # 是否保存梯度信息
    profile_training: false    # 是否进行训练性能分析
    detect_anomaly: false      # 是否检测异常
    
  # 实验配置
  experiment:
    seed: 42                   # 随机种子
    deterministic: true        # 是否使用确定性算法
    benchmark: false           # 是否启用cuDNN基准测试
    
  # 联邦学习特定配置
  federated:
    local_epochs: 5            # 本地训练轮数
    client_fraction: 1.0       # 参与训练的客户端比例
    min_clients: 1             # 最小客户端数量
    max_clients: 100           # 最大客户端数量
    
    # 客户端资源配置
    client_resources:
      min_memory: 1024         # 最小内存要求（MB）
      min_compute: 1.0         # 最小计算能力要求
      timeout: 300             # 训练超时时间（秒）
      
    # 模型更新配置
    model_update:
      compression: null        # 压缩方法: none, quantization, sparsification
      encryption: false        # 是否加密模型更新
      differential_privacy: false  # 是否使用差分隐私
      
  # 持续学习特定配置
  continual_learning:
    memory_size: 1000          # 记忆库大小
    rehearsal_ratio: 0.1       # 重放比例
    task_increment: "class"    # 任务增量类型: class, domain, task
    
    # 正则化参数
    regularization:
      ewc_lambda: 1000         # EWC正则化强度
      l2_lambda: 0.001         # L2正则化强度
      
    # 知识蒸馏参数
    distillation:
      temperature: 3.0         # 蒸馏温度
      alpha: 0.5              # 蒸馏损失权重
      
  # 度量和日志配置
  metrics:
    track_accuracy: true       # 是否跟踪准确率
    track_loss: true          # 是否跟踪损失
    track_memory: true        # 是否跟踪内存使用
    track_time: true          # 是否跟踪时间
    
    # 自定义度量
    custom_metrics:
      - "f1_score"
      - "precision"
      - "recall"
      
  # 回调配置
  callbacks:
    tensorboard: true          # 是否启用TensorBoard
    wandb: false              # 是否启用Weights & Biases
    mlflow: false             # 是否启用MLflow
    
  # 错误处理配置
  error_handling:
    max_retries: 3             # 最大重试次数
    retry_delay: 1.0          # 重试延迟（秒）
    fallback_strategy: "reduce_batch"  # 回退策略
    save_on_error: true        # 错误时是否保存状态
