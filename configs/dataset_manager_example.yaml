# configs/dataset_manager_example.yaml
# Dataset Manager 配置示例

# 数据集配置
datasets:
  # CIFAR-10 数据集
  cifar10:
    type: "torchvision"
    name: "CIFAR10" 
    root: "./data/cifar10"
    download: true
    transforms:
      train: 
        - name: "random_horizontal_flip"
          params:
            p: 0.5
        - name: "random_crop" 
          params:
            size: [32, 32]
            padding: 4
        - name: "normalize"
          params:
            mean: [0.4914, 0.4822, 0.4465]
            std: [0.2023, 0.1994, 0.2010]
      test:
        - name: "normalize"
          params:
            mean: [0.4914, 0.4822, 0.4465]
            std: [0.2023, 0.1994, 0.2010]
    
  # CIFAR-100 数据集  
  cifar100:
    type: "torchvision"
    name: "CIFAR100"
    root: "./data/cifar100"
    download: true
    transforms:
      train:
        - name: "random_horizontal_flip"
          params:
            p: 0.5
        - name: "random_crop"
          params:
            size: [32, 32]
            padding: 4
        - name: "normalize"
          params:
            mean: [0.5071, 0.4865, 0.4409]
            std: [0.2673, 0.2564, 0.2762]
      test:
        - name: "normalize"
          params:
            mean: [0.5071, 0.4865, 0.4409]
            std: [0.2673, 0.2564, 0.2762]

  # 自定义数据集
  custom_dataset:
    type: "custom"
    data_path: "./data/custom"
    loader_class: "CustomDatasetLoader"
    preprocessing:
      - name: "resize"
        params:
          size: [224, 224]
      - name: "normalize"
        params:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    metadata:
      description: "Custom dataset for federated learning"
      num_classes: 10
      
  # 从文件加载数据集
  file_dataset:
    type: "file"
    file_path: "./data/preprocessed/dataset.pkl"
    metadata:
      description: "Preprocessed dataset from pickle file"

# 缓存配置
cache:
  enable: true
  max_size: "2GB"           # 最大缓存大小
  strategy: "LRU"           # 缓存策略 (LRU, FIFO)
  persist: true             # 是否持久化缓存
  
  # 缓存性能配置
  compression: false        # 是否压缩缓存数据
  memory_threshold: 0.8     # 内存使用阈值

# 验证配置
validation:
  enable: true
  strict_mode: false        # 严格模式：验证失败时抛出异常
  
  # 验证检查项
  checks:
    integrity: true         # 数据完整性检查
    format: true           # 数据格式检查
    size: true             # 数据大小检查
    labels: true           # 标签有效性检查
    distribution: true     # 类别分布检查
    
  # 验证阈值
  thresholds:
    min_samples: 10        # 最小样本数
    max_imbalance_ratio: 10 # 最大类别不平衡比例
    
# 下载配置
download:
  parallel: true           # 并行下载
  max_workers: 4          # 最大并行数
  retry_attempts: 3       # 重试次数
  timeout: 300            # 超时时间(秒)
  
# 性能优化配置
performance:
  lazy_loading: true      # 延迟加载
  memory_mapping: false   # 内存映射
  prefetch_factor: 2      # 预取因子
  
  # 并发配置
  max_threads: 8          # 最大线程数
  thread_pool_size: 4     # 线程池大小

# 监控和日志配置
monitoring:
  enable_stats: true      # 启用统计信息收集
  log_level: "INFO"       # 日志级别
  metrics_interval: 60    # 指标收集间隔(秒)
  
  # 统计信息
  track_memory_usage: true
  track_access_patterns: true
  track_cache_performance: true

# 任务生成配置
task_generation:
  num_tasks: 10
  classes_per_task: 10
  type: "class_incremental"  # class_incremental, domain_incremental, task_incremental
  
  # 任务序列配置
  shuffle_classes: true
  random_seed: 42
  
  # 重放缓冲区配置
  replay:
    enable: false
    buffer_size_per_class: 50
    selection_strategy: "random"  # random, herding, gradient_based
