# =============================================================================
# FedBABU Algorithm Preset
# =============================================================================
# Paper: Federated Learning with Only Positive Labels
# Authors: Oh et al., 2021
#
# Description:
#   FedBABU (Federated learning with BAckdoor and BAck-propagation Unlearning)
#   freezes the body (feature extractor) during fine-tuning and only updates
#   the head (classifier). This approach prevents overfitting to local data
#   while maintaining good generalization.
#
# Key Features:
#   - Body freezing during local fine-tuning
#   - Only head is updated locally after receiving global model
#   - Reduces overfitting to local non-IID data
#   - Simple but effective personalization strategy
#
# Components:
#   - Trainer: default
#   - Learner: fl.fedbabu (body freezing during fine-tuning)
#   - Aggregator: fedavg (aggregates body only)
#
# Hyperparameters:
#   - finetune_epochs: Number of epochs for head fine-tuning (default: 5)
#
# Usage:
#   extend: presets/algorithms/fedbabu.yaml
#
# =============================================================================

extend: ../common/base.yaml

# Trainer configuration
trainer:
  type: default
  args:
    max_rounds: 100
    local_epochs: 5
    client_fraction: 0.1
    min_available_clients: 2

    fit_config:
      epochs: 5
      evaluate_after_fit: true

    eval_interval: 5
    evaluate_after_aggregation: false

# Aggregator configuration (aggregates body only)
aggregator:
  type: fedavg
  args:
    weighted: true

# Learner configuration (FedBABU with body freezing)
learner:
  type: fl.fedbabu
  args:
    learning_rate: 0.01
    batch_size: 32
    optimizer: SGD
    momentum: 0.9

    # FedBABU-specific configuration
    finetune_epochs: 5  # Epochs for head fine-tuning with frozen body
