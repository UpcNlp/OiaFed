# =============================================================================
# FedPer Algorithm Preset
# =============================================================================
# Paper: Federated Learning with Personalization Layers
# Authors: Arivazhagan et al., 2019
#
# Description:
#   FedPer divides the model into shared base layers and personalized layers.
#   Only base layers are aggregated across clients, while personalized layers
#   (typically final classification layers) remain client-specific.
#
# Key Features:
#   - Separates shared representation from personalized classification
#   - Personalized layers adapt to local data distribution
#   - Effective for heterogeneous client data
#
# Components:
#   - Trainer: default
#   - Learner: fl.fedper (handles layer partitioning)
#   - Aggregator: fedavg (only aggregates base layers)
#
# Hyperparameters:
#   - personalized_layers: List of layer names to keep personalized
#                          (default: ["fc"] for final fully-connected layer)
#
# Usage:
#   extend: presets/algorithms/fedper.yaml
#
# =============================================================================

extend: ../common/base.yaml

# Trainer configuration
trainer:
  type: default
  args:
    max_rounds: 100
    local_epochs: 5
    client_fraction: 0.1
    min_available_clients: 2

    fit_config:
      epochs: 5
      evaluate_after_fit: true

    eval_interval: 5
    evaluate_after_aggregation: false

# Aggregator configuration (only aggregates base layers)
aggregator:
  type: fedavg
  args:
    weighted: true

# Learner configuration (FedPer with personalized layers)
learner:
  type: fl.fedper
  args:
    learning_rate: 0.01
    batch_size: 32
    optimizer: SGD
    momentum: 0.9

    # Personalized layer configuration
    personalized_layers:
      - fc  # Final fully-connected layer remains local
