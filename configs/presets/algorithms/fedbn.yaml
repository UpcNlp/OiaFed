# =============================================================================
# FedBN Algorithm Preset
# =============================================================================
# Paper: FedBN: Federated Learning on Non-IID Features via Local Batch Normalization
# Authors: Li et al., 2021
#
# Description:
#   FedBN addresses feature shift non-IID by keeping batch normalization
#   parameters local (not aggregated), while aggregating other model weights.
#   This allows models to adapt to local data distributions via BN statistics.
#
# Key Features:
#   - Local batch normalization parameters (not aggregated)
#   - Global aggregation of other model weights
#   - Effective for feature distribution skew
#
# Components:
#   - Trainer: default
#   - Learner: fl.generic
#   - Aggregator: fedbn (excludes BN parameters from aggregation)
#
# Usage:
#   extend: presets/algorithms/fedbn.yaml
#
# Note:
#   Requires models with batch normalization layers. The aggregator will
#   automatically exclude parameters matching patterns like "bn", "batch_norm".
#
# =============================================================================

extend: ../common/base.yaml

# Trainer configuration
trainer:
  type: default
  args:
    max_rounds: 100
    local_epochs: 5
    client_fraction: 0.1
    min_available_clients: 2

    fit_config:
      epochs: 5
      evaluate_after_fit: true

    eval_interval: 5
    evaluate_after_aggregation: false

# Aggregator configuration (FedBN excludes BN parameters)
aggregator:
  type: fedbn
  args:
    weighted: true

# Learner configuration
learner:
  type: fl.generic
  args:
    learning_rate: 0.01
    batch_size: 32
    optimizer: SGD
    momentum: 0.9
